{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c094908",
   "metadata": {},
   "source": [
    "# TP 1 : Coder avec la tête.\n",
    "\n",
    "### 1. Définition du problème\n",
    "\n",
    "Soit D un document texte (par exemple, les oeuvres complètes de Shakespeare). \n",
    "\n",
    "Un _mot_ est une séquence consécutive de caractères alpha-numériques, tels que \"Hamlet\" ou \"2023\". Nous traiterons les lettres majuscules comme si elles étaient minuscules. Ainsi, \"Hamlet\" et \"hamlet\" sont un seul et même mot. Les mots se terminent au premier caractère non alpha-numérique. Ainsi \"aujourd'hui\" est constitué de deux mots : \"aujourd\" et \"hui\".\n",
    "\n",
    "La distribution de fréquence des mots d'un document D est la fonction qui à chaque mot $w$ associe son nombre d'occurences noté $D(w)$.\n",
    "\n",
    "On peut voir la distribution de fréquence $D$ comme un vecteur avec une coordonnée par mot, à valeur dans $\\mathbb{N}$. La norme de ce vecteur se définit habituellement \n",
    "\n",
    "$$ N(D) = \\sqrt{D\\cdot D} = \\sqrt{\\sum_w D(w)^2}. $$\n",
    "\n",
    "Le produit scalaire de deux vecteurs $D$ et $D'$ est aussi défini usuellement :\n",
    "\n",
    "$$D\\cdot D' = \\sum_w D(w)D'(w).$$\n",
    "\n",
    "Enfin, l'angle entre deux vecteurs $D$ et $D'$ est défini comme suit :\n",
    "\n",
    "$$angle(D,D') = \\arccos\\left(\\frac{D\\cdot D'}{N(D)N(D')}\\right).$$\n",
    "\n",
    "Cet angle (en radians) sera un nombre entre $0$ et $\\pi/2 = 1.57079632\\ldots$ puisques les vecteurs sont à coordonnées positives. Clairement, on a :\n",
    "\n",
    "- $angle(D,D) = 0$ pour tout vecteur $D$\n",
    "- $angle(D,D') = \\pi/2$ si $D$ et $D'$ n'ont aucun mot en commun.\n",
    "\n",
    "On définit la distance entre deux documents comme l'angle entre leurs vecteurs distribution de fréquence. Le problème est donc de calculer la distance entre deux documents texte.\n",
    "\n",
    "### 2. Première version du programme\n",
    "\n",
    "Nous codons une première version du programme.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7dda21c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "    # math.acos(x) is the arccosine of x.\n",
    "    # math.sqrt(x) is the square root of x.\n",
    "\n",
    "import string\n",
    "    # string.join(words,sep) takes a given list of words,\n",
    "    #    and returns a single string resulting from concatenating them\n",
    "    #    together, separated by the string sep .\n",
    "    # string.lower(word) converts word to lower-case\n",
    "\n",
    "##################################\n",
    "# Operation 1: read a text file ##\n",
    "##################################\n",
    "def read_file(filename):\n",
    "    \"\"\" \n",
    "    Read the text file with the given filename;\n",
    "    return a list of the lines of text in the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fp = open(filename)\n",
    "        L = fp.readlines()\n",
    "    except IOError:\n",
    "        print (\"Error opening or reading input file: \",filename)\n",
    "    return L\n",
    "\n",
    "#################################################\n",
    "# Operation 2: split the text lines into words ##\n",
    "#################################################\n",
    "def get_words_from_line_list(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list = word_list + words_in_line\n",
    "    return word_list\n",
    "\n",
    "def get_words_from_string(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string,\n",
    "    converting each word to lower-case.\n",
    "\n",
    "    Input:  line (a string)\n",
    "    Output: a list of strings \n",
    "              (each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"\n",
    "    word_list = []          # accumulates words in line\n",
    "    character_list = []     # accumulates characters in word\n",
    "    emptysymb = \"\"\n",
    "    for c in line:\n",
    "        if c.isalnum():\n",
    "            character_list.append(c)\n",
    "        elif len(character_list)>0:\n",
    "            word = emptysymb.join(character_list)\n",
    "            word = word.lower()\n",
    "            word_list.append(word)\n",
    "            character_list = []\n",
    "    if len(character_list)>0:\n",
    "        word = emptysymb.join(character_list)\n",
    "        word = word.lower()\n",
    "        word_list.append(word)\n",
    "    return word_list\n",
    "\n",
    "##############################################\n",
    "# Operation 3: count frequency of each word ##\n",
    "##############################################\n",
    "def count_frequency(word_list):\n",
    "    \"\"\"\n",
    "    Return a list giving pairs of form: (word,frequency)\n",
    "    \"\"\"\n",
    "    L = []\n",
    "    for new_word in word_list:\n",
    "        for entry in L:\n",
    "            if new_word == entry[0]:\n",
    "                entry[1] = entry[1] + 1\n",
    "                break\n",
    "        else:\n",
    "            L.append([new_word,1])\n",
    "    return L\n",
    "\n",
    "###############################################################\n",
    "# Operation 4: sort words into alphabetic order             ###\n",
    "###############################################################\n",
    "def insertion_sort(A):\n",
    "    \"\"\"\n",
    "    Sort list A into order, in place.\n",
    "\n",
    "    From Cormen/Leiserson/Rivest/Stein,\n",
    "    Introduction to Algorithms (second edition), page 17,\n",
    "    modified to adjust for fact that Python arrays use \n",
    "    0-indexing.\n",
    "    \"\"\"\n",
    "    for j in range(len(A)):\n",
    "        key = A[j]\n",
    "        # insert A[j] into sorted sequence A[0..j-1]\n",
    "        i = j-1\n",
    "        while i>-1 and A[i]>key:\n",
    "            A[i+1] = A[i]\n",
    "            i = i-1\n",
    "        A[i+1] = key\n",
    "    return A\n",
    "    \n",
    "#############################################\n",
    "## compute word frequencies for input file ##\n",
    "#############################################\n",
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    insertion_sort(freq_mapping)\n",
    "\n",
    "    print (\"File\",filename,\":\",)\n",
    "    print (len(line_list),\"lines,\",)\n",
    "    print (len(word_list),\"words,\",)\n",
    "    print (len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping\n",
    "\n",
    "def inner_product(L1,L2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as alphabetically sorted (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product([[\"and\",3],[\"of\",2],[\"the\",5]],\n",
    "                           [[\"and\",4],[\"in\",1],[\"of\",1],[\"this\",2]]) = 14.0 \n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i<len(L1) and j<len(L2):\n",
    "        # L1[i:] and L2[j:] yet to be processed\n",
    "        if L1[i][0] == L2[j][0]:\n",
    "            # both vectors have this word\n",
    "            sum += L1[i][1] * L2[j][1]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif L1[i][0] < L2[j][0]:\n",
    "            # word L1[i][0] is in L1 but not L2\n",
    "            i += 1\n",
    "        else:\n",
    "            # word L2[j][0] is in L2 but not L1\n",
    "            j += 1\n",
    "    return sum\n",
    "\n",
    "def vector_angle(L1,L2):\n",
    "    \"\"\"\n",
    "    The input is a list of (word,freq) pairs, sorted alphabetically.\n",
    "\n",
    "    Return the angle between these two vectors.\n",
    "    \"\"\"\n",
    "    numerator = inner_product(L1,L2)\n",
    "    denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2))\n",
    "    return math.acos(numerator/denominator)\n",
    "\n",
    "def main1(filename_1,filename_2):\n",
    "    sorted_word_list_1 = word_frequencies_for_file(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(sorted_word_list_1,sorted_word_list_2)\n",
    "    print (\"The distance between the documents is: %0.6f (radians)\"%distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d52cf1",
   "metadata": {},
   "source": [
    "Testons le sur quelques fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcba2ee4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1 = \"./data/t1.verne.txt\" ## taille : 51 ko\n",
    "file2 = \"./data/t2.bobsey.txt\" ## taille : 256 ko\n",
    "file3 = \"./data/t3.lewis.txt\" ## taille : 1 Mo\n",
    "file4 = \"./data/t4.arabian.txt\" ## taille : 3 Mo\n",
    "file5 = \"./data/t5.churchill.txt\" ## taille : 9 Mo\n",
    "file6 = \"./data/t8.shakespeare.txt\" ## taille : 5 Mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be510d5c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/t3.lewis.txt :\n",
      "15996 lines,\n",
      "182355 words,\n",
      "8530 distinct words\n",
      "File ./data/t2.bobsey.txt :\n",
      "6667 lines,\n",
      "49785 words,\n",
      "3354 distinct words\n",
      "The distance between the documents is: 0.574160 (radians)\n"
     ]
    }
   ],
   "source": [
    "main1(file3,file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74779cb",
   "metadata": {},
   "source": [
    "Nous observons que le calcul est vite très lent... \n",
    "\n",
    "### 3. Deuxième version, pour chasser le coupable.\n",
    "\n",
    "Afin de déterminer les opérations qui prennent le plus de temps, nous ajoutons à la fin du programme la méthode de profiling qui permet de faire des rapports statistiques sur le nombre d'appels et le temps passé dans chaque sous-routine.\n",
    "\n",
    "#### Question 1. \n",
    "_D'après vous, qui est le coupable du temps passé à calculer ?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78f857f2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main2(filename_1,filename_2):\n",
    "    import profile\n",
    "    profile.run(\"main1('\"+filename_1+\"','\"+filename_2+\"')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38a643bb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/t2.bobsey.txt :\n",
      "6667 lines,\n",
      "49785 words,\n",
      "3354 distinct words\n",
      "File ./data/t3.lewis.txt :\n",
      "15996 lines,\n",
      "182355 words,\n",
      "8530 distinct words\n",
      "The distance between the documents is: 0.574160 (radians)\n",
      "         3352701 function calls in 33.011 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.001    0.001   32.947   16.474 3695471828.py:112(word_frequencies_for_file)\n",
      "        3    0.038    0.013    0.057    0.019 3695471828.py:130(inner_product)\n",
      "        1    0.000    0.000    0.057    0.057 3695471828.py:156(vector_angle)\n",
      "        2    0.000    0.000    0.004    0.002 3695471828.py:16(read_file)\n",
      "        1    0.004    0.004   33.009   33.009 3695471828.py:166(main1)\n",
      "        2   14.612    7.306   17.715    8.858 3695471828.py:32(get_words_from_line_list)\n",
      "    22663    1.660    0.000    3.104    0.000 3695471828.py:44(get_words_from_string)\n",
      "        2   11.347    5.674   11.353    5.677 3695471828.py:73(count_frequency)\n",
      "        2    3.873    1.937    3.873    1.937 3695471828.py:90(insertion_sort)\n",
      "       38    0.000    0.000    0.000    0.000 :0(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 :0(acos)\n",
      "        2    0.000    0.000    0.000    0.000 :0(acquire)\n",
      "  1241851    0.543    0.000    0.543    0.000 :0(append)\n",
      "        1    0.000    0.000   33.011   33.011 :0(exec)\n",
      "       38    0.000    0.000    0.000    0.000 :0(getpid)\n",
      "  1277585    0.556    0.000    0.556    0.000 :0(isalnum)\n",
      "       38    0.000    0.000    0.000    0.000 :0(isinstance)\n",
      "   232140    0.119    0.000    0.119    0.000 :0(join)\n",
      "   345688    0.145    0.000    0.145    0.000 :0(len)\n",
      "   232140    0.107    0.000    0.107    0.000 :0(lower)\n",
      "        2    0.000    0.000    0.000    0.000 :0(open)\n",
      "        9    0.000    0.000    0.001    0.000 :0(print)\n",
      "        2    0.003    0.001    0.003    0.002 :0(readlines)\n",
      "        1    0.000    0.000    0.000    0.000 :0(setprofile)\n",
      "        1    0.000    0.000    0.000    0.000 :0(sqrt)\n",
      "      158    0.000    0.000    0.000    0.000 :0(utf_8_decode)\n",
      "       38    0.000    0.000    0.000    0.000 :0(write)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "      158    0.000    0.000    0.001    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.002    0.002   33.010   33.010 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:437(_is_master_process)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:456(_schedule_flush)\n",
      "       38    0.000    0.000    0.001    0.000 iostream.py:526(write)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000   33.011   33.011 profile:0(main1('./data/t2.bobsey.txt','./data/t3.lewis.txt'))\n",
      "        0    0.000             0.000          profile:0(profiler)\n",
      "        2    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main2(file2,file3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04523c36",
   "metadata": {},
   "source": [
    "On observe que la routine passe le plus clair de son temps (colonne tottime' dans la méthode `get_words_from_line_list`). Observons cela de plus près."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959319e3",
   "metadata": {},
   "source": [
    "```\n",
    "def get_words_from_line_list(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        word_list = word_list + words_in_line\n",
    "    return word_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3718dfe",
   "metadata": {},
   "source": [
    "#### Question 2.\n",
    "\n",
    "_Qu'est-ce qui ne va pas ?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adcbb2a9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_from_line_list(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "\n",
    "# VOTRE CODE ICI !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d35c90",
   "metadata": {},
   "source": [
    "Et oui, la concaténation de liste est particulièrement laborieuse et prend un temps proportionnel à la somme des tailles des deux listes... Donc ajouter un à un les termes à la liste prend un temps $O(n^2)$ alors qu'avec append ou extend, on réduit drastiquement le temps de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e24b0c29",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/t2.bobsey.txt :\n",
      "6667 lines,\n",
      "49785 words,\n",
      "3354 distinct words\n",
      "File ./data/t3.lewis.txt :\n",
      "15996 lines,\n",
      "182355 words,\n",
      "8530 distinct words\n",
      "The distance between the documents is: 0.574160 (radians)\n",
      "         3375364 function calls in 15.528 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.023    0.011    2.743    1.371 2200860914.py:1(get_words_from_line_list)\n",
      "        2    0.000    0.000   15.468    7.734 3695471828.py:112(word_frequencies_for_file)\n",
      "        3    0.036    0.012    0.052    0.017 3695471828.py:130(inner_product)\n",
      "        1    0.000    0.000    0.052    0.052 3695471828.py:156(vector_angle)\n",
      "        2    0.000    0.000    0.002    0.001 3695471828.py:16(read_file)\n",
      "        1    0.005    0.005   15.526   15.526 3695471828.py:166(main1)\n",
      "    22663    1.445    0.000    2.710    0.000 3695471828.py:44(get_words_from_string)\n",
      "        2    9.927    4.964    9.933    4.967 3695471828.py:73(count_frequency)\n",
      "        2    2.789    1.395    2.789    1.395 3695471828.py:90(insertion_sort)\n",
      "       38    0.000    0.000    0.000    0.000 :0(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 :0(acos)\n",
      "        2    0.000    0.000    0.000    0.000 :0(acquire)\n",
      "  1241851    0.477    0.000    0.477    0.000 :0(append)\n",
      "        1    0.000    0.000   15.528   15.528 :0(exec)\n",
      "    22663    0.010    0.000    0.010    0.000 :0(extend)\n",
      "       38    0.000    0.000    0.000    0.000 :0(getpid)\n",
      "  1277585    0.487    0.000    0.487    0.000 :0(isalnum)\n",
      "       38    0.000    0.000    0.000    0.000 :0(isinstance)\n",
      "   232140    0.102    0.000    0.102    0.000 :0(join)\n",
      "   345688    0.127    0.000    0.127    0.000 :0(len)\n",
      "   232140    0.093    0.000    0.093    0.000 :0(lower)\n",
      "        2    0.000    0.000    0.000    0.000 :0(open)\n",
      "        9    0.000    0.000    0.001    0.000 :0(print)\n",
      "        2    0.001    0.001    0.002    0.001 :0(readlines)\n",
      "        1    0.000    0.000    0.000    0.000 :0(setprofile)\n",
      "        1    0.000    0.000    0.000    0.000 :0(sqrt)\n",
      "      158    0.000    0.000    0.000    0.000 :0(utf_8_decode)\n",
      "       38    0.000    0.000    0.000    0.000 :0(write)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "      158    0.000    0.000    0.000    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.002    0.002   15.528   15.528 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:437(_is_master_process)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:456(_schedule_flush)\n",
      "       38    0.000    0.000    0.001    0.000 iostream.py:526(write)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000   15.528   15.528 profile:0(main1('./data/t2.bobsey.txt','./data/t3.lewis.txt'))\n",
      "        0    0.000             0.000          profile:0(profiler)\n",
      "        2    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main2(file2,file3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9717af7c",
   "metadata": {},
   "source": [
    "On vient de gagner la moitié du temps de calcul. \n",
    "\n",
    "#### Question 4. \n",
    "_Qui est le coupable suivant ? Comment l'améliorer ?_\n",
    "\n",
    "Il s'agit de `count_frequency` qui prend plus de la moitié du temps de calcul. Pour l'instant il ressemble à ça :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cacb7e1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_frequency(word_list):\n",
    "    \"\"\"\n",
    "    Return a list giving pairs of form: (word,frequency)\n",
    "    \"\"\"\n",
    "    L = []\n",
    "    for new_word in word_list:\n",
    "        for entry in L:\n",
    "            if new_word == entry[0]:\n",
    "                entry[1] = entry[1] + 1\n",
    "                break\n",
    "        else:\n",
    "            L.append([new_word,1])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49429b1b",
   "metadata": {},
   "source": [
    "Il cherche à chaque fois dans la liste en un temps linéaire. Les dictionnaires (et leurs tables de hachage) peuvent nous aider à gérer cette situation bien plus vite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8690f4a6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_frequency(word_list):\n",
    "    \"\"\"\n",
    "    Return a list giving pairs of form: (word,frequency)\n",
    "    \"\"\"\n",
    "    \n",
    "    # VOTRE CODE ICI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e052288",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/t2.bobsey.txt :\n",
      "6667 lines,\n",
      "49785 words,\n",
      "3354 distinct words\n",
      "File ./data/t3.lewis.txt :\n",
      "15996 lines,\n",
      "182355 words,\n",
      "8530 distinct words\n",
      "The distance between the documents is: 0.574160 (radians)\n",
      "         3363482 function calls in 5.208 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.022    0.011    2.676    1.338 2200860914.py:1(get_words_from_line_list)\n",
      "        2    0.000    0.000    5.162    2.581 3695471828.py:112(word_frequencies_for_file)\n",
      "        3    0.026    0.009    0.041    0.014 3695471828.py:130(inner_product)\n",
      "        1    0.000    0.000    0.041    0.041 3695471828.py:156(vector_angle)\n",
      "        2    0.000    0.000    0.006    0.003 3695471828.py:16(read_file)\n",
      "        1    0.004    0.004    5.207    5.207 3695471828.py:166(main1)\n",
      "    22663    1.420    0.000    2.645    0.000 3695471828.py:44(get_words_from_string)\n",
      "        2    2.448    1.224    2.448    1.224 3695471828.py:90(insertion_sort)\n",
      "        2    0.031    0.015    0.031    0.015 3755543530.py:1(count_frequency)\n",
      "       38    0.000    0.000    0.000    0.000 :0(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 :0(acos)\n",
      "        2    0.000    0.000    0.000    0.000 :0(acquire)\n",
      "  1229967    0.457    0.000    0.457    0.000 :0(append)\n",
      "        1    0.000    0.000    5.208    5.208 :0(exec)\n",
      "    22663    0.009    0.000    0.009    0.000 :0(extend)\n",
      "       38    0.000    0.000    0.000    0.000 :0(getpid)\n",
      "  1277585    0.472    0.000    0.472    0.000 :0(isalnum)\n",
      "       38    0.000    0.000    0.000    0.000 :0(isinstance)\n",
      "        2    0.000    0.000    0.000    0.000 :0(items)\n",
      "   232140    0.098    0.000    0.098    0.000 :0(join)\n",
      "   345688    0.123    0.000    0.123    0.000 :0(len)\n",
      "   232140    0.090    0.000    0.090    0.000 :0(lower)\n",
      "        2    0.001    0.000    0.001    0.000 :0(open)\n",
      "        9    0.000    0.000    0.000    0.000 :0(print)\n",
      "        2    0.004    0.002    0.005    0.002 :0(readlines)\n",
      "        1    0.000    0.000    0.000    0.000 :0(setprofile)\n",
      "        1    0.000    0.000    0.000    0.000 :0(sqrt)\n",
      "      158    0.000    0.000    0.000    0.000 :0(utf_8_decode)\n",
      "       38    0.000    0.000    0.000    0.000 :0(write)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "      158    0.001    0.000    0.001    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.001    0.001    5.208    5.208 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:437(_is_master_process)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:456(_schedule_flush)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:526(write)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    5.208    5.208 profile:0(main1('./data/t2.bobsey.txt','./data/t3.lewis.txt'))\n",
      "        0    0.000             0.000          profile:0(profiler)\n",
      "        2    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main2(file2,file3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd16f36",
   "metadata": {},
   "source": [
    "Encore un facteur 3 de gagné sur le temps total !\n",
    "\n",
    "Les deux derniers gros morceaux sont `get_words_from_string` et `insertion_sort`. Comment les améliorer ? Actuellement, `get_words_from_string` ressemble à ça."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c004e8d5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_from_string(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string,\n",
    "    converting each word to lower-case.\n",
    "\n",
    "    Input:  line (a string)\n",
    "    Output: a list of strings \n",
    "              (each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"\n",
    "    word_list = []          # accumulates words in line\n",
    "    character_list = []     # accumulates characters in word\n",
    "    emptysymb = \"\"\n",
    "    for c in line:\n",
    "        if c.isalnum():\n",
    "            character_list.append(c)\n",
    "        elif len(character_list)>0:\n",
    "            word = emptysymb.join(character_list)\n",
    "            word = word.lower()\n",
    "            word_list.append(word)\n",
    "            character_list = []\n",
    "    if len(character_list)>0:\n",
    "        word = emptysymb.join(character_list)\n",
    "        word = word.lower()\n",
    "        word_list.append(word)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebf965b",
   "metadata": {},
   "source": [
    "On va utiliser ```translate``` qui permet de transformer à la voler les caractères selon une table de traduction que l'on peut définir comme il nous sied. Ici, on veut remplacer les signes de ponctuation par des espaces et les lettres majuscules par leurs version en minuscules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa3cc2f2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intab = string.punctuation+string.ascii_uppercase\n",
    "outtab = \" \"*len(string.punctuation)+string.ascii_lowercase\n",
    "\n",
    "tab = str.maketrans(intab,outtab)\n",
    "\n",
    "def get_words_from_string(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string,\n",
    "    converting each word to lower-case.\n",
    "\n",
    "    Input:  line (a string)\n",
    "    Output: a list of strings \n",
    "              (each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"\n",
    "    line = line.translate(tab)\n",
    "    word_list = line.split()\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1231bbc3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/t2.bobsey.txt :\n",
      "6667 lines,\n",
      "49785 words,\n",
      "3354 distinct words\n",
      "File ./data/t3.lewis.txt :\n",
      "15996 lines,\n",
      "182355 words,\n",
      "8530 distinct words\n",
      "The distance between the documents is: 0.574160 (radians)\n",
      "         134555 function calls in 2.589 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.022    0.011    0.106    0.053 2200860914.py:1(get_words_from_line_list)\n",
      "        2    0.000    0.000    2.543    1.272 3695471828.py:112(word_frequencies_for_file)\n",
      "        3    0.026    0.009    0.041    0.014 3695471828.py:130(inner_product)\n",
      "        1    0.000    0.000    0.041    0.041 3695471828.py:156(vector_angle)\n",
      "        2    0.000    0.000    0.003    0.001 3695471828.py:16(read_file)\n",
      "        1    0.003    0.003    2.588    2.588 3695471828.py:166(main1)\n",
      "        2    2.402    1.201    2.402    1.201 3695471828.py:90(insertion_sort)\n",
      "        2    0.032    0.016    0.032    0.016 3755543530.py:1(count_frequency)\n",
      "    22663    0.030    0.000    0.074    0.000 401727528.py:6(get_words_from_string)\n",
      "       38    0.000    0.000    0.000    0.000 :0(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 :0(acos)\n",
      "        2    0.000    0.000    0.000    0.000 :0(acquire)\n",
      "        2    0.000    0.000    0.000    0.000 :0(append)\n",
      "        1    0.000    0.000    2.589    2.589 :0(exec)\n",
      "    22663    0.009    0.000    0.009    0.000 :0(extend)\n",
      "       38    0.000    0.000    0.000    0.000 :0(getpid)\n",
      "       38    0.000    0.000    0.000    0.000 :0(isinstance)\n",
      "        2    0.000    0.000    0.000    0.000 :0(items)\n",
      "    43265    0.016    0.000    0.016    0.000 :0(len)\n",
      "        2    0.001    0.000    0.001    0.000 :0(open)\n",
      "        9    0.000    0.000    0.000    0.000 :0(print)\n",
      "        2    0.001    0.001    0.002    0.001 :0(readlines)\n",
      "        1    0.000    0.000    0.000    0.000 :0(setprofile)\n",
      "    22663    0.018    0.000    0.018    0.000 :0(split)\n",
      "        1    0.000    0.000    0.000    0.000 :0(sqrt)\n",
      "    22663    0.027    0.000    0.027    0.000 :0(translate)\n",
      "      158    0.000    0.000    0.000    0.000 :0(utf_8_decode)\n",
      "       38    0.000    0.000    0.000    0.000 :0(write)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "      158    0.000    0.000    0.000    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.001    0.001    2.589    2.589 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:437(_is_master_process)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:456(_schedule_flush)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:526(write)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    2.589    2.589 profile:0(main1('./data/t2.bobsey.txt','./data/t3.lewis.txt'))\n",
      "        0    0.000             0.000          profile:0(profiler)\n",
      "        2    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main2(file2,file3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9f2deb",
   "metadata": {},
   "source": [
    "Le dernier problème à régler est insertion_sort. Mais on sait que c'est nul !  Alors on fait un bon petit merge_sort et tout ira bien !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf87c689",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_sort(A):\n",
    "  \n",
    "    # VOTRE CODE ICI\n",
    "\n",
    "def merge(L,R):\n",
    "\n",
    "    # VOTRE CODE ICI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2041039c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "## compute word frequencies for input file ##\n",
    "#############################################\n",
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "    merge_sort(freq_mapping)\n",
    "\n",
    "    print (\"File\",filename,\":\",)\n",
    "    print (len(line_list),\"lines,\",)\n",
    "    print (len(word_list),\"words,\",)\n",
    "    print (len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09cb4536",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/t2.bobsey.txt :\n",
      "6667 lines,\n",
      "49785 words,\n",
      "3354 distinct words\n",
      "File ./data/t3.lewis.txt :\n",
      "15996 lines,\n",
      "182355 words,\n",
      "8530 distinct words\n",
      "The distance between the documents is: 1.123077 (radians)\n",
      "         652339 function calls (628575 primitive calls) in 0.638 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        2    0.022    0.011    0.107    0.054 2200860914.py:1(get_words_from_line_list)\n",
      "  23766/2    0.041    0.000    0.451    0.226 298243687.py:1(merge_sort)\n",
      "    11882    0.230    0.000    0.402    0.000 298243687.py:13(merge)\n",
      "        3    0.023    0.008    0.039    0.013 3695471828.py:130(inner_product)\n",
      "        1    0.000    0.000    0.039    0.039 3695471828.py:156(vector_angle)\n",
      "        2    0.000    0.000    0.003    0.001 3695471828.py:16(read_file)\n",
      "        1    0.004    0.004    0.637    0.637 3695471828.py:166(main1)\n",
      "        2    0.033    0.016    0.033    0.016 3755543530.py:1(count_frequency)\n",
      "    22663    0.030    0.000    0.075    0.000 401727528.py:6(get_words_from_string)\n",
      "        2    0.000    0.000    0.595    0.297 4224529285.py:4(word_frequencies_for_file)\n",
      "       38    0.000    0.000    0.000    0.000 :0(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 :0(acos)\n",
      "        2    0.000    0.000    0.000    0.000 :0(acquire)\n",
      "   135808    0.051    0.000    0.051    0.000 :0(append)\n",
      "        1    0.000    0.000    0.638    0.638 :0(exec)\n",
      "    34545    0.014    0.000    0.014    0.000 :0(extend)\n",
      "       38    0.000    0.000    0.000    0.000 :0(getpid)\n",
      "       38    0.000    0.000    0.000    0.000 :0(isinstance)\n",
      "        2    0.000    0.000    0.000    0.000 :0(items)\n",
      "   377715    0.140    0.000    0.140    0.000 :0(len)\n",
      "        2    0.000    0.000    0.000    0.000 :0(open)\n",
      "        9    0.000    0.000    0.000    0.000 :0(print)\n",
      "        2    0.002    0.001    0.003    0.001 :0(readlines)\n",
      "        1    0.000    0.000    0.000    0.000 :0(setprofile)\n",
      "    22663    0.018    0.000    0.018    0.000 :0(split)\n",
      "        1    0.000    0.000    0.000    0.000 :0(sqrt)\n",
      "    22663    0.027    0.000    0.027    0.000 :0(translate)\n",
      "      158    0.000    0.000    0.000    0.000 :0(utf_8_decode)\n",
      "       38    0.000    0.000    0.000    0.000 :0(write)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "      158    0.000    0.000    0.000    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.001    0.001    0.638    0.638 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:437(_is_master_process)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:456(_schedule_flush)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:526(write)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    0.638    0.638 profile:0(main1('./data/t2.bobsey.txt','./data/t3.lewis.txt'))\n",
      "        0    0.000             0.000          profile:0(profiler)\n",
      "        2    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main2(file2,file3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4111586",
   "metadata": {},
   "source": [
    "Est-ce que vous pouvez vous passer complétement du tri ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bae9dfec",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "\n",
    "    print (\"File\",filename,\":\",)\n",
    "    print (len(line_list),\"lines,\",)\n",
    "    print (len(word_list),\"words,\",)\n",
    "    print (len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping\n",
    "\n",
    "def inner_product(D1,D2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as dictionaries of (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product({\"and\":3,\"of\":2,\"the\":5},\n",
    "                           {\"and\":4,\"in\":1,\"of\":1,\"this\":2}) = 14.0\n",
    "    \"\"\"\n",
    "   \n",
    "    # VOTRE CODE ICI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce8802",
   "metadata": {},
   "source": [
    "### Programme final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e5f1a04",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "    # math.acos(x) is the arccosine of x.\n",
    "    # math.sqrt(x) is the square root of x.\n",
    "\n",
    "import string\n",
    "    # string.join(words,sep) takes a given list of words,\n",
    "    #    and returns a single string resulting from concatenating them\n",
    "    #    together, separated by the string sep .\n",
    "    # string.lower(word) converts word to lower-case\n",
    "\n",
    "##################################\n",
    "# Operation 1: read a text file ##\n",
    "##################################\n",
    "def read_file(filename):\n",
    "    \"\"\" \n",
    "    Read the text file with the given filename;\n",
    "    return a list of the lines of text in the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fp = open(filename)\n",
    "        L = fp.readlines()\n",
    "    except IOError:\n",
    "        print (\"Error opening or reading input file: \",filename)\n",
    "    return L\n",
    "\n",
    "#################################################\n",
    "# Operation 2: split the text lines into words ##\n",
    "#################################################\n",
    "def get_words_from_line_list(L):\n",
    "    \"\"\"\n",
    "    Parse the given list L of text lines into words.\n",
    "    Return list of all words found.\n",
    "    \"\"\"\n",
    "\n",
    "    word_list = []\n",
    "    for line in L:\n",
    "        words_in_line = get_words_from_string(line)\n",
    "        # Using \"extend\" is much more efficient than concatenation here:\n",
    "        word_list.extend(words_in_line)\n",
    "    return word_list\n",
    "\n",
    "intab = string.punctuation+string.ascii_uppercase\n",
    "outtab = \" \"*len(string.punctuation)+string.ascii_lowercase\n",
    "\n",
    "tab = str.maketrans(intab,outtab)\n",
    "\n",
    "def get_words_from_string(line):\n",
    "    \"\"\"\n",
    "    Return a list of the words in the given input string,\n",
    "    converting each word to lower-case.\n",
    "\n",
    "    Input:  line (a string)\n",
    "    Output: a list of strings \n",
    "              (each string is a sequence of alphanumeric characters)\n",
    "    \"\"\"\n",
    "    line = line.translate(tab)\n",
    "    word_list = line.split()\n",
    "    return word_list\n",
    "\n",
    "##############################################\n",
    "# Operation 3: count frequency of each word ##\n",
    "##############################################\n",
    "def count_frequency(word_list):\n",
    "    \"\"\"\n",
    "    Return a dictionary mapping words to frequency.\n",
    "    \"\"\"\n",
    "    D = {}\n",
    "    for new_word in word_list:\n",
    "        if new_word in D:\n",
    "            D[new_word] = D[new_word]+1\n",
    "        else:\n",
    "            D[new_word] = 1\n",
    "    return D\n",
    "\n",
    "    \n",
    "#############################################\n",
    "## compute word frequencies for input file ##\n",
    "#############################################\n",
    "def word_frequencies_for_file(filename):\n",
    "    \"\"\"\n",
    "    Return alphabetically sorted list of (word,frequency) pairs \n",
    "    for the given file.\n",
    "    \"\"\"\n",
    "\n",
    "    line_list = read_file(filename)\n",
    "    word_list = get_words_from_line_list(line_list)\n",
    "    freq_mapping = count_frequency(word_list)\n",
    "\n",
    "    print (\"File\",filename,\":\",)\n",
    "    print (len(line_list),\"lines,\",)\n",
    "    print (len(word_list),\"words,\",)\n",
    "    print (len(freq_mapping),\"distinct words\")\n",
    "\n",
    "    return freq_mapping\n",
    "\n",
    "\n",
    "def inner_product(D1,D2):\n",
    "    \"\"\"\n",
    "    Inner product between two vectors, where vectors\n",
    "    are represented as dictionaries of (word,freq) pairs.\n",
    "\n",
    "    Example: inner_product({\"and\":3,\"of\":2,\"the\":5},\n",
    "                           {\"and\":4,\"in\":1,\"of\":1,\"this\":2}) = 14.0\n",
    "    \"\"\"\n",
    "    sum = 0.0\n",
    "    for key in D1:\n",
    "        if key in D2:\n",
    "            sum += D1[key] * D2[key]\n",
    "    return sum\n",
    "\n",
    "\n",
    "def vector_angle(L1,L2):\n",
    "    \"\"\"\n",
    "    The input is a list of (word,freq) pairs, sorted alphabetically.\n",
    "\n",
    "    Return the angle between these two vectors.\n",
    "    \"\"\"\n",
    "    numerator = inner_product(L1,L2)\n",
    "    denominator = math.sqrt(inner_product(L1,L1)*inner_product(L2,L2))\n",
    "    return math.acos(numerator/denominator)\n",
    "\n",
    "def main1(filename_1,filename_2):\n",
    "    sorted_word_list_1 = word_frequencies_for_file(filename_1)\n",
    "    sorted_word_list_2 = word_frequencies_for_file(filename_2)\n",
    "    distance = vector_angle(sorted_word_list_1,sorted_word_list_2)\n",
    "    print (\"The distance between the documents is: %0.6f (radians)\"%distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a03f25fa",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/t2.bobsey.txt :\n",
      "6667 lines,\n",
      "49785 words,\n",
      "3354 distinct words\n",
      "File ./data/t3.lewis.txt :\n",
      "15996 lines,\n",
      "182355 words,\n",
      "8530 distinct words\n",
      "The distance between the documents is: 0.574160 (radians)\n",
      "         91330 function calls in 0.164 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.004    0.004 4225794408.py:112(vector_angle)\n",
      "        1    0.005    0.005    0.164    0.164 4225794408.py:122(main1)\n",
      "        2    0.000    0.000    0.003    0.002 4225794408.py:14(read_file)\n",
      "        2    0.026    0.013    0.124    0.062 4225794408.py:29(get_words_from_line_list)\n",
      "    22663    0.035    0.000    0.087    0.000 4225794408.py:47(get_words_from_string)\n",
      "        2    0.027    0.014    0.027    0.014 4225794408.py:63(count_frequency)\n",
      "        2    0.000    0.000    0.155    0.078 4225794408.py:79(word_frequencies_for_file)\n",
      "        3    0.004    0.001    0.004    0.001 4225794408.py:97(inner_product)\n",
      "       38    0.000    0.000    0.000    0.000 :0(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 :0(acos)\n",
      "        2    0.000    0.000    0.000    0.000 :0(acquire)\n",
      "        2    0.000    0.000    0.000    0.000 :0(append)\n",
      "        1    0.000    0.000    0.164    0.164 :0(exec)\n",
      "    22663    0.011    0.000    0.011    0.000 :0(extend)\n",
      "       38    0.000    0.000    0.000    0.000 :0(getpid)\n",
      "       38    0.000    0.000    0.000    0.000 :0(isinstance)\n",
      "       44    0.000    0.000    0.000    0.000 :0(len)\n",
      "        2    0.001    0.000    0.001    0.000 :0(open)\n",
      "        9    0.000    0.000    0.001    0.000 :0(print)\n",
      "        2    0.002    0.001    0.003    0.001 :0(readlines)\n",
      "        1    0.000    0.000    0.000    0.000 :0(setprofile)\n",
      "    22663    0.020    0.000    0.020    0.000 :0(split)\n",
      "        1    0.000    0.000    0.000    0.000 :0(sqrt)\n",
      "    22663    0.032    0.000    0.032    0.000 :0(translate)\n",
      "      158    0.000    0.000    0.000    0.000 :0(utf_8_decode)\n",
      "       38    0.000    0.000    0.000    0.000 :0(write)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "      158    0.000    0.000    0.000    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.000    0.000    0.164    0.164 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:437(_is_master_process)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:456(_schedule_flush)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:526(write)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    0.164    0.164 profile:0(main1('./data/t2.bobsey.txt','./data/t3.lewis.txt'))\n",
      "        0    0.000             0.000          profile:0(profiler)\n",
      "        2    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main2(file2,file3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007a84bd",
   "metadata": {},
   "source": [
    "On a amélioré par un facteur 200 notre programme pour notre exemple. Et surtout on est passé en linéaire ! On peut désormais calculer la distance entre Churchill et Shakespeare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "025e19f4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./data/t5.churchill.txt :\n",
      "189685 lines,\n",
      "1717247 words,\n",
      "32544 distinct words\n",
      "File ./data/t8.shakespeare.txt :\n",
      "124456 lines,\n",
      "929462 words,\n",
      "23881 distinct words\n",
      "The distance between the documents is: 0.462095 (radians)\n",
      "         1260548 function calls in 1.841 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.022    0.022 4225794408.py:112(vector_angle)\n",
      "        1    0.044    0.044    1.834    1.834 4225794408.py:122(main1)\n",
      "        2    0.000    0.000    0.023    0.011 4225794408.py:14(read_file)\n",
      "        2    0.301    0.150    1.417    0.708 4225794408.py:29(get_words_from_line_list)\n",
      "   314141    0.409    0.000    0.983    0.000 4225794408.py:47(get_words_from_string)\n",
      "        2    0.328    0.164    0.328    0.164 4225794408.py:63(count_frequency)\n",
      "        2    0.000    0.000    1.768    0.884 4225794408.py:79(word_frequencies_for_file)\n",
      "        3    0.022    0.007    0.022    0.007 4225794408.py:97(inner_product)\n",
      "       38    0.000    0.000    0.000    0.000 :0(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 :0(acos)\n",
      "        2    0.000    0.000    0.000    0.000 :0(acquire)\n",
      "        2    0.000    0.000    0.000    0.000 :0(append)\n",
      "        1    0.000    0.000    1.841    1.841 :0(exec)\n",
      "   314141    0.133    0.000    0.133    0.000 :0(extend)\n",
      "       38    0.000    0.000    0.000    0.000 :0(getpid)\n",
      "       38    0.000    0.000    0.000    0.000 :0(isinstance)\n",
      "       44    0.000    0.000    0.000    0.000 :0(len)\n",
      "        2    0.001    0.000    0.001    0.000 :0(open)\n",
      "        9    0.000    0.000    0.000    0.000 :0(print)\n",
      "        2    0.018    0.009    0.022    0.011 :0(readlines)\n",
      "        1    0.000    0.000    0.000    0.000 :0(setprofile)\n",
      "   314141    0.218    0.000    0.218    0.000 :0(split)\n",
      "        1    0.000    0.000    0.000    0.000 :0(sqrt)\n",
      "   314141    0.356    0.000    0.356    0.000 :0(translate)\n",
      "     1811    0.002    0.000    0.002    0.000 :0(utf_8_decode)\n",
      "       38    0.000    0.000    0.000    0.000 :0(write)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "     1811    0.002    0.000    0.004    0.000 <frozen codecs>:319(decode)\n",
      "        1    0.007    0.007    1.841    1.841 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:202(schedule)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:437(_is_master_process)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:456(_schedule_flush)\n",
      "       38    0.000    0.000    0.000    0.000 iostream.py:526(write)\n",
      "        2    0.000    0.000    0.000    0.000 iostream.py:90(_event_pipe)\n",
      "        1    0.000    0.000    1.841    1.841 profile:0(main1('./data/t5.churchill.txt','./data/t8.shakespeare.txt'))\n",
      "        0    0.000             0.000          profile:0(profiler)\n",
      "        2    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main2(file5,file6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

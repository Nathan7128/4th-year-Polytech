{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importating libraries\n",
    "\n",
    "import numpy as np\n",
    "from keras import models, losses, layers, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter = \",\")\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "X = dataset[:, :-1]\n",
    "y = dataset[:, -1]\n",
    "mean = X.mean(axis = 0)\n",
    "std = X.std(axis = 0)\n",
    "X = (X - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Basic neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\Documents\\GitHub\\4th year Polytech\\Deep Learning\\env_deep_learning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - binary_accuracy: 0.3555 - loss: 0.9648 - val_binary_accuracy: 0.5118 - val_loss: 0.7228\n",
      "Epoch 2/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.5654 - loss: 0.6790 - val_binary_accuracy: 0.7205 - val_loss: 0.5981\n",
      "Epoch 3/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.6411 - loss: 0.6091 - val_binary_accuracy: 0.7165 - val_loss: 0.5408\n",
      "Epoch 4/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.6983 - loss: 0.5470 - val_binary_accuracy: 0.7362 - val_loss: 0.5169\n",
      "Epoch 5/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.6742 - loss: 0.5960 - val_binary_accuracy: 0.7402 - val_loss: 0.4979\n",
      "Epoch 6/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.7235 - loss: 0.5234 - val_binary_accuracy: 0.7520 - val_loss: 0.4914\n",
      "Epoch 7/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.7215 - loss: 0.5158 - val_binary_accuracy: 0.7638 - val_loss: 0.4827\n",
      "Epoch 8/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.7482 - loss: 0.5316 - val_binary_accuracy: 0.7717 - val_loss: 0.4782\n",
      "Epoch 9/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7547 - loss: 0.5165 - val_binary_accuracy: 0.7795 - val_loss: 0.4712\n",
      "Epoch 10/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.7326 - loss: 0.5358 - val_binary_accuracy: 0.7992 - val_loss: 0.4664\n",
      "Epoch 11/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.7487 - loss: 0.5184 - val_binary_accuracy: 0.7953 - val_loss: 0.4640\n",
      "Epoch 12/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7460 - loss: 0.5259 - val_binary_accuracy: 0.7953 - val_loss: 0.4582\n",
      "Epoch 13/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7842 - loss: 0.4934 - val_binary_accuracy: 0.7913 - val_loss: 0.4564\n",
      "Epoch 14/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7678 - loss: 0.5189 - val_binary_accuracy: 0.7913 - val_loss: 0.4535\n",
      "Epoch 15/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.7553 - loss: 0.4941 - val_binary_accuracy: 0.7795 - val_loss: 0.4515\n",
      "Epoch 16/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7374 - loss: 0.5152 - val_binary_accuracy: 0.7913 - val_loss: 0.4487\n",
      "Epoch 17/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7658 - loss: 0.4799 - val_binary_accuracy: 0.7835 - val_loss: 0.4475\n",
      "Epoch 18/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - binary_accuracy: 0.7588 - loss: 0.4853 - val_binary_accuracy: 0.7874 - val_loss: 0.4477\n",
      "Epoch 19/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7534 - loss: 0.5008 - val_binary_accuracy: 0.7874 - val_loss: 0.4466\n",
      "Epoch 20/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7843 - loss: 0.4743 - val_binary_accuracy: 0.8031 - val_loss: 0.4429\n",
      "Epoch 21/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8075 - loss: 0.4560 - val_binary_accuracy: 0.7874 - val_loss: 0.4475\n",
      "Epoch 22/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.7634 - loss: 0.4732 - val_binary_accuracy: 0.7913 - val_loss: 0.4442\n",
      "Epoch 23/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.7723 - loss: 0.4478 - val_binary_accuracy: 0.7992 - val_loss: 0.4425\n",
      "Epoch 24/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - binary_accuracy: 0.7511 - loss: 0.4790 - val_binary_accuracy: 0.7953 - val_loss: 0.4371\n",
      "Epoch 25/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7770 - loss: 0.4532 - val_binary_accuracy: 0.7953 - val_loss: 0.4372\n",
      "Epoch 26/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8007 - loss: 0.4550 - val_binary_accuracy: 0.7913 - val_loss: 0.4400\n",
      "Epoch 27/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7595 - loss: 0.4776 - val_binary_accuracy: 0.7913 - val_loss: 0.4365\n",
      "Epoch 28/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.8212 - loss: 0.4483 - val_binary_accuracy: 0.7953 - val_loss: 0.4362\n",
      "Epoch 29/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7652 - loss: 0.4561 - val_binary_accuracy: 0.7953 - val_loss: 0.4343\n",
      "Epoch 30/30\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.7563 - loss: 0.5007 - val_binary_accuracy: 0.7913 - val_loss: 0.4312\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "# create model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation = \"relu\", input_dim = 8))\n",
    "model.add(layers.Dense(16, activation = \"exponential\"))\n",
    "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='rmsprop',loss=losses.BinaryCrossentropy(),metrics=[metrics.BinaryAccuracy()])\n",
    "\n",
    "# fit model\n",
    "hist = model.fit(X, y, validation_split = 0.33, epochs = 30, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and validation loss')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss and validation loss curves\n",
    "\n",
    "loss = hist.history[\"loss\"]\n",
    "val_loss = hist.history[\"val_loss\"]\n",
    "ep = range(1, len(loss) + 1)\n",
    "plt.plot(ep, loss, \"r-\")\n",
    "plt.plot(ep, val_loss, \"b-\")\n",
    "plt.title(\"Training and validation loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Neural networks with K-Fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters\n",
    "params = {\"N1\" : 32, \"N2\" : 32, \"act1\" : \"relu\", \"act2\" : \"relu\", \"opt\" : \"adam\", \"loss\" : losses.BinaryCrossentropy(),\n",
    "          \"epochs\" : 200, \"batch_size\" : 5}\n",
    "\n",
    "def create_model(X, y) :\n",
    "    \"\"\"create and return model\"\"\"\n",
    "\n",
    "    # create model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(params[\"N1\"], activation = params[\"act1\"], input_dim = 8))\n",
    "    model.add(layers.Dense(params[\"N2\"], activation = params[\"act2\"]))\n",
    "    # model.add(layers.Dense(params[\"N3\"], activation = params[\"act3\"]))\n",
    "    model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=params[\"opt\"],loss=params[\"loss\"],metrics=[\"accuracy\"])\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X, y, validation_split = 0, epochs = params[\"epochs\"], batch_size = params[\"batch_size\"], verbose = 0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\Documents\\GitHub\\4th year Polytech\\Deep Learning\\env_deep_learning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile_metrics 62.337660789489746\n",
      "compile_metrics 67.53246784210205\n",
      "compile_metrics 74.02597665786743\n",
      "compile_metrics 71.42857313156128\n",
      "compile_metrics 70.1298713684082\n",
      "compile_metrics 76.6233742237091\n",
      "compile_metrics 84.41558480262756\n",
      "compile_metrics 74.02597665786743\n",
      "compile_metrics 68.42105388641357\n",
      "compile_metrics 63.15789222717285\n",
      "average accuracy and standard deviation: 71.20984315872192 6.20985746388507\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N1</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N2</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N3</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act1</th>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2</th>\n",
       "      <td>exponential</td>\n",
       "      <td>exponential</td>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act3</th>\n",
       "      <td>relu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt</th>\n",
       "      <td>adam</td>\n",
       "      <td>adam</td>\n",
       "      <td>adam</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>&lt;keras.src.losses.losses.BinaryCrossentropy ob...</td>\n",
       "      <td>&lt;keras.src.losses.losses.BinaryCrossentropy ob...</td>\n",
       "      <td>&lt;keras.src.losses.losses.BinaryCrossentropy ob...</td>\n",
       "      <td>&lt;keras.src.losses.losses.BinaryCrossentropy ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epochs</th>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>74.210527</td>\n",
       "      <td>75.909091</td>\n",
       "      <td>75.252905</td>\n",
       "      <td>71.209843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            0  \\\n",
       "N1                                                         12   \n",
       "N2                                                         16   \n",
       "N3                                                          8   \n",
       "act1                                                     relu   \n",
       "act2                                              exponential   \n",
       "act3                                                     relu   \n",
       "opt                                                      adam   \n",
       "loss        <keras.src.losses.losses.BinaryCrossentropy ob...   \n",
       "epochs                                                    100   \n",
       "batch_size                                                 10   \n",
       "accuracy                                            74.210527   \n",
       "\n",
       "                                                            0  \\\n",
       "N1                                                         12   \n",
       "N2                                                         16   \n",
       "N3                                                        NaN   \n",
       "act1                                                     relu   \n",
       "act2                                              exponential   \n",
       "act3                                                      NaN   \n",
       "opt                                                      adam   \n",
       "loss        <keras.src.losses.losses.BinaryCrossentropy ob...   \n",
       "epochs                                                     50   \n",
       "batch_size                                                  5   \n",
       "accuracy                                            75.909091   \n",
       "\n",
       "                                                            0  \\\n",
       "N1                                                         32   \n",
       "N2                                                         16   \n",
       "N3                                                        NaN   \n",
       "act1                                                     relu   \n",
       "act2                                                     relu   \n",
       "act3                                                      NaN   \n",
       "opt                                                      adam   \n",
       "loss        <keras.src.losses.losses.BinaryCrossentropy ob...   \n",
       "epochs                                                     50   \n",
       "batch_size                                                  5   \n",
       "accuracy                                            75.252905   \n",
       "\n",
       "                                                            0  \n",
       "N1                                                         32  \n",
       "N2                                                         32  \n",
       "N3                                                        NaN  \n",
       "act1                                                     relu  \n",
       "act2                                                     relu  \n",
       "act3                                                      NaN  \n",
       "opt                                                      adam  \n",
       "loss        <keras.src.losses.losses.BinaryCrossentropy ob...  \n",
       "epochs                                                    200  \n",
       "batch_size                                                  5  \n",
       "accuracy                                            71.209843  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into 10 folds\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 0)\n",
    "\n",
    "# list that will store the results\n",
    "cv_score = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y) :\n",
    "    # create model\n",
    "    model = create_model(X[train_index], y[train_index])\n",
    "    \n",
    "    # evaluate the model\n",
    "    score = model.evaluate(X[test_index], y[test_index], verbose = 0)\n",
    "    print(model.metrics_names[1], score[1]*100)\n",
    "    cv_score.append(score[1]*100)\n",
    "\n",
    "params[\"accuracy\"] = np.mean(cv_score)\n",
    "df = pd.concat([df, pd.Series(params)], axis = 1)\n",
    "print(\"average accuracy and standard deviation:\", np.mean(cv_score), np.std(cv_score))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. WITH CALLBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kfold, X_test, y_kfold, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\Documents\\GitHub\\4th year Polytech\\Deep Learning\\env_deep_learning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.69565, saving model to my_best_model0.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.69565\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.69565 to 0.73913, saving model to my_best_model0.keras\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.73913\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.73913 to 0.79710, saving model to my_best_model0.keras\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.79710\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.79710\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.79710 to 0.81159, saving model to my_best_model0.keras\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.81159\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.81159\n",
      "\n",
      "Epoch 11: val_accuracy improved from 0.81159 to 0.82609, saving model to my_best_model0.keras\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.82609\n",
      "\n",
      "Epoch 13: val_accuracy improved from 0.82609 to 0.84058, saving model to my_best_model0.keras\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 32: val_accuracy did not improve from 0.84058\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.84058\n",
      "compile_metrics 79.71014380455017\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66667, saving model to my_best_model1.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.66667 to 0.71014, saving model to my_best_model1.keras\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.71014 to 0.72464, saving model to my_best_model1.keras\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.72464 to 0.75362, saving model to my_best_model1.keras\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.75362\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.75362\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.75362\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.75362\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.75362 to 0.78261, saving model to my_best_model1.keras\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.78261\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.78261\n",
      "compile_metrics 72.46376872062683\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.64706, saving model to my_best_model2.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.64706 to 0.69118, saving model to my_best_model2.keras\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.69118 to 0.70588, saving model to my_best_model2.keras\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.70588 to 0.72059, saving model to my_best_model2.keras\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.72059 to 0.73529, saving model to my_best_model2.keras\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.73529\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.73529\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.73529 to 0.75000, saving model to my_best_model2.keras\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.75000 to 0.76471, saving model to my_best_model2.keras\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.76471\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.76471\n",
      "compile_metrics 72.0588207244873\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67647, saving model to my_best_model3.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.67647 to 0.73529, saving model to my_best_model3.keras\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.73529 to 0.75000, saving model to my_best_model3.keras\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.75000 to 0.76471, saving model to my_best_model3.keras\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.76471 to 0.77941, saving model to my_best_model3.keras\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 19: val_accuracy improved from 0.77941 to 0.79412, saving model to my_best_model3.keras\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 32: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 36: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 38: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 39: val_accuracy did not improve from 0.79412\n",
      "compile_metrics 76.47058963775635\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67647, saving model to my_best_model4.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.67647 to 0.69118, saving model to my_best_model4.keras\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.69118\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.69118\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.69118\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.69118\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.69118 to 0.70588, saving model to my_best_model4.keras\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.70588\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.70588\n",
      "compile_metrics 67.64705777168274\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33824, saving model to my_best_model5.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.33824\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.33824 to 0.45588, saving model to my_best_model5.keras\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.45588 to 0.57353, saving model to my_best_model5.keras\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.57353 to 0.63235, saving model to my_best_model5.keras\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.63235 to 0.67647, saving model to my_best_model5.keras\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.67647 to 0.69118, saving model to my_best_model5.keras\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.69118 to 0.73529, saving model to my_best_model5.keras\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.73529 to 0.75000, saving model to my_best_model5.keras\n",
      "\n",
      "Epoch 10: val_accuracy improved from 0.75000 to 0.76471, saving model to my_best_model5.keras\n",
      "\n",
      "Epoch 11: val_accuracy improved from 0.76471 to 0.77941, saving model to my_best_model5.keras\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 13: val_accuracy improved from 0.77941 to 0.79412, saving model to my_best_model5.keras\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 32: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.79412\n",
      "compile_metrics 76.47058963775635\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41176, saving model to my_best_model6.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.41176 to 0.72059, saving model to my_best_model6.keras\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.72059 to 0.73529, saving model to my_best_model6.keras\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.73529 to 0.75000, saving model to my_best_model6.keras\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.75000 to 0.77941, saving model to my_best_model6.keras\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.77941\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.77941 to 0.80882, saving model to my_best_model6.keras\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.80882\n",
      "compile_metrics 75.0\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66176, saving model to my_best_model7.keras\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.66176\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.66176 to 0.72059, saving model to my_best_model7.keras\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.72059 to 0.77941, saving model to my_best_model7.keras\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.77941 to 0.82353, saving model to my_best_model7.keras\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.82353\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.82353 to 0.83824, saving model to my_best_model7.keras\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.83824\n",
      "compile_metrics 83.82353186607361\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66176, saving model to my_best_model8.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.66176 to 0.73529, saving model to my_best_model8.keras\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.73529 to 0.75000, saving model to my_best_model8.keras\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.75000\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.75000 to 0.76471, saving model to my_best_model8.keras\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.76471 to 0.79412, saving model to my_best_model8.keras\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.79412\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.79412 to 0.80882, saving model to my_best_model8.keras\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 11: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.80882\n",
      "\n",
      "Epoch 24: val_accuracy improved from 0.80882 to 0.82353, saving model to my_best_model8.keras\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.82353\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.82353\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.82353\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.82353\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.82353\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.82353\n",
      "\n",
      "Epoch 31: val_accuracy improved from 0.82353 to 0.83824, saving model to my_best_model8.keras\n",
      "\n",
      "Epoch 32: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 36: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 38: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 39: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 41: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 42: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 43: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 44: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 46: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 47: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 48: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 49: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 50: val_accuracy did not improve from 0.83824\n",
      "\n",
      "Epoch 51: val_accuracy did not improve from 0.83824\n",
      "compile_metrics 72.0588207244873\n",
      "average accuracy and standard deviation: 75.07814698749118 4.4982684820381325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N1</th>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N2</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act1</th>\n",
       "      <td>relu</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act2</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opt</th>\n",
       "      <td>adam</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>&lt;keras.src.losses.losses.BinaryCrossentropy ob...</td>\n",
       "      <td>&lt;keras.src.losses.losses.BinaryCrossentropy ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epochs</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>77.846453</td>\n",
       "      <td>75.078147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            0  \\\n",
       "N1                                                         12   \n",
       "N2                                                         12   \n",
       "act1                                                     relu   \n",
       "act2                                                  sigmoid   \n",
       "opt                                                      adam   \n",
       "loss        <keras.src.losses.losses.BinaryCrossentropy ob...   \n",
       "epochs                                                    100   \n",
       "batch_size                                                 20   \n",
       "accuracy                                            77.846453   \n",
       "N3                                                        NaN   \n",
       "act3                                                      NaN   \n",
       "\n",
       "                                                            0  \n",
       "N1                                                         24  \n",
       "N2                                                         12  \n",
       "act1                                                     relu  \n",
       "act2                                                     relu  \n",
       "opt                                                      adam  \n",
       "loss        <keras.src.losses.losses.BinaryCrossentropy ob...  \n",
       "epochs                                                    100  \n",
       "batch_size                                                 20  \n",
       "accuracy                                            75.078147  \n",
       "N3                                                         16  \n",
       "act3                                              exponential  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_folds = 9\n",
    "\n",
    "# initialize parameters\n",
    "params = {\"N1\" : 24, \"N2\" : 12, \"N3\" : 16, \"act1\" : \"relu\", \"act2\" : \"relu\", \"act3\" : \"exponential\",\"opt\" : \"adam\", \"loss\" : losses.BinaryCrossentropy(),\n",
    "          \"epochs\" : 100, \"batch_size\" : 20}\n",
    "\n",
    "def create_model(X_t, y_t, X_v, y_v, count) :\n",
    "    \"\"\"create and return model\"\"\"\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor = \"val_accuracy\", patience = 20),\n",
    "        ModelCheckpoint(\n",
    "            filepath = \"my_best_model\" + str(count) + \".keras\",\n",
    "            monitor = \"val_accuracy\",\n",
    "            mode = \"max\",\n",
    "            save_best_only = True,\n",
    "            verbose = 1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # create model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(params[\"N1\"], activation = params[\"act1\"], input_dim = 8))\n",
    "    model.add(layers.Dense(params[\"N2\"], activation = params[\"act2\"]))\n",
    "    model.add(layers.Dense(params[\"N3\"], activation = params[\"act3\"]))\n",
    "    model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=params[\"opt\"],loss=params[\"loss\"],metrics=[\"accuracy\"])\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X_t, y_t, validation_data = (X_v, y_v), epochs = params[\"epochs\"], batch_size = params[\"batch_size\"], verbose = 0, callbacks = callbacks)\n",
    "\n",
    "    return model\n",
    "\n",
    "# split data into 10 folds\n",
    "kfold = StratifiedKFold(n_splits = n_folds, shuffle = True, random_state = 0)\n",
    "\n",
    "# list that will store the results\n",
    "cv_score = []\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_kfold, y_kfold) :\n",
    "    # create model\n",
    "    model = create_model(X_kfold[train_index], y_kfold[train_index], X_kfold[test_index], y_kfold[test_index], i)\n",
    "    \n",
    "    # evaluate the model\n",
    "    score = model.evaluate(X_kfold[test_index], y_kfold[test_index], verbose = 0)\n",
    "    print(model.metrics_names[1], score[1]*100)\n",
    "    cv_score.append(score[1]*100)\n",
    "    i += 1\n",
    "\n",
    "params[\"accuracy\"] = np.mean(cv_score)\n",
    "df2 = pd.concat([df2, pd.Series(params)], axis = 1)\n",
    "print(\"average accuracy and standard deviation:\", np.mean(cv_score), np.std(cv_score))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model = []\n",
    "for i in range (n_folds) :\n",
    "    all_model.append(load_model(\"my_best_model\" + str(i) + \".keras\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "accuracy :  0.7467532467532467\n"
     ]
    }
   ],
   "source": [
    "model_predict_moyenne = all_model[0].predict(X_test)\n",
    "\n",
    "for i in range(1, n_folds) :\n",
    "    model_predict_moyenne += all_model[i].predict(X_test)\n",
    "\n",
    "model_predict_moyenne = np.round(model_predict_moyenne/10)\n",
    "\n",
    "print(\"accuracy : \", 1 - (np.sum(np.abs(model_predict_moyenne[:, 0] - y_test))/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

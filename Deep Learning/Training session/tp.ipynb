{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras import Input\n",
    "from keras.layers import Concatenate\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>squareMeters</th>\n",
       "      <th>numberOfRooms</th>\n",
       "      <th>hasYard</th>\n",
       "      <th>hasPool</th>\n",
       "      <th>floors</th>\n",
       "      <th>cityCode</th>\n",
       "      <th>cityPartRange</th>\n",
       "      <th>numPrevOwners</th>\n",
       "      <th>made</th>\n",
       "      <th>isNewBuilt</th>\n",
       "      <th>hasStormProtector</th>\n",
       "      <th>basement</th>\n",
       "      <th>attic</th>\n",
       "      <th>garage</th>\n",
       "      <th>hasStorageRoom</th>\n",
       "      <th>hasGuestRoom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77747</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>98938</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4829</td>\n",
       "      <td>4204</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7786197.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28459</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>50114</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3570</td>\n",
       "      <td>9363</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2846923.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34668</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>17366</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3476</td>\n",
       "      <td>7549</td>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3475230.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64335</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>65939</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7301</td>\n",
       "      <td>6989</td>\n",
       "      <td>802</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6435779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22875</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>8661</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6394</td>\n",
       "      <td>2119</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2295511.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   squareMeters  numberOfRooms  hasYard  hasPool  floors  cityCode  \\\n",
       "0         77747             50        1        1      72     98938   \n",
       "1         28459             52        0        0       4     50114   \n",
       "2         34668             69        1        1      12     17366   \n",
       "3         64335              4        0        0      83     65939   \n",
       "4         22875             86        1        0      95      8661   \n",
       "\n",
       "   cityPartRange  numPrevOwners  made  isNewBuilt  hasStormProtector  \\\n",
       "0              8             10  2014           0                  1   \n",
       "1              1              7  2012           1                  1   \n",
       "2              8              7  2002           0                  1   \n",
       "3              6              9  2020           1                  0   \n",
       "4              5              7  1994           0                  0   \n",
       "\n",
       "   basement  attic  garage  hasStorageRoom  hasGuestRoom      price  \n",
       "0      4829   4204     455               0             3  7786197.4  \n",
       "1      3570   9363     318               0             6  2846923.2  \n",
       "2      3476   7549     503               1             7  3475230.2  \n",
       "3      7301   6989     802               0             1  6435779.0  \n",
       "4      6394   2119     542               0             7  2295511.4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data describe the characteristics of a house (surface, number of rooms...)\n",
    "# and you should predict its price\n",
    "\n",
    "# The metrics for the ranking will be based on the mean square error ('mse')\n",
    "\n",
    "df_train = pd.read_csv(\"Train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>squareMeters</th>\n",
       "      <th>numberOfRooms</th>\n",
       "      <th>hasYard</th>\n",
       "      <th>hasPool</th>\n",
       "      <th>floors</th>\n",
       "      <th>cityCode</th>\n",
       "      <th>cityPartRange</th>\n",
       "      <th>numPrevOwners</th>\n",
       "      <th>made</th>\n",
       "      <th>isNewBuilt</th>\n",
       "      <th>hasStormProtector</th>\n",
       "      <th>basement</th>\n",
       "      <th>attic</th>\n",
       "      <th>garage</th>\n",
       "      <th>hasStorageRoom</th>\n",
       "      <th>hasGuestRoom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92649</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>56098</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6811</td>\n",
       "      <td>2656</td>\n",
       "      <td>429</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9271774.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42485</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>23782</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>974</td>\n",
       "      <td>9553</td>\n",
       "      <td>426</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4251851.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65867</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>67725</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3054</td>\n",
       "      <td>4650</td>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6593211.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2372</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>60320</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8041</td>\n",
       "      <td>7294</td>\n",
       "      <td>736</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>241014.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60514</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>76413</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9227</td>\n",
       "      <td>737</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6059360.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   squareMeters  numberOfRooms  hasYard  hasPool  floors  cityCode  \\\n",
       "0         92649             31        0        0      77     56098   \n",
       "1         42485              1        0        0      40     23782   \n",
       "2         65867             37        0        0      92     67725   \n",
       "3          2372             41        1        0       5     60320   \n",
       "4         60514             46        1        1      35     76413   \n",
       "\n",
       "   cityPartRange  numPrevOwners  made  isNewBuilt  hasStormProtector  \\\n",
       "0             10              8  1991           1                  1   \n",
       "1              7              7  2017           0                  1   \n",
       "2              6              2  1994           1                  1   \n",
       "3              1              1  2003           0                  0   \n",
       "4              2              1  2019           1                  0   \n",
       "\n",
       "   basement  attic  garage  hasStorageRoom  hasGuestRoom      price  \n",
       "0      6811   2656     429               1             8  9271774.1  \n",
       "1       974   9553     426               0             3  4251851.7  \n",
       "2      3054   4650     998               1            10  6593211.4  \n",
       "3      8041   7294     736               1             4   241014.3  \n",
       "4      9227    737     340               0             8  6059360.9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"Test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input data/output data and store into numpy array\n",
    "\n",
    "X_train = np.array(df_train.drop('price', axis=1))\n",
    "y_train = np.array(df_train['price'])/10000\n",
    "\n",
    "X_test = np.array(df_test.drop('price', axis=1))\n",
    "y_test = np.array(df_test['price'])/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min, max = np.min(X_train, axis = 0), np.max(X_train, axis = 0)\n",
    "\n",
    "X_train = (X_train - min)/(max - min)\n",
    "X_test = (X_test - min)/(max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 16) (8000,)\n",
      "(1000, 16) (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "def create_model() :\n",
    "\n",
    "    # Input layer\n",
    "    x0 = [Input(shape = (16, )) for _ in range (16)]\n",
    "\n",
    "    # Hiddens layer\n",
    "    x1 = [Dense(3, input_dim = 16, activation = \"relu\")(x) for x in x0]\n",
    "\n",
    "    x2 = [Dense(3, activation = \"relu\")(x) for x in x1]\n",
    "\n",
    "    x3 = [Dense(3, activation = \"relu\")(x) for x in x2]\n",
    "\n",
    "    x3_temp = x3.copy()\n",
    "\n",
    "    x4 = [Concatenate()([x3[i], x3[i + 1]]) for i in range (0, len(x3), 2)]\n",
    "\n",
    "    x5 = [Dense(6, activation = \"relu\")(x) for x in x4]\n",
    "\n",
    "    x6 = [Dense(5, activation = \"relu\")(x) for x in x5]\n",
    "\n",
    "    x7 = [Concatenate()([x6[i], x6[i + 1]] + x3_temp[2*i : int(4*(i/2 + 1))]) for i in range (0, len(x6), 2)]\n",
    "\n",
    "    x8 = [Dense(8, activation = \"relu\")(x) for x in x7]\n",
    "\n",
    "    x9 = [Dense(8, activation = \"relu\")(x) for x in x8]\n",
    "\n",
    "    x10 = [Concatenate()([x9[i], x9[i + 1]]) for i in range (0, len(x9), 2)]\n",
    "\n",
    "    x11 = [Dense(16, activation = \"relu\")(x) for x in x10]\n",
    "\n",
    "    x12 = [Dense(16, activation = \"relu\")(x) for x in x11]\n",
    "\n",
    "    x13 = Concatenate()(x12)\n",
    "\n",
    "    x14 = Dense(256, activation = \"relu\")(x13)\n",
    "\n",
    "    # # Output layer\n",
    "    x15 = Dense(1)(x14)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs = x0, outputs = x15)\n",
    "\n",
    "    plot_model(model, show_shapes = True, to_file = \"model_graph_test.png\") ;\n",
    "\n",
    "    model.compile(optimizer = 'rmsprop', loss = [\"mse\"], metrics = [\"mse\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 218536.0469 - mse: 218536.0469\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45563.5703 - mse: 45563.5703\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2999.5139 - mse: 2999.5139\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1493.0770 - mse: 1493.0770\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1140.5792 - mse: 1140.5792\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 925.6960 - mse: 925.6960\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 818.7584 - mse: 818.7584\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 697.3891 - mse: 697.3891\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 729.6597 - mse: 729.6597\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 681.0978 - mse: 681.0978\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train for _ in range (16)], y_train, epochs = 10, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x264247ab890>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additionnal libraries\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 237236.1406 - mse: 237236.1406\n",
      "Epoch 1: mse improved from inf to 144049.65625, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 234929.1719 - mse: 234929.1719\n",
      "Epoch 2/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56060.9102 - mse: 56060.9102\n",
      "Epoch 2: mse improved from 144049.65625 to 40137.96484, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54331.7539 - mse: 54331.7539\n",
      "Epoch 3/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3462.1428 - mse: 3462.1428\n",
      "Epoch 3: mse improved from 40137.96484 to 2477.77808, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3404.0652 - mse: 3404.0652\n",
      "Epoch 4/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1248.2852 - mse: 1248.2852\n",
      "Epoch 4: mse improved from 2477.77808 to 1175.93787, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1241.7659 - mse: 1241.7659\n",
      "Epoch 5/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 973.0140 - mse: 973.0140\n",
      "Epoch 5: mse improved from 1175.93787 to 915.82428, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 968.2171 - mse: 968.2171\n",
      "Epoch 6/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 816.8934 - mse: 816.8934\n",
      "Epoch 6: mse improved from 915.82428 to 785.34991, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 814.6704 - mse: 814.6704\n",
      "Epoch 7/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 678.6496 - mse: 678.6496\n",
      "Epoch 7: mse improved from 785.34991 to 687.97711, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 679.0588 - mse: 679.0588\n",
      "Epoch 8/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 651.4571 - mse: 651.4571\n",
      "Epoch 8: mse improved from 687.97711 to 636.65802, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 651.1633 - mse: 651.1633\n",
      "Epoch 9/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 636.8605 - mse: 636.8605\n",
      "Epoch 9: mse improved from 636.65802 to 611.36517, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 636.4908 - mse: 636.4908\n",
      "Epoch 10/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 612.1778 - mse: 612.1778\n",
      "Epoch 10: mse improved from 611.36517 to 583.65790, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 609.5151 - mse: 609.5151\n",
      "Epoch 11/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 523.5289 - mse: 523.5289\n",
      "Epoch 11: mse improved from 583.65790 to 531.89447, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 525.2133 - mse: 525.2133\n",
      "Epoch 12/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 550.7814 - mse: 550.7814\n",
      "Epoch 12: mse improved from 531.89447 to 521.31671, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 549.9474 - mse: 549.9474\n",
      "Epoch 13/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 539.0846 - mse: 539.0846\n",
      "Epoch 13: mse improved from 521.31671 to 491.64133, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 536.4445 - mse: 536.4445\n",
      "Epoch 14/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 547.3149 - mse: 547.3149\n",
      "Epoch 14: mse did not improve from 491.64133\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 541.0385 - mse: 541.0385\n",
      "Epoch 15/100\n",
      "\u001b[1m181/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 509.8841 - mse: 509.8841\n",
      "Epoch 15: mse improved from 491.64133 to 489.03799, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 507.8107 - mse: 507.8107\n",
      "Epoch 16/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 462.9884 - mse: 462.9884\n",
      "Epoch 16: mse improved from 489.03799 to 463.56949, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 462.8490 - mse: 462.8490\n",
      "Epoch 17/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.7983 - mse: 430.7983\n",
      "Epoch 17: mse improved from 463.56949 to 442.66263, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431.8211 - mse: 431.8211\n",
      "Epoch 18/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.9423 - mse: 458.9423\n",
      "Epoch 18: mse improved from 442.66263 to 430.85712, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 456.8810 - mse: 456.8810\n",
      "Epoch 19/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 461.2463 - mse: 461.2463\n",
      "Epoch 19: mse did not improve from 430.85712\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 461.1216 - mse: 461.1216\n",
      "Epoch 20/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 404.8675 - mse: 404.8675\n",
      "Epoch 20: mse improved from 430.85712 to 423.32654, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 404.9594 - mse: 404.9594\n",
      "Epoch 21/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.3513 - mse: 379.3513\n",
      "Epoch 21: mse improved from 423.32654 to 390.98001, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.4670 - mse: 379.4670\n",
      "Epoch 22/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 406.0362 - mse: 406.0362\n",
      "Epoch 22: mse did not improve from 390.98001\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405.9991 - mse: 405.9991\n",
      "Epoch 23/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.4384 - mse: 375.4384\n",
      "Epoch 23: mse improved from 390.98001 to 385.45270, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377.8017 - mse: 377.8017\n",
      "Epoch 24/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 406.3932 - mse: 406.3932\n",
      "Epoch 24: mse improved from 385.45270 to 384.35635, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405.9693 - mse: 405.9693\n",
      "Epoch 25/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388.1528 - mse: 388.1528\n",
      "Epoch 25: mse improved from 384.35635 to 378.93155, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 387.8893 - mse: 387.8893\n",
      "Epoch 26/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 385.7692 - mse: 385.7692\n",
      "Epoch 26: mse did not improve from 378.93155\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 384.4715 - mse: 384.4715\n",
      "Epoch 27/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.4481 - mse: 353.4481\n",
      "Epoch 27: mse improved from 378.93155 to 359.30579, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.5615 - mse: 353.5615\n",
      "Epoch 28/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 343.1834 - mse: 343.1834\n",
      "Epoch 28: mse improved from 359.30579 to 356.33157, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 343.4161 - mse: 343.4161\n",
      "Epoch 29/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.4408 - mse: 353.4408\n",
      "Epoch 29: mse improved from 356.33157 to 355.32715, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.4502 - mse: 353.4502\n",
      "Epoch 30/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331.3046 - mse: 331.3046\n",
      "Epoch 30: mse improved from 355.32715 to 349.23761, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 334.5799 - mse: 334.5799\n",
      "Epoch 31/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.2057 - mse: 353.2057\n",
      "Epoch 31: mse improved from 349.23761 to 348.46915, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.1585 - mse: 353.1585\n",
      "Epoch 32/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 354.1631 - mse: 354.1631\n",
      "Epoch 32: mse improved from 348.46915 to 345.57556, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 354.0777 - mse: 354.0777\n",
      "Epoch 33/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 300.1605 - mse: 300.1605\n",
      "Epoch 33: mse improved from 345.57556 to 321.00757, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 300.8406 - mse: 300.8406\n",
      "Epoch 34/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 387.4969 - mse: 387.4969\n",
      "Epoch 34: mse did not improve from 321.00757\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 386.5565 - mse: 386.5565\n",
      "Epoch 35/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340.7343 - mse: 340.7343\n",
      "Epoch 35: mse did not improve from 321.00757\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340.6531 - mse: 340.6531\n",
      "Epoch 36/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 328.4060 - mse: 328.4060\n",
      "Epoch 36: mse improved from 321.00757 to 320.96838, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 328.2480 - mse: 328.2480\n",
      "Epoch 37/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344.0750 - mse: 344.0750\n",
      "Epoch 37: mse did not improve from 320.96838\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 343.8022 - mse: 343.8022\n",
      "Epoch 38/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 337.7935 - mse: 337.7935\n",
      "Epoch 38: mse did not improve from 320.96838\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 336.4804 - mse: 336.4804\n",
      "Epoch 39/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 334.3445 - mse: 334.3445\n",
      "Epoch 39: mse did not improve from 320.96838\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 334.2459 - mse: 334.2459\n",
      "Epoch 40/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 300.0354 - mse: 300.0354\n",
      "Epoch 40: mse improved from 320.96838 to 308.69180, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 301.9287 - mse: 301.9287\n",
      "Epoch 41/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.4984 - mse: 333.4984\n",
      "Epoch 41: mse did not improve from 308.69180\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.2955 - mse: 333.2955\n",
      "Epoch 42/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.0567 - mse: 286.0567\n",
      "Epoch 42: mse improved from 308.69180 to 303.30557, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.1425 - mse: 286.1425\n",
      "Epoch 43/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 316.5078 - mse: 316.5078\n",
      "Epoch 43: mse did not improve from 303.30557\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315.7440 - mse: 315.7440\n",
      "Epoch 44/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 325.4778 - mse: 325.4778\n",
      "Epoch 44: mse did not improve from 303.30557\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 322.8941 - mse: 322.8941\n",
      "Epoch 45/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 308.4861 - mse: 308.4861\n",
      "Epoch 45: mse did not improve from 303.30557\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 308.2228 - mse: 308.2228\n",
      "Epoch 46/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295.6038 - mse: 295.6038\n",
      "Epoch 46: mse improved from 303.30557 to 299.82892, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295.6781 - mse: 295.6781\n",
      "Epoch 47/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 284.9228 - mse: 284.9228\n",
      "Epoch 47: mse improved from 299.82892 to 298.89078, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.5498 - mse: 286.5498\n",
      "Epoch 48/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.7157 - mse: 264.7157\n",
      "Epoch 48: mse improved from 298.89078 to 287.78650, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.1761 - mse: 265.1761\n",
      "Epoch 49/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 294.6599 - mse: 294.6599\n",
      "Epoch 49: mse did not improve from 287.78650\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 294.6794 - mse: 294.6794\n",
      "Epoch 50/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 298.7232 - mse: 298.7232\n",
      "Epoch 50: mse did not improve from 287.78650\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 297.5913 - mse: 297.5913\n",
      "Epoch 51/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 290.5728 - mse: 290.5728\n",
      "Epoch 51: mse did not improve from 287.78650\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 290.5796 - mse: 290.5796\n",
      "Epoch 52/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268.5471 - mse: 268.5471\n",
      "Epoch 52: mse improved from 287.78650 to 281.54938, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.0847 - mse: 270.0847\n",
      "Epoch 53/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.7999 - mse: 271.7999\n",
      "Epoch 53: mse improved from 281.54938 to 280.12415, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.8413 - mse: 271.8413\n",
      "Epoch 54/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.4467 - mse: 285.4467\n",
      "Epoch 54: mse did not improve from 280.12415\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.4122 - mse: 285.4122\n",
      "Epoch 55/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.4851 - mse: 273.4851\n",
      "Epoch 55: mse improved from 280.12415 to 278.80835, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.6531 - mse: 273.6531\n",
      "Epoch 56/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.4096 - mse: 275.4096\n",
      "Epoch 56: mse improved from 278.80835 to 272.28345, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.5336 - mse: 275.5336\n",
      "Epoch 57/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 300.0380 - mse: 300.0380\n",
      "Epoch 57: mse did not improve from 272.28345\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 296.4612 - mse: 296.4612\n",
      "Epoch 58/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 293.3331 - mse: 293.3331\n",
      "Epoch 58: mse did not improve from 272.28345\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 290.8770 - mse: 290.8770\n",
      "Epoch 59/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.3292 - mse: 273.3292\n",
      "Epoch 59: mse improved from 272.28345 to 267.63452, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.0958 - mse: 273.0958\n",
      "Epoch 60/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.8856 - mse: 270.8856\n",
      "Epoch 60: mse did not improve from 267.63452\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.8795 - mse: 270.8795\n",
      "Epoch 61/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.8608 - mse: 264.8608\n",
      "Epoch 61: mse improved from 267.63452 to 267.35571, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.9920 - mse: 264.9920\n",
      "Epoch 62/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 257.9045 - mse: 257.9045\n",
      "Epoch 62: mse improved from 267.35571 to 260.49289, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 259.2526 - mse: 259.2526\n",
      "Epoch 63/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.7474 - mse: 285.7474\n",
      "Epoch 63: mse did not improve from 260.49289\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282.7959 - mse: 282.7959\n",
      "Epoch 64/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.9859 - mse: 271.9859\n",
      "Epoch 64: mse did not improve from 260.49289\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.7415 - mse: 270.7415\n",
      "Epoch 65/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 250.9163 - mse: 250.9163\n",
      "Epoch 65: mse improved from 260.49289 to 258.81683, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.4571 - mse: 252.4571\n",
      "Epoch 66/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.5281 - mse: 265.5281\n",
      "Epoch 66: mse did not improve from 258.81683\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.7282 - mse: 264.7282\n",
      "Epoch 67/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.6237 - mse: 264.6237\n",
      "Epoch 67: mse did not improve from 258.81683\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.4060 - mse: 264.4060\n",
      "Epoch 68/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 243.9671 - mse: 243.9671\n",
      "Epoch 68: mse improved from 258.81683 to 250.35846, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.1661 - mse: 245.1661\n",
      "Epoch 69/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.3503 - mse: 264.3503\n",
      "Epoch 69: mse did not improve from 250.35846\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 262.4314 - mse: 262.4314\n",
      "Epoch 70/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.2134 - mse: 255.2134\n",
      "Epoch 70: mse did not improve from 250.35846\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.1694 - mse: 255.1694\n",
      "Epoch 71/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 248.1837 - mse: 248.1837\n",
      "Epoch 71: mse improved from 250.35846 to 248.70995, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 248.2538 - mse: 248.2538\n",
      "Epoch 72/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240.0904 - mse: 240.0904\n",
      "Epoch 72: mse improved from 248.70995 to 247.31834, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.4924 - mse: 241.4924\n",
      "Epoch 73/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.9720 - mse: 252.9720\n",
      "Epoch 73: mse improved from 247.31834 to 239.79465, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.5465 - mse: 251.5465\n",
      "Epoch 74/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 272.1479 - mse: 272.1479\n",
      "Epoch 74: mse did not improve from 239.79465\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268.8870 - mse: 268.8870\n",
      "Epoch 75/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 234.2891 - mse: 234.2891\n",
      "Epoch 75: mse did not improve from 239.79465\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 235.8911 - mse: 235.8911\n",
      "Epoch 76/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 246.0505 - mse: 246.0505\n",
      "Epoch 76: mse did not improve from 239.79465\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.8910 - mse: 245.8910\n",
      "Epoch 77/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253.7426 - mse: 253.7426\n",
      "Epoch 77: mse did not improve from 239.79465\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253.6905 - mse: 253.6905\n",
      "Epoch 78/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240.5881 - mse: 240.5881\n",
      "Epoch 78: mse improved from 239.79465 to 238.68979, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240.0087 - mse: 240.0087\n",
      "Epoch 79/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.0341 - mse: 232.0341\n",
      "Epoch 79: mse did not improve from 238.68979\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.0866 - mse: 233.0866\n",
      "Epoch 80/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236.4335 - mse: 236.4335\n",
      "Epoch 80: mse improved from 238.68979 to 234.24161, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236.4703 - mse: 236.4703\n",
      "Epoch 81/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.5558 - mse: 251.5558\n",
      "Epoch 81: mse did not improve from 234.24161\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.4854 - mse: 251.4854\n",
      "Epoch 82/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253.5486 - mse: 253.5486\n",
      "Epoch 82: mse did not improve from 234.24161\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 250.7679 - mse: 250.7679\n",
      "Epoch 83/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 230.9858 - mse: 230.9858\n",
      "Epoch 83: mse did not improve from 234.24161\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 231.0164 - mse: 231.0164\n",
      "Epoch 84/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 228.9876 - mse: 228.9876\n",
      "Epoch 84: mse did not improve from 234.24161\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 229.5173 - mse: 229.5173\n",
      "Epoch 85/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.1724 - mse: 210.1724\n",
      "Epoch 85: mse improved from 234.24161 to 227.96838, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.0781 - mse: 211.0781\n",
      "Epoch 86/100\n",
      "\u001b[1m181/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 225.3415 - mse: 225.3415\n",
      "Epoch 86: mse did not improve from 227.96838\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 226.0268 - mse: 226.0268\n",
      "Epoch 87/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236.0553 - mse: 236.0553\n",
      "Epoch 87: mse did not improve from 227.96838\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 235.6404 - mse: 235.6404\n",
      "Epoch 88/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.9707 - mse: 232.9707\n",
      "Epoch 88: mse did not improve from 227.96838\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.6677 - mse: 232.6677\n",
      "Epoch 89/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.1282 - mse: 216.1282\n",
      "Epoch 89: mse improved from 227.96838 to 227.13908, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.6585 - mse: 216.6585\n",
      "Epoch 90/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 219.5847 - mse: 219.5847\n",
      "Epoch 90: mse did not improve from 227.13908\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 220.0923 - mse: 220.0923\n",
      "Epoch 91/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.6387 - mse: 214.6387\n",
      "Epoch 91: mse improved from 227.13908 to 225.31877, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.3504 - mse: 215.3504\n",
      "Epoch 92/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.5240 - mse: 201.5240\n",
      "Epoch 92: mse improved from 225.31877 to 224.40648, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.7717 - mse: 204.7717\n",
      "Epoch 93/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.6941 - mse: 215.6941\n",
      "Epoch 93: mse did not improve from 224.40648\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.5560 - mse: 216.5560\n",
      "Epoch 94/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.7424 - mse: 204.7424\n",
      "Epoch 94: mse improved from 224.40648 to 219.07513, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.0581 - mse: 206.0581\n",
      "Epoch 95/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.0553 - mse: 214.0553\n",
      "Epoch 95: mse improved from 219.07513 to 217.88947, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.5154 - mse: 214.5154\n",
      "Epoch 96/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 229.9221 - mse: 229.9221\n",
      "Epoch 96: mse did not improve from 217.88947\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 229.5476 - mse: 229.5476\n",
      "Epoch 97/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 221.9760 - mse: 221.9760\n",
      "Epoch 97: mse did not improve from 217.88947\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 221.9517 - mse: 221.9517\n",
      "Epoch 98/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.3033 - mse: 211.3033\n",
      "Epoch 98: mse improved from 217.88947 to 215.94566, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.3495 - mse: 211.3495\n",
      "Epoch 99/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 219.7622 - mse: 219.7622\n",
      "Epoch 99: mse improved from 215.94566 to 213.23535, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 219.2286 - mse: 219.2286\n",
      "Epoch 100/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.4645 - mse: 233.4645\n",
      "Epoch 100: mse did not improve from 213.23535\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 231.3127 - mse: 231.3127\n",
      "Epoch 1/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 235922.9844 - mse: 235922.9844\n",
      "Epoch 1: mse improved from inf to 143857.96875, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 225806.5781 - mse: 225806.5781\n",
      "Epoch 2/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64452.0078 - mse: 64452.0078\n",
      "Epoch 2: mse improved from 143857.96875 to 47277.69922, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62311.9570 - mse: 62311.9570\n",
      "Epoch 3/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8485.9014 - mse: 8485.9014\n",
      "Epoch 3: mse improved from 47277.69922 to 5675.74170, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8268.6387 - mse: 8268.6387\n",
      "Epoch 4/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2243.5591 - mse: 2243.5591\n",
      "Epoch 4: mse improved from 5675.74170 to 1952.66138, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2222.2146 - mse: 2222.2146\n",
      "Epoch 5/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1332.3778 - mse: 1332.3778\n",
      "Epoch 5: mse improved from 1952.66138 to 1196.28418, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1320.1045 - mse: 1320.1045\n",
      "Epoch 6/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 929.1305 - mse: 929.1305\n",
      "Epoch 6: mse improved from 1196.28418 to 943.16748, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 929.7592 - mse: 929.7592\n",
      "Epoch 7/100\n",
      "\u001b[1m181/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 757.5043 - mse: 757.5043\n",
      "Epoch 7: mse improved from 943.16748 to 805.82227, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 763.0958 - mse: 763.0958\n",
      "Epoch 8/100\n",
      "\u001b[1m181/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 776.4536 - mse: 776.4536\n",
      "Epoch 8: mse improved from 805.82227 to 761.84814, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 775.6126 - mse: 775.6126\n",
      "Epoch 9/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 706.6024 - mse: 706.6024\n",
      "Epoch 9: mse improved from 761.84814 to 710.59888, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 707.1559 - mse: 707.1559\n",
      "Epoch 10/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 682.0804 - mse: 682.0804\n",
      "Epoch 10: mse improved from 710.59888 to 673.55310, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 681.6556 - mse: 681.6556\n",
      "Epoch 11/100\n",
      "\u001b[1m181/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 657.7788 - mse: 657.7788\n",
      "Epoch 11: mse improved from 673.55310 to 633.89648, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 656.0749 - mse: 656.0749\n",
      "Epoch 12/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 642.1428 - mse: 642.1428\n",
      "Epoch 12: mse improved from 633.89648 to 623.80212, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 639.6492 - mse: 639.6492\n",
      "Epoch 13/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 597.6771 - mse: 597.6771\n",
      "Epoch 13: mse improved from 623.80212 to 578.94916, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 597.1682 - mse: 597.1682\n",
      "Epoch 14/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 565.8565 - mse: 565.8565\n",
      "Epoch 14: mse improved from 578.94916 to 571.90808, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 566.6653 - mse: 566.6653\n",
      "Epoch 15/100\n",
      "\u001b[1m181/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 586.4451 - mse: 586.4451\n",
      "Epoch 15: mse improved from 571.90808 to 568.90363, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 584.0659 - mse: 584.0659\n",
      "Epoch 16/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 553.1509 - mse: 553.1509\n",
      "Epoch 16: mse improved from 568.90363 to 552.89978, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 552.9136 - mse: 552.9136\n",
      "Epoch 17/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 519.8024 - mse: 519.8024\n",
      "Epoch 17: mse improved from 552.89978 to 534.81335, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 520.9785 - mse: 520.9785\n",
      "Epoch 18/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 541.7330 - mse: 541.7330\n",
      "Epoch 18: mse improved from 534.81335 to 527.64685, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 540.4467 - mse: 540.4467\n",
      "Epoch 19/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 503.6537 - mse: 503.6537\n",
      "Epoch 19: mse improved from 527.64685 to 502.86981, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 503.7753 - mse: 503.7753\n",
      "Epoch 20/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 529.9789 - mse: 529.9789\n",
      "Epoch 20: mse did not improve from 502.86981\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 527.3092 - mse: 527.3092\n",
      "Epoch 21/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 511.7787 - mse: 511.7787\n",
      "Epoch 21: mse improved from 502.86981 to 499.11261, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 511.4835 - mse: 511.4835\n",
      "Epoch 22/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 491.9814 - mse: 491.9814\n",
      "Epoch 22: mse improved from 499.11261 to 483.14804, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 490.9507 - mse: 490.9507\n",
      "Epoch 23/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 423.7130 - mse: 423.7130\n",
      "Epoch 23: mse improved from 483.14804 to 459.18094, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 426.7017 - mse: 426.7017\n",
      "Epoch 24/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 489.6227 - mse: 489.6227\n",
      "Epoch 24: mse did not improve from 459.18094\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 487.7838 - mse: 487.7838\n",
      "Epoch 25/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 486.3081 - mse: 486.3081\n",
      "Epoch 25: mse did not improve from 459.18094\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 483.8294 - mse: 483.8294\n",
      "Epoch 26/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 445.6225 - mse: 445.6225\n",
      "Epoch 26: mse improved from 459.18094 to 449.16684, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 445.8241 - mse: 445.8241\n",
      "Epoch 27/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 419.0380 - mse: 419.0380\n",
      "Epoch 27: mse improved from 449.16684 to 435.44559, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 420.2108 - mse: 420.2108\n",
      "Epoch 28/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 448.2463 - mse: 448.2463\n",
      "Epoch 28: mse did not improve from 435.44559\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 448.0348 - mse: 448.0348\n",
      "Epoch 29/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 482.3346 - mse: 482.3346\n",
      "Epoch 29: mse did not improve from 435.44559\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 481.1366 - mse: 481.1366\n",
      "Epoch 30/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.0240 - mse: 422.0240\n",
      "Epoch 30: mse improved from 435.44559 to 427.67834, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.1162 - mse: 422.1162\n",
      "Epoch 31/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 410.1791 - mse: 410.1791\n",
      "Epoch 31: mse improved from 427.67834 to 424.74023, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 411.3911 - mse: 411.3911\n",
      "Epoch 32/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.9583 - mse: 373.9583\n",
      "Epoch 32: mse improved from 424.74023 to 400.80469, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.4640 - mse: 375.4640\n",
      "Epoch 33/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 411.3328 - mse: 411.3328\n",
      "Epoch 33: mse did not improve from 400.80469\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 411.2422 - mse: 411.2422\n",
      "Epoch 34/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 399.0877 - mse: 399.0877\n",
      "Epoch 34: mse improved from 400.80469 to 396.06641, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 399.0255 - mse: 399.0255\n",
      "Epoch 35/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 410.5423 - mse: 410.5423\n",
      "Epoch 35: mse did not improve from 396.06641\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 410.3612 - mse: 410.3612\n",
      "Epoch 36/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389.1454 - mse: 389.1454\n",
      "Epoch 36: mse improved from 396.06641 to 389.34937, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389.1047 - mse: 389.1047\n",
      "Epoch 37/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 396.6882 - mse: 396.6882\n",
      "Epoch 37: mse improved from 389.34937 to 385.51279, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 396.5770 - mse: 396.5770\n",
      "Epoch 38/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388.0941 - mse: 388.0941\n",
      "Epoch 38: mse did not improve from 385.51279\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388.0038 - mse: 388.0038\n",
      "Epoch 39/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390.9701 - mse: 390.9701\n",
      "Epoch 39: mse improved from 385.51279 to 383.24139, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390.5988 - mse: 390.5988\n",
      "Epoch 40/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 408.8140 - mse: 408.8140\n",
      "Epoch 40: mse did not improve from 383.24139\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405.9545 - mse: 405.9545\n",
      "Epoch 41/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.7657 - mse: 364.7657\n",
      "Epoch 41: mse improved from 383.24139 to 370.23895, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.0502 - mse: 365.0502\n",
      "Epoch 42/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.4079 - mse: 365.4079\n",
      "Epoch 42: mse improved from 370.23895 to 367.53232, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.4236 - mse: 365.4236\n",
      "Epoch 43/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 372.4156 - mse: 372.4156\n",
      "Epoch 43: mse did not improve from 367.53232\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 372.0345 - mse: 372.0345\n",
      "Epoch 44/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 329.1360 - mse: 329.1360\n",
      "Epoch 44: mse improved from 367.53232 to 353.70190, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331.1067 - mse: 331.1067\n",
      "Epoch 45/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.7144 - mse: 346.7144\n",
      "Epoch 45: mse did not improve from 353.70190\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 347.7390 - mse: 347.7390\n",
      "Epoch 46/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340.5515 - mse: 340.5515\n",
      "Epoch 46: mse did not improve from 353.70190\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 341.5606 - mse: 341.5606\n",
      "Epoch 47/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 348.5708 - mse: 348.5708\n",
      "Epoch 47: mse improved from 353.70190 to 350.73062, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 348.5802 - mse: 348.5802\n",
      "Epoch 48/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362.8080 - mse: 362.8080\n",
      "Epoch 48: mse did not improve from 350.73062\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362.2315 - mse: 362.2315\n",
      "Epoch 49/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 307.4047 - mse: 307.4047\n",
      "Epoch 49: mse improved from 350.73062 to 342.50323, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.2416 - mse: 310.2416\n",
      "Epoch 50/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 326.5343 - mse: 326.5343\n",
      "Epoch 50: mse did not improve from 342.50323\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 328.7514 - mse: 328.7514\n",
      "Epoch 51/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.8604 - mse: 333.8604\n",
      "Epoch 51: mse improved from 342.50323 to 339.62247, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 334.2471 - mse: 334.2471\n",
      "Epoch 52/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 337.9503 - mse: 337.9503\n",
      "Epoch 52: mse did not improve from 339.62247\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 337.9270 - mse: 337.9270\n",
      "Epoch 53/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 303.2543 - mse: 303.2543\n",
      "Epoch 53: mse improved from 339.62247 to 330.72333, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 305.2200 - mse: 305.2200\n",
      "Epoch 54/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 323.8094 - mse: 323.8094\n",
      "Epoch 54: mse did not improve from 330.72333\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 324.7694 - mse: 324.7694\n",
      "Epoch 55/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 297.5495 - mse: 297.5495\n",
      "Epoch 55: mse improved from 330.72333 to 324.17377, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 300.6944 - mse: 300.6944\n",
      "Epoch 56/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304.6425 - mse: 304.6425\n",
      "Epoch 56: mse did not improve from 324.17377\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 306.2002 - mse: 306.2002\n",
      "Epoch 57/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.0966 - mse: 289.0966\n",
      "Epoch 57: mse improved from 324.17377 to 321.00220, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.5509 - mse: 291.5509\n",
      "Epoch 58/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 306.6997 - mse: 306.6997\n",
      "Epoch 58: mse did not improve from 321.00220\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 307.9275 - mse: 307.9275\n",
      "Epoch 59/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.2631 - mse: 310.2631\n",
      "Epoch 59: mse improved from 321.00220 to 315.68237, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.7641 - mse: 310.7641\n",
      "Epoch 60/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 347.6505 - mse: 347.6505\n",
      "Epoch 60: mse did not improve from 315.68237\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344.1159 - mse: 344.1159\n",
      "Epoch 61/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 317.8170 - mse: 317.8170\n",
      "Epoch 61: mse improved from 315.68237 to 311.38361, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 317.3115 - mse: 317.3115\n",
      "Epoch 62/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 317.1545 - mse: 317.1545\n",
      "Epoch 62: mse did not improve from 311.38361\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 317.0596 - mse: 317.0596\n",
      "Epoch 63/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 300.6447 - mse: 300.6447\n",
      "Epoch 63: mse did not improve from 311.38361\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 301.1225 - mse: 301.1225\n",
      "Epoch 64/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 296.2222 - mse: 296.2222\n",
      "Epoch 64: mse improved from 311.38361 to 308.92267, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 296.8785 - mse: 296.8785\n",
      "Epoch 65/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 290.2354 - mse: 290.2354\n",
      "Epoch 65: mse improved from 308.92267 to 299.72397, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.4898 - mse: 291.4898\n",
      "Epoch 66/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 319.0948 - mse: 319.0948\n",
      "Epoch 66: mse did not improve from 299.72397\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 318.5349 - mse: 318.5349\n",
      "Epoch 67/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 314.8230 - mse: 314.8230\n",
      "Epoch 67: mse did not improve from 299.72397\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 313.5982 - mse: 313.5982\n",
      "Epoch 68/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 296.9995 - mse: 296.9995\n",
      "Epoch 68: mse improved from 299.72397 to 295.28088, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 296.7645 - mse: 296.7645\n",
      "Epoch 69/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 293.1536 - mse: 293.1536\n",
      "Epoch 69: mse did not improve from 295.28088\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 293.5097 - mse: 293.5097\n",
      "Epoch 70/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 283.2881 - mse: 283.2881\n",
      "Epoch 70: mse improved from 295.28088 to 288.04288, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 283.7399 - mse: 283.7399\n",
      "Epoch 71/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 301.1867 - mse: 301.1867\n",
      "Epoch 71: mse did not improve from 288.04288\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 300.4991 - mse: 300.4991\n",
      "Epoch 72/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 266.8149 - mse: 266.8149\n",
      "Epoch 72: mse did not improve from 288.04288\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268.3759 - mse: 268.3759\n",
      "Epoch 73/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.4304 - mse: 271.4304\n",
      "Epoch 73: mse improved from 288.04288 to 286.77948, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 272.4750 - mse: 272.4750\n",
      "Epoch 74/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 284.8729 - mse: 284.8729\n",
      "Epoch 74: mse improved from 286.77948 to 279.13788, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 284.8536 - mse: 284.8536\n",
      "Epoch 75/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 314.2307 - mse: 314.2307\n",
      "Epoch 75: mse did not improve from 279.13788\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 312.9600 - mse: 312.9600\n",
      "Epoch 76/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 292.5996 - mse: 292.5996\n",
      "Epoch 76: mse did not improve from 279.13788\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.7363 - mse: 291.7363\n",
      "Epoch 77/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.4048 - mse: 285.4048\n",
      "Epoch 77: mse did not improve from 279.13788\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.1192 - mse: 285.1192\n",
      "Epoch 78/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 260.4729 - mse: 260.4729\n",
      "Epoch 78: mse improved from 279.13788 to 272.55087, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261.3254 - mse: 261.3254\n",
      "Epoch 79/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.3298 - mse: 278.3298\n",
      "Epoch 79: mse improved from 272.55087 to 271.93008, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 277.6646 - mse: 277.6646\n",
      "Epoch 80/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.1015 - mse: 265.1015\n",
      "Epoch 80: mse improved from 271.93008 to 271.15503, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.9641 - mse: 265.9641\n",
      "Epoch 81/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 279.1127 - mse: 279.1127\n",
      "Epoch 81: mse did not improve from 271.15503\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.6412 - mse: 278.6412\n",
      "Epoch 82/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 272.0164 - mse: 272.0164\n",
      "Epoch 82: mse improved from 271.15503 to 270.32874, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.6978 - mse: 271.6978\n",
      "Epoch 83/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 262.4021 - mse: 262.4021\n",
      "Epoch 83: mse improved from 270.32874 to 268.57483, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 262.8425 - mse: 262.8425\n",
      "Epoch 84/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.4646 - mse: 251.4646\n",
      "Epoch 84: mse improved from 268.57483 to 264.50183, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.3437 - mse: 252.3437\n",
      "Epoch 85/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.1796 - mse: 255.1796\n",
      "Epoch 85: mse improved from 264.50183 to 261.38278, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.6939 - mse: 255.6939\n",
      "Epoch 86/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.9974 - mse: 265.9974\n",
      "Epoch 86: mse improved from 261.38278 to 261.13779, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.8184 - mse: 265.8184\n",
      "Epoch 87/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.8283 - mse: 271.8283\n",
      "Epoch 87: mse improved from 261.13779 to 259.46991, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.5424 - mse: 270.5424\n",
      "Epoch 88/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 259.3064 - mse: 259.3064\n",
      "Epoch 88: mse improved from 259.46991 to 257.04260, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 259.1010 - mse: 259.1010\n",
      "Epoch 89/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.8337 - mse: 251.8337\n",
      "Epoch 89: mse improved from 257.04260 to 254.74966, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.0424 - mse: 252.0424\n",
      "Epoch 90/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 243.5931 - mse: 243.5931\n",
      "Epoch 90: mse improved from 254.74966 to 252.89732, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 244.2560 - mse: 244.2560\n",
      "Epoch 91/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 244.4776 - mse: 244.4776\n",
      "Epoch 91: mse improved from 252.89732 to 249.02394, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 244.6597 - mse: 244.6597\n",
      "Epoch 92/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240.7280 - mse: 240.7280\n",
      "Epoch 92: mse did not improve from 249.02394\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.2284 - mse: 241.2284\n",
      "Epoch 93/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 243.7873 - mse: 243.7873\n",
      "Epoch 93: mse improved from 249.02394 to 247.88101, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 244.2409 - mse: 244.2409\n",
      "Epoch 94/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 247.3802 - mse: 247.3802\n",
      "Epoch 94: mse improved from 247.88101 to 246.49872, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 247.2334 - mse: 247.2334\n",
      "Epoch 95/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240.7160 - mse: 240.7160\n",
      "Epoch 95: mse improved from 246.49872 to 244.96101, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.1051 - mse: 241.1051\n",
      "Epoch 96/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 249.6668 - mse: 249.6668\n",
      "Epoch 96: mse improved from 244.96101 to 243.35783, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 249.3613 - mse: 249.3613\n",
      "Epoch 97/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 263.4120 - mse: 263.4120\n",
      "Epoch 97: mse improved from 243.35783 to 242.51239, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261.8733 - mse: 261.8733\n",
      "Epoch 98/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 239.1166 - mse: 239.1166\n",
      "Epoch 98: mse improved from 242.51239 to 241.48631, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 239.2826 - mse: 239.2826\n",
      "Epoch 99/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.3143 - mse: 232.3143\n",
      "Epoch 99: mse improved from 241.48631 to 237.00717, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.0886 - mse: 233.0886\n",
      "Epoch 100/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 250.7877 - mse: 250.7877\n",
      "Epoch 100: mse did not improve from 237.00717\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 250.3815 - mse: 250.3815\n",
      "Epoch 1/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236090.6875 - mse: 236090.6875\n",
      "Epoch 1: mse improved from inf to 137236.59375, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 222627.3906 - mse: 222627.3906\n",
      "Epoch 2/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 44411.7734 - mse: 44411.7734\n",
      "Epoch 2: mse improved from 137236.59375 to 27962.84180, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 43312.7891 - mse: 43312.7891\n",
      "Epoch 3/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3612.2458 - mse: 3612.2458\n",
      "Epoch 3: mse improved from 27962.84180 to 2960.51880, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3580.8945 - mse: 3580.8945\n",
      "Epoch 4/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1845.8794 - mse: 1845.8794\n",
      "Epoch 4: mse improved from 2960.51880 to 1679.61890, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1836.9658 - mse: 1836.9658\n",
      "Epoch 5/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1354.1620 - mse: 1354.1620\n",
      "Epoch 5: mse improved from 1679.61890 to 1269.51001, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1343.7653 - mse: 1343.7653\n",
      "Epoch 6/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1047.0032 - mse: 1047.0032\n",
      "Epoch 6: mse improved from 1269.51001 to 1037.47607, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1046.6626 - mse: 1046.6626\n",
      "Epoch 7/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 914.0837 - mse: 914.0837\n",
      "Epoch 7: mse improved from 1037.47607 to 908.91705, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 913.7330 - mse: 913.7330\n",
      "Epoch 8/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 816.3440 - mse: 816.3440\n",
      "Epoch 8: mse improved from 908.91705 to 815.95264, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 816.6409 - mse: 816.6409\n",
      "Epoch 9/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 826.7716 - mse: 826.7716\n",
      "Epoch 9: mse improved from 815.95264 to 783.09320, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 821.6780 - mse: 821.6780\n",
      "Epoch 10/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 754.6770 - mse: 754.6770\n",
      "Epoch 10: mse improved from 783.09320 to 724.31415, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 751.7106 - mse: 751.7106\n",
      "Epoch 11/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 691.2141 - mse: 691.2141\n",
      "Epoch 11: mse improved from 724.31415 to 704.37427, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 691.3450 - mse: 691.3450\n",
      "Epoch 12/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 665.7089 - mse: 665.7089\n",
      "Epoch 12: mse improved from 704.37427 to 670.14740, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 665.4985 - mse: 665.4985\n",
      "Epoch 13/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 594.2917 - mse: 594.2917\n",
      "Epoch 13: mse improved from 670.14740 to 617.12476, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 594.5190 - mse: 594.5190\n",
      "Epoch 14/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 607.7816 - mse: 607.7816\n",
      "Epoch 14: mse improved from 617.12476 to 609.34552, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 607.7971 - mse: 607.7971\n",
      "Epoch 15/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 631.3126 - mse: 631.3126\n",
      "Epoch 15: mse improved from 609.34552 to 581.93781, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 628.2860 - mse: 628.2860\n",
      "Epoch 16/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 659.7332 - mse: 659.7332\n",
      "Epoch 16: mse did not improve from 581.93781\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 658.4794 - mse: 658.4794\n",
      "Epoch 17/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 559.7849 - mse: 559.7849\n",
      "Epoch 17: mse improved from 581.93781 to 554.88525, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 559.6171 - mse: 559.6171\n",
      "Epoch 18/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 527.6542 - mse: 527.6542\n",
      "Epoch 18: mse improved from 554.88525 to 528.82733, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 527.6659 - mse: 527.6659\n",
      "Epoch 19/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 548.7438 - mse: 548.7438\n",
      "Epoch 19: mse did not improve from 528.82733\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 548.4858 - mse: 548.4858\n",
      "Epoch 20/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 520.2426 - mse: 520.2426\n",
      "Epoch 20: mse improved from 528.82733 to 522.30994, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 520.2529 - mse: 520.2529\n",
      "Epoch 21/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 468.0557 - mse: 468.0557\n",
      "Epoch 21: mse improved from 522.30994 to 499.84943, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 468.5401 - mse: 468.5401\n",
      "Epoch 22/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479.2964 - mse: 479.2964\n",
      "Epoch 22: mse improved from 499.84943 to 497.69528, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 481.2281 - mse: 481.2281\n",
      "Epoch 23/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 493.0392 - mse: 493.0392\n",
      "Epoch 23: mse improved from 497.69528 to 491.86902, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 492.5666 - mse: 492.5666\n",
      "Epoch 24/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 446.0732 - mse: 446.0732\n",
      "Epoch 24: mse improved from 491.86902 to 464.45587, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 449.6998 - mse: 449.6998\n",
      "Epoch 25/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 545.0833 - mse: 545.0833\n",
      "Epoch 25: mse did not improve from 464.45587\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 540.5208 - mse: 540.5208\n",
      "Epoch 26/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 442.2408 - mse: 442.2408\n",
      "Epoch 26: mse improved from 464.45587 to 458.64661, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 443.1311 - mse: 443.1311\n",
      "Epoch 27/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 433.3023 - mse: 433.3023\n",
      "Epoch 27: mse did not improve from 458.64661\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 434.5998 - mse: 434.5998\n",
      "Epoch 28/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429.5967 - mse: 429.5967\n",
      "Epoch 28: mse improved from 458.64661 to 435.83856, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.4070 - mse: 430.4070\n",
      "Epoch 29/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 469.4044 - mse: 469.4044\n",
      "Epoch 29: mse did not improve from 435.83856\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 467.7218 - mse: 467.7218\n",
      "Epoch 30/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 434.7163 - mse: 434.7163\n",
      "Epoch 30: mse improved from 435.83856 to 426.76978, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 434.7431 - mse: 434.7431\n",
      "Epoch 31/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457.1512 - mse: 457.1512\n",
      "Epoch 31: mse did not improve from 426.76978\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 455.9883 - mse: 455.9883\n",
      "Epoch 32/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.5062 - mse: 430.5062\n",
      "Epoch 32: mse improved from 426.76978 to 426.42017, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.5677 - mse: 430.5677\n",
      "Epoch 33/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 442.9594 - mse: 442.9594\n",
      "Epoch 33: mse did not improve from 426.42017\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 441.9980 - mse: 441.9980\n",
      "Epoch 34/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 387.6723 - mse: 387.6723\n",
      "Epoch 34: mse improved from 426.42017 to 406.90320, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390.1325 - mse: 390.1325\n",
      "Epoch 35/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.4879 - mse: 430.4879\n",
      "Epoch 35: mse did not improve from 406.90320\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.1096 - mse: 430.1096\n",
      "Epoch 36/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 395.3000 - mse: 395.3000\n",
      "Epoch 36: mse improved from 406.90320 to 405.00235, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 395.6907 - mse: 395.6907\n",
      "Epoch 37/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397.3654 - mse: 397.3654\n",
      "Epoch 37: mse improved from 405.00235 to 397.39429, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397.5780 - mse: 397.5780\n",
      "Epoch 38/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 398.5139 - mse: 398.5139\n",
      "Epoch 38: mse improved from 397.39429 to 397.24905, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 398.5013 - mse: 398.5013\n",
      "Epoch 39/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.5759 - mse: 401.5759\n",
      "Epoch 39: mse improved from 397.24905 to 393.44263, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.2478 - mse: 401.2478\n",
      "Epoch 40/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 406.6209 - mse: 406.6209\n",
      "Epoch 40: mse did not improve from 393.44263\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 404.8994 - mse: 404.8994\n",
      "Epoch 41/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.3547 - mse: 365.3547\n",
      "Epoch 41: mse improved from 393.44263 to 381.56110, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366.1653 - mse: 366.1653\n",
      "Epoch 42/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.7992 - mse: 375.7992\n",
      "Epoch 42: mse improved from 381.56110 to 377.84161, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.6911 - mse: 375.6911\n",
      "Epoch 43/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 361.9478 - mse: 361.9478\n",
      "Epoch 43: mse improved from 377.84161 to 367.28714, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362.4108 - mse: 362.4108\n",
      "Epoch 44/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366.0016 - mse: 366.0016\n",
      "Epoch 44: mse improved from 367.28714 to 361.68610, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366.0481 - mse: 366.0481\n",
      "Epoch 45/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.3571 - mse: 380.3571\n",
      "Epoch 45: mse did not improve from 361.68610\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.6717 - mse: 379.6717\n",
      "Epoch 46/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.4661 - mse: 346.4661\n",
      "Epoch 46: mse improved from 361.68610 to 359.46069, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 347.8367 - mse: 347.8367\n",
      "Epoch 47/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.2290 - mse: 365.2290\n",
      "Epoch 47: mse did not improve from 359.46069\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.0501 - mse: 365.0501\n",
      "Epoch 48/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.3457 - mse: 353.3457\n",
      "Epoch 48: mse improved from 359.46069 to 348.43546, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.4133 - mse: 353.4133\n",
      "Epoch 49/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 400.2989 - mse: 400.2989\n",
      "Epoch 49: mse did not improve from 348.43546\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 395.1802 - mse: 395.1802\n",
      "Epoch 50/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 349.9487 - mse: 349.9487\n",
      "Epoch 50: mse improved from 348.43546 to 346.29852, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 349.8061 - mse: 349.8061\n",
      "Epoch 51/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.4787 - mse: 333.4787\n",
      "Epoch 51: mse improved from 346.29852 to 338.55389, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.9900 - mse: 333.9900\n",
      "Epoch 52/100\n",
      "\u001b[1m181/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 342.0368 - mse: 342.0368\n",
      "Epoch 52: mse did not improve from 338.55389\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 342.0263 - mse: 342.0263\n",
      "Epoch 53/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344.1117 - mse: 344.1117\n",
      "Epoch 53: mse improved from 338.55389 to 338.06085, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 343.6254 - mse: 343.6254\n",
      "Epoch 54/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 349.6947 - mse: 349.6947\n",
      "Epoch 54: mse improved from 338.06085 to 335.36542, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 348.0042 - mse: 348.0042\n",
      "Epoch 55/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.3357 - mse: 333.3357\n",
      "Epoch 55: mse improved from 335.36542 to 330.17590, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.2979 - mse: 333.2979\n",
      "Epoch 56/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 348.7376 - mse: 348.7376\n",
      "Epoch 56: mse did not improve from 330.17590\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 347.8282 - mse: 347.8282\n",
      "Epoch 57/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.8500 - mse: 309.8500\n",
      "Epoch 57: mse did not improve from 330.17590\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.9541 - mse: 309.9541\n",
      "Epoch 58/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295.2409 - mse: 295.2409\n",
      "Epoch 58: mse improved from 330.17590 to 318.01624, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 298.6071 - mse: 298.6071\n",
      "Epoch 59/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 335.3105 - mse: 335.3105\n",
      "Epoch 59: mse did not improve from 318.01624\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 334.7849 - mse: 334.7849\n",
      "Epoch 60/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.3342 - mse: 333.3342\n",
      "Epoch 60: mse did not improve from 318.01624\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.3001 - mse: 333.3001\n",
      "Epoch 61/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.9699 - mse: 291.9699\n",
      "Epoch 61: mse improved from 318.01624 to 306.48630, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 292.1143 - mse: 292.1143\n",
      "Epoch 62/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 342.2835 - mse: 342.2835\n",
      "Epoch 62: mse did not improve from 306.48630\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 341.0867 - mse: 341.0867\n",
      "Epoch 63/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 312.7497 - mse: 312.7497\n",
      "Epoch 63: mse did not improve from 306.48630\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 312.2090 - mse: 312.2090\n",
      "Epoch 64/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 314.2672 - mse: 314.2672\n",
      "Epoch 64: mse did not improve from 306.48630\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 314.2327 - mse: 314.2327\n",
      "Epoch 65/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 318.8951 - mse: 318.8951\n",
      "Epoch 65: mse did not improve from 306.48630\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 318.7806 - mse: 318.7806\n",
      "Epoch 66/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.3966 - mse: 291.3966\n",
      "Epoch 66: mse improved from 306.48630 to 301.63397, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.6501 - mse: 291.6501\n",
      "Epoch 67/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.9037 - mse: 309.9037\n",
      "Epoch 67: mse did not improve from 301.63397\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.7323 - mse: 309.7323\n",
      "Epoch 68/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304.7054 - mse: 304.7054\n",
      "Epoch 68: mse did not improve from 301.63397\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304.5696 - mse: 304.5696\n",
      "Epoch 69/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304.0395 - mse: 304.0395\n",
      "Epoch 69: mse improved from 301.63397 to 293.36072, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 303.5249 - mse: 303.5249\n",
      "Epoch 70/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 319.3108 - mse: 319.3108\n",
      "Epoch 70: mse did not improve from 293.36072\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 317.8712 - mse: 317.8712\n",
      "Epoch 71/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 284.0618 - mse: 284.0618\n",
      "Epoch 71: mse did not improve from 293.36072\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 284.5907 - mse: 284.5907\n",
      "Epoch 72/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 272.3786 - mse: 272.3786\n",
      "Epoch 72: mse improved from 293.36072 to 292.92413, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.1047 - mse: 273.1047\n",
      "Epoch 73/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 288.5649 - mse: 288.5649\n",
      "Epoch 73: mse improved from 292.92413 to 289.01834, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 288.8279 - mse: 288.8279\n",
      "Epoch 74/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.4381 - mse: 310.4381\n",
      "Epoch 74: mse did not improve from 289.01834\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.9507 - mse: 309.9507\n",
      "Epoch 75/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 266.8899 - mse: 266.8899\n",
      "Epoch 75: mse improved from 289.01834 to 286.14789, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268.7448 - mse: 268.7448\n",
      "Epoch 76/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.5888 - mse: 275.5888\n",
      "Epoch 76: mse did not improve from 286.14789\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.6494 - mse: 275.6494\n",
      "Epoch 77/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 276.8334 - mse: 276.8334\n",
      "Epoch 77: mse did not improve from 286.14789\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 277.5720 - mse: 277.5720\n",
      "Epoch 78/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 244.4113 - mse: 244.4113\n",
      "Epoch 78: mse improved from 286.14789 to 270.84216, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 247.5420 - mse: 247.5420\n",
      "Epoch 79/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295.0985 - mse: 295.0985\n",
      "Epoch 79: mse did not improve from 270.84216\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295.0455 - mse: 295.0455\n",
      "Epoch 80/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 259.1939 - mse: 259.1939\n",
      "Epoch 80: mse did not improve from 270.84216\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 260.3272 - mse: 260.3272\n",
      "Epoch 81/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 279.5908 - mse: 279.5908\n",
      "Epoch 81: mse did not improve from 270.84216\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 279.1967 - mse: 279.1967\n",
      "Epoch 82/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 276.9757 - mse: 276.9757\n",
      "Epoch 82: mse did not improve from 270.84216\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 276.6719 - mse: 276.6719\n",
      "Epoch 83/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282.7639 - mse: 282.7639\n",
      "Epoch 83: mse did not improve from 270.84216\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 281.9699 - mse: 281.9699\n",
      "Epoch 1/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 224587.0469 - mse: 224587.0469\n",
      "Epoch 1: mse improved from inf to 138239.60938, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 222028.8750 - mse: 222028.8750\n",
      "Epoch 2/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61062.7383 - mse: 61062.7383\n",
      "Epoch 2: mse improved from 138239.60938 to 47394.94922, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59732.1133 - mse: 59732.1133\n",
      "Epoch 3/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7982.8008 - mse: 7982.8008\n",
      "Epoch 3: mse improved from 47394.94922 to 4934.47021, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7789.3130 - mse: 7789.3130\n",
      "Epoch 4/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2082.9819 - mse: 2082.9819\n",
      "Epoch 4: mse improved from 4934.47021 to 1891.02771, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2074.6797 - mse: 2074.6797\n",
      "Epoch 5/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1495.3480 - mse: 1495.3480\n",
      "Epoch 5: mse improved from 1891.02771 to 1414.86401, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1485.1538 - mse: 1485.1538\n",
      "Epoch 6/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1114.8423 - mse: 1114.8423\n",
      "Epoch 6: mse improved from 1414.86401 to 1115.27734, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1114.7894 - mse: 1114.7894\n",
      "Epoch 7/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1002.6185 - mse: 1002.6185\n",
      "Epoch 7: mse improved from 1115.27734 to 958.14819, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1002.3973 - mse: 1002.3973\n",
      "Epoch 8/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 895.1197 - mse: 895.1197\n",
      "Epoch 8: mse improved from 958.14819 to 872.76367, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 893.8762 - mse: 893.8762\n",
      "Epoch 9/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 816.2148 - mse: 816.2148\n",
      "Epoch 9: mse improved from 872.76367 to 791.53033, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 815.6624 - mse: 815.6624\n",
      "Epoch 10/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 738.7911 - mse: 738.7911\n",
      "Epoch 10: mse improved from 791.53033 to 740.91821, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 738.5998 - mse: 738.5998\n",
      "Epoch 11/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 713.9014 - mse: 713.9014\n",
      "Epoch 11: mse improved from 740.91821 to 682.25427, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 712.2078 - mse: 712.2078\n",
      "Epoch 12/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 696.2950 - mse: 696.2950\n",
      "Epoch 12: mse improved from 682.25427 to 673.99329, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 695.4028 - mse: 695.4028\n",
      "Epoch 13/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 590.8971 - mse: 590.8971\n",
      "Epoch 13: mse improved from 673.99329 to 620.96606, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 593.4207 - mse: 593.4207\n",
      "Epoch 14/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 622.2492 - mse: 622.2492\n",
      "Epoch 14: mse improved from 620.96606 to 618.20386, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 622.0052 - mse: 622.0052\n",
      "Epoch 15/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 594.5222 - mse: 594.5222\n",
      "Epoch 15: mse improved from 618.20386 to 584.22247, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 593.3214 - mse: 593.3214\n",
      "Epoch 16/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 557.9511 - mse: 557.9511\n",
      "Epoch 16: mse improved from 584.22247 to 553.38702, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 558.2118 - mse: 558.2118\n",
      "Epoch 17/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 580.4929 - mse: 580.4929\n",
      "Epoch 17: mse did not improve from 553.38702\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 579.3929 - mse: 579.3929\n",
      "Epoch 18/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 523.3494 - mse: 523.3494\n",
      "Epoch 18: mse improved from 553.38702 to 526.89673, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 523.6662 - mse: 523.6662\n",
      "Epoch 19/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 536.7111 - mse: 536.7111\n",
      "Epoch 19: mse improved from 526.89673 to 521.67651, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 536.2214 - mse: 536.2214\n",
      "Epoch 20/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 527.7108 - mse: 527.7108\n",
      "Epoch 20: mse improved from 521.67651 to 517.92621, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 527.2561 - mse: 527.2561\n",
      "Epoch 21/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 480.2396 - mse: 480.2396\n",
      "Epoch 21: mse improved from 517.92621 to 500.43289, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 482.2704 - mse: 482.2704\n",
      "Epoch 22/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 494.6098 - mse: 494.6098\n",
      "Epoch 22: mse improved from 500.43289 to 487.81979, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 493.5400 - mse: 493.5400\n",
      "Epoch 23/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 453.0996 - mse: 453.0996\n",
      "Epoch 23: mse improved from 487.81979 to 468.39294, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 454.6023 - mse: 454.6023\n",
      "Epoch 24/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479.3120 - mse: 479.3120\n",
      "Epoch 24: mse did not improve from 468.39294\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479.0078 - mse: 479.0078\n",
      "Epoch 25/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 468.7326 - mse: 468.7326\n",
      "Epoch 25: mse improved from 468.39294 to 450.89276, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 468.3250 - mse: 468.3250\n",
      "Epoch 26/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 489.8046 - mse: 489.8046\n",
      "Epoch 26: mse improved from 450.89276 to 450.66479, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 489.0132 - mse: 489.0132\n",
      "Epoch 27/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.7513 - mse: 458.7513\n",
      "Epoch 27: mse improved from 450.66479 to 442.16376, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.5862 - mse: 458.5862\n",
      "Epoch 28/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.2955 - mse: 421.2955\n",
      "Epoch 28: mse improved from 442.16376 to 431.26733, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.3835 - mse: 422.3835\n",
      "Epoch 29/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 449.9574 - mse: 449.9574\n",
      "Epoch 29: mse did not improve from 431.26733\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 446.7747 - mse: 446.7747\n",
      "Epoch 30/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 378.8684 - mse: 378.8684\n",
      "Epoch 30: mse improved from 431.26733 to 412.46487, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.3777 - mse: 379.3777\n",
      "Epoch 31/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 378.1913 - mse: 378.1913\n",
      "Epoch 31: mse improved from 412.46487 to 406.84705, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.8393 - mse: 380.8393\n",
      "Epoch 32/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413.3196 - mse: 413.3196\n",
      "Epoch 32: mse did not improve from 406.84705\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413.2816 - mse: 413.2816\n",
      "Epoch 33/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 436.8081 - mse: 436.8081\n",
      "Epoch 33: mse did not improve from 406.84705\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 434.8584 - mse: 434.8584\n",
      "Epoch 34/100\n",
      "\u001b[1m181/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 367.3075 - mse: 367.3075\n",
      "Epoch 34: mse improved from 406.84705 to 380.24472, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.7697 - mse: 368.7697\n",
      "Epoch 35/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 402.5862 - mse: 402.5862\n",
      "Epoch 35: mse did not improve from 380.24472\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.7209 - mse: 401.7209\n",
      "Epoch 36/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 392.0240 - mse: 392.0240\n",
      "Epoch 36: mse did not improve from 380.24472\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 391.8686 - mse: 391.8686\n",
      "Epoch 37/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 385.6187 - mse: 385.6187\n",
      "Epoch 37: mse improved from 380.24472 to 379.30276, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 384.8549 - mse: 384.8549\n",
      "Epoch 38/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.6122 - mse: 381.6122\n",
      "Epoch 38: mse improved from 379.30276 to 377.95676, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.3422 - mse: 381.3422\n",
      "Epoch 39/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.6244 - mse: 373.6244\n",
      "Epoch 39: mse improved from 377.95676 to 370.44724, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.4976 - mse: 373.4976\n",
      "Epoch 40/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.9291 - mse: 368.9291\n",
      "Epoch 40: mse improved from 370.44724 to 363.96832, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.5316 - mse: 368.5316\n",
      "Epoch 41/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344.8128 - mse: 344.8128\n",
      "Epoch 41: mse improved from 363.96832 to 358.85074, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 345.4677 - mse: 345.4677\n",
      "Epoch 42/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 361.2757 - mse: 361.2757\n",
      "Epoch 42: mse improved from 358.85074 to 353.02942, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 360.8463 - mse: 360.8463\n",
      "Epoch 43/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.3075 - mse: 353.3075\n",
      "Epoch 43: mse improved from 353.02942 to 348.89374, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353.1097 - mse: 353.1097\n",
      "Epoch 44/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 378.2202 - mse: 378.2202\n",
      "Epoch 44: mse did not improve from 348.89374\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376.7758 - mse: 376.7758\n",
      "Epoch 45/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.3567 - mse: 381.3567\n",
      "Epoch 45: mse did not improve from 348.89374\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377.9482 - mse: 377.9482\n",
      "Epoch 46/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331.3811 - mse: 331.3811\n",
      "Epoch 46: mse improved from 348.89374 to 336.68155, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331.9517 - mse: 331.9517\n",
      "Epoch 47/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340.8625 - mse: 340.8625\n",
      "Epoch 47: mse did not improve from 336.68155\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 341.1145 - mse: 341.1145\n",
      "Epoch 48/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 335.7516 - mse: 335.7516\n",
      "Epoch 48: mse improved from 336.68155 to 336.49054, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 336.0372 - mse: 336.0372\n",
      "Epoch 49/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331.0504 - mse: 331.0504\n",
      "Epoch 49: mse did not improve from 336.49054\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331.7452 - mse: 331.7452\n",
      "Epoch 50/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 324.5409 - mse: 324.5409\n",
      "Epoch 50: mse improved from 336.49054 to 324.73651, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 324.9787 - mse: 324.9787\n",
      "Epoch 51/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 338.1052 - mse: 338.1052\n",
      "Epoch 51: mse did not improve from 324.73651\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 337.2943 - mse: 337.2943\n",
      "Epoch 52/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 307.8677 - mse: 307.8677\n",
      "Epoch 52: mse did not improve from 324.73651\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 308.8861 - mse: 308.8861\n",
      "Epoch 53/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 276.6953 - mse: 276.6953\n",
      "Epoch 53: mse improved from 324.73651 to 312.35971, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 279.5433 - mse: 279.5433\n",
      "Epoch 54/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.2753 - mse: 333.2753\n",
      "Epoch 54: mse did not improve from 312.35971\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 332.5082 - mse: 332.5082\n",
      "Epoch 55/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 305.1947 - mse: 305.1947\n",
      "Epoch 55: mse did not improve from 312.35971\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 306.6912 - mse: 306.6912\n",
      "Epoch 56/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315.5355 - mse: 315.5355\n",
      "Epoch 56: mse did not improve from 312.35971\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315.1978 - mse: 315.1978\n",
      "Epoch 57/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 301.6633 - mse: 301.6633\n",
      "Epoch 57: mse did not improve from 312.35971\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 302.7957 - mse: 302.7957\n",
      "Epoch 58/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.2447 - mse: 291.2447\n",
      "Epoch 58: mse improved from 312.35971 to 301.91727, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.9629 - mse: 291.9629\n",
      "Epoch 59/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315.7031 - mse: 315.7031\n",
      "Epoch 59: mse did not improve from 301.91727\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315.0611 - mse: 315.0611\n",
      "Epoch 60/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.3162 - mse: 278.3162\n",
      "Epoch 60: mse improved from 301.91727 to 296.63522, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 280.8270 - mse: 280.8270\n",
      "Epoch 61/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 323.4862 - mse: 323.4862\n",
      "Epoch 61: mse did not improve from 296.63522\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 322.2923 - mse: 322.2923\n",
      "Epoch 62/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 288.8624 - mse: 288.8624\n",
      "Epoch 62: mse did not improve from 296.63522\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.4682 - mse: 289.4682\n",
      "Epoch 63/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304.4311 - mse: 304.4311\n",
      "Epoch 63: mse did not improve from 296.63522\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304.2094 - mse: 304.2094\n",
      "Epoch 64/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 281.0102 - mse: 281.0102\n",
      "Epoch 64: mse improved from 296.63522 to 294.68112, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282.6989 - mse: 282.6989\n",
      "Epoch 65/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 287.0996 - mse: 287.0996\n",
      "Epoch 65: mse improved from 294.68112 to 289.16925, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 287.5777 - mse: 287.5777\n",
      "Epoch 66/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 316.7357 - mse: 316.7357\n",
      "Epoch 66: mse did not improve from 289.16925\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315.8020 - mse: 315.8020\n",
      "Epoch 67/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.3816 - mse: 289.3816\n",
      "Epoch 67: mse improved from 289.16925 to 289.04443, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.6023 - mse: 289.6023\n",
      "Epoch 68/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 293.4272 - mse: 293.4272\n",
      "Epoch 68: mse did not improve from 289.04443\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 293.1709 - mse: 293.1709\n",
      "Epoch 69/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 283.2219 - mse: 283.2219\n",
      "Epoch 69: mse did not improve from 289.04443\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 283.8687 - mse: 283.8687\n",
      "Epoch 70/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 276.3579 - mse: 276.3579\n",
      "Epoch 70: mse improved from 289.04443 to 278.38327, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 277.0525 - mse: 277.0525\n",
      "Epoch 71/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.6888 - mse: 309.6888\n",
      "Epoch 71: mse did not improve from 278.38327\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 308.1959 - mse: 308.1959\n",
      "Epoch 72/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 298.8285 - mse: 298.8285\n",
      "Epoch 72: mse improved from 278.38327 to 277.63031, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 296.7480 - mse: 296.7480\n",
      "Epoch 73/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 292.4790 - mse: 292.4790\n",
      "Epoch 73: mse did not improve from 277.63031\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 292.3791 - mse: 292.3791\n",
      "Epoch 74/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.9494 - mse: 286.9494\n",
      "Epoch 74: mse did not improve from 277.63031\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.3257 - mse: 286.3257\n",
      "Epoch 75/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 258.6226 - mse: 258.6226\n",
      "Epoch 75: mse improved from 277.63031 to 274.74411, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 260.0060 - mse: 260.0060\n",
      "Epoch 76/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 279.3617 - mse: 279.3617\n",
      "Epoch 76: mse did not improve from 274.74411\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.8647 - mse: 278.8647\n",
      "Epoch 77/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 279.7031 - mse: 279.7031\n",
      "Epoch 77: mse improved from 274.74411 to 272.68808, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 279.0563 - mse: 279.0563\n",
      "Epoch 78/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.6464 - mse: 285.6464\n",
      "Epoch 78: mse improved from 272.68808 to 268.63007, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 283.9497 - mse: 283.9497\n",
      "Epoch 79/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.7359 - mse: 291.7359\n",
      "Epoch 79: mse did not improve from 268.63007\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 290.6446 - mse: 290.6446\n",
      "Epoch 80/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.5216 - mse: 265.5216\n",
      "Epoch 80: mse improved from 268.63007 to 266.60342, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.4435 - mse: 265.4435\n",
      "Epoch 81/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261.4061 - mse: 261.4061\n",
      "Epoch 81: mse improved from 266.60342 to 265.31329, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261.5462 - mse: 261.5462\n",
      "Epoch 82/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 269.1284 - mse: 269.1284\n",
      "Epoch 82: mse did not improve from 265.31329\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268.7796 - mse: 268.7796\n",
      "Epoch 83/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 237.0666 - mse: 237.0666\n",
      "Epoch 83: mse improved from 265.31329 to 258.18518, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 239.7838 - mse: 239.7838\n",
      "Epoch 84/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 262.3562 - mse: 262.3562\n",
      "Epoch 84: mse did not improve from 258.18518\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 262.5736 - mse: 262.5736\n",
      "Epoch 85/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 272.2302 - mse: 272.2302\n",
      "Epoch 85: mse improved from 258.18518 to 258.00317, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.7075 - mse: 271.7075\n",
      "Epoch 86/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 277.0050 - mse: 277.0050\n",
      "Epoch 86: mse did not improve from 258.00317\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.2577 - mse: 275.2577\n",
      "Epoch 87/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 239.0633 - mse: 239.0633\n",
      "Epoch 87: mse did not improve from 258.00317\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240.3293 - mse: 240.3293\n",
      "Epoch 88/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.4341 - mse: 232.4341\n",
      "Epoch 88: mse improved from 258.00317 to 250.79512, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 234.8732 - mse: 234.8732\n",
      "Epoch 89/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 254.7438 - mse: 254.7438\n",
      "Epoch 89: mse did not improve from 250.79512\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.0539 - mse: 255.0539\n",
      "Epoch 90/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 262.3609 - mse: 262.3609\n",
      "Epoch 90: mse did not improve from 250.79512\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261.8991 - mse: 261.8991\n",
      "Epoch 91/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.5195 - mse: 252.5195\n",
      "Epoch 91: mse did not improve from 250.79512\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.6620 - mse: 252.6620\n",
      "Epoch 92/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253.1594 - mse: 253.1594\n",
      "Epoch 92: mse did not improve from 250.79512\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253.0020 - mse: 253.0020\n",
      "Epoch 93/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.2431 - mse: 245.2431\n",
      "Epoch 93: mse improved from 250.79512 to 248.13593, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.4629 - mse: 245.4629\n",
      "Epoch 94/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.1337 - mse: 252.1337\n",
      "Epoch 94: mse improved from 248.13593 to 241.58957, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.6210 - mse: 251.6210\n",
      "Epoch 95/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.3501 - mse: 264.3501\n",
      "Epoch 95: mse did not improve from 241.58957\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.2796 - mse: 264.2796\n",
      "Epoch 96/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 243.1138 - mse: 243.1138\n",
      "Epoch 96: mse did not improve from 241.58957\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 243.2620 - mse: 243.2620\n",
      "Epoch 97/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.1982 - mse: 210.1982\n",
      "Epoch 97: mse improved from 241.58957 to 233.79204, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 211.5551 - mse: 211.5551\n",
      "Epoch 98/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.9971 - mse: 264.9971\n",
      "Epoch 98: mse did not improve from 233.79204\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.5734 - mse: 264.5734\n",
      "Epoch 99/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 227.4475 - mse: 227.4475\n",
      "Epoch 99: mse did not improve from 233.79204\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 228.2531 - mse: 228.2531\n",
      "Epoch 100/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 234.4094 - mse: 234.4094\n",
      "Epoch 100: mse did not improve from 233.79204\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 234.4433 - mse: 234.4433\n",
      "Epoch 1/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 223500.7656 - mse: 223500.7656\n",
      "Epoch 1: mse improved from inf to 135363.01562, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 219177.4688 - mse: 219177.4688\n",
      "Epoch 2/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52000.9531 - mse: 52000.9531\n",
      "Epoch 2: mse improved from 135363.01562 to 34296.14844, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49794.0156 - mse: 49794.0156\n",
      "Epoch 3/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3859.9292 - mse: 3859.9292\n",
      "Epoch 3: mse improved from 34296.14844 to 2921.27539, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3832.1292 - mse: 3832.1292\n",
      "Epoch 4/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1759.8057 - mse: 1759.8057\n",
      "Epoch 4: mse improved from 2921.27539 to 1507.19287, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1733.6737 - mse: 1733.6737\n",
      "Epoch 5/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1332.2637 - mse: 1332.2637\n",
      "Epoch 5: mse improved from 1507.19287 to 1153.22107, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1307.6317 - mse: 1307.6317\n",
      "Epoch 6/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 972.4675 - mse: 972.4675\n",
      "Epoch 6: mse improved from 1153.22107 to 937.12140, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 969.8951 - mse: 969.8951\n",
      "Epoch 7/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 849.5372 - mse: 849.5372\n",
      "Epoch 7: mse improved from 937.12140 to 829.17560, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 845.9318 - mse: 845.9318\n",
      "Epoch 8/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 723.4656 - mse: 723.4656\n",
      "Epoch 8: mse improved from 829.17560 to 727.46094, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 724.6058 - mse: 724.6058\n",
      "Epoch 9/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 719.5143 - mse: 719.5143\n",
      "Epoch 9: mse improved from 727.46094 to 671.20386, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 714.9453 - mse: 714.9453\n",
      "Epoch 10/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 632.9656 - mse: 632.9656\n",
      "Epoch 10: mse improved from 671.20386 to 633.09253, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 633.0047 - mse: 633.0047\n",
      "Epoch 11/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 603.1329 - mse: 603.1329\n",
      "Epoch 11: mse improved from 633.09253 to 587.98370, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 602.1682 - mse: 602.1682\n",
      "Epoch 12/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 546.5724 - mse: 546.5724\n",
      "Epoch 12: mse improved from 587.98370 to 557.69653, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 546.6830 - mse: 546.6830\n",
      "Epoch 13/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 601.4992 - mse: 601.4992\n",
      "Epoch 13: mse improved from 557.69653 to 539.55676, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 596.7285 - mse: 596.7285\n",
      "Epoch 14/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 572.9206 - mse: 572.9206\n",
      "Epoch 14: mse did not improve from 539.55676\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 572.7610 - mse: 572.7610\n",
      "Epoch 15/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 498.2225 - mse: 498.2225\n",
      "Epoch 15: mse improved from 539.55676 to 503.55792, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 499.0432 - mse: 499.0432\n",
      "Epoch 16/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 533.8865 - mse: 533.8865\n",
      "Epoch 16: mse did not improve from 503.55792\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 530.5309 - mse: 530.5309\n",
      "Epoch 17/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.8355 - mse: 463.8355\n",
      "Epoch 17: mse improved from 503.55792 to 471.59589, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 464.9291 - mse: 464.9291\n",
      "Epoch 18/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 496.4556 - mse: 496.4556\n",
      "Epoch 18: mse improved from 471.59589 to 469.09570, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 491.6366 - mse: 491.6366\n",
      "Epoch 19/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 436.9268 - mse: 436.9268\n",
      "Epoch 19: mse improved from 469.09570 to 439.59824, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 437.5171 - mse: 437.5171\n",
      "Epoch 20/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 507.8755 - mse: 507.8755\n",
      "Epoch 20: mse improved from 439.59824 to 438.83206, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 505.0676 - mse: 505.0676\n",
      "Epoch 21/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431.4174 - mse: 431.4174\n",
      "Epoch 21: mse improved from 438.83206 to 436.30542, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431.4875 - mse: 431.4875\n",
      "Epoch 22/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.3294 - mse: 401.3294\n",
      "Epoch 22: mse improved from 436.30542 to 410.05676, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.1454 - mse: 403.1454\n",
      "Epoch 23/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 428.5634 - mse: 428.5634\n",
      "Epoch 23: mse did not improve from 410.05676\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.6080 - mse: 427.6080\n",
      "Epoch 24/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.2168 - mse: 381.2168\n",
      "Epoch 24: mse improved from 410.05676 to 395.51440, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 383.3515 - mse: 383.3515\n",
      "Epoch 25/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409.1794 - mse: 409.1794\n",
      "Epoch 25: mse improved from 395.51440 to 394.61102, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 408.0800 - mse: 408.0800\n",
      "Epoch 26/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.1159 - mse: 407.1159\n",
      "Epoch 26: mse improved from 394.61102 to 391.25177, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 406.9580 - mse: 406.9580\n",
      "Epoch 27/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 399.5470 - mse: 399.5470\n",
      "Epoch 27: mse did not improve from 391.25177\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 398.6406 - mse: 398.6406\n",
      "Epoch 28/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 355.3445 - mse: 355.3445\n",
      "Epoch 28: mse improved from 391.25177 to 377.99194, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 357.6035 - mse: 357.6035\n",
      "Epoch 29/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 355.3390 - mse: 355.3390\n",
      "Epoch 29: mse improved from 377.99194 to 368.32898, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 356.7134 - mse: 356.7134\n",
      "Epoch 30/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 408.2679 - mse: 408.2679\n",
      "Epoch 30: mse did not improve from 368.32898\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.6832 - mse: 403.6832\n",
      "Epoch 31/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362.7610 - mse: 362.7610\n",
      "Epoch 31: mse improved from 368.32898 to 365.09332, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362.8314 - mse: 362.8314\n",
      "Epoch 32/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.3994 - mse: 373.3994\n",
      "Epoch 32: mse improved from 365.09332 to 361.03372, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.5966 - mse: 371.5966\n",
      "Epoch 33/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.3680 - mse: 371.3680\n",
      "Epoch 33: mse did not improve from 361.03372\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.6960 - mse: 369.6960\n",
      "Epoch 34/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 339.6155 - mse: 339.6155\n",
      "Epoch 34: mse improved from 361.03372 to 348.05576, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340.1347 - mse: 340.1347\n",
      "Epoch 35/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 325.5851 - mse: 325.5851\n",
      "Epoch 35: mse improved from 348.05576 to 336.48672, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 326.6279 - mse: 326.6279\n",
      "Epoch 36/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.7021 - mse: 346.7021\n",
      "Epoch 36: mse did not improve from 336.48672\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 345.5508 - mse: 345.5508\n",
      "Epoch 37/100\n",
      "\u001b[1m181/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 300.9890 - mse: 300.9890\n",
      "Epoch 37: mse improved from 336.48672 to 328.94907, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 303.9635 - mse: 303.9635\n",
      "Epoch 38/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.9667 - mse: 333.9667\n",
      "Epoch 38: mse did not improve from 328.94907\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.7282 - mse: 333.7282\n",
      "Epoch 39/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 347.7458 - mse: 347.7458\n",
      "Epoch 39: mse did not improve from 328.94907\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 345.7867 - mse: 345.7867\n",
      "Epoch 40/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 343.8364 - mse: 343.8364\n",
      "Epoch 40: mse did not improve from 328.94907\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340.6162 - mse: 340.6162\n",
      "Epoch 41/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.1292 - mse: 286.1292\n",
      "Epoch 41: mse improved from 328.94907 to 321.65237, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.9921 - mse: 289.9921\n",
      "Epoch 42/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304.6807 - mse: 304.6807\n",
      "Epoch 42: mse improved from 321.65237 to 313.97903, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304.7732 - mse: 304.7732\n",
      "Epoch 43/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 298.3903 - mse: 298.3903\n",
      "Epoch 43: mse improved from 313.97903 to 309.63611, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 299.6300 - mse: 299.6300\n",
      "Epoch 44/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 320.0444 - mse: 320.0444\n",
      "Epoch 44: mse did not improve from 309.63611\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 318.9922 - mse: 318.9922\n",
      "Epoch 45/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282.7942 - mse: 282.7942\n",
      "Epoch 45: mse improved from 309.63611 to 308.48126, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.4453 - mse: 285.4453\n",
      "Epoch 46/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261.5301 - mse: 261.5301\n",
      "Epoch 46: mse improved from 308.48126 to 296.88895, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 264.4392 - mse: 264.4392\n",
      "Epoch 47/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.6690 - mse: 291.6690\n",
      "Epoch 47: mse improved from 296.88895 to 293.88284, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.6910 - mse: 291.6910\n",
      "Epoch 48/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 312.7856 - mse: 312.7856\n",
      "Epoch 48: mse did not improve from 293.88284\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311.4277 - mse: 311.4277\n",
      "Epoch 49/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 307.6385 - mse: 307.6385\n",
      "Epoch 49: mse did not improve from 293.88284\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 307.2959 - mse: 307.2959\n",
      "Epoch 50/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 277.3581 - mse: 277.3581\n",
      "Epoch 50: mse improved from 293.88284 to 288.54175, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 278.3963 - mse: 278.3963\n",
      "Epoch 51/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.3112 - mse: 286.3112\n",
      "Epoch 51: mse did not improve from 288.54175\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.4931 - mse: 286.4931\n",
      "Epoch 52/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.5307 - mse: 271.5307\n",
      "Epoch 52: mse improved from 288.54175 to 277.50040, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 272.2643 - mse: 272.2643\n",
      "Epoch 53/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 294.5338 - mse: 294.5338\n",
      "Epoch 53: mse did not improve from 277.50040\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 294.2933 - mse: 294.2933\n",
      "Epoch 54/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 293.4435 - mse: 293.4435\n",
      "Epoch 54: mse did not improve from 277.50040\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 292.5807 - mse: 292.5807\n",
      "Epoch 55/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 277.7997 - mse: 277.7997\n",
      "Epoch 55: mse improved from 277.50040 to 275.13760, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 277.7566 - mse: 277.7566\n",
      "Epoch 56/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282.4742 - mse: 282.4742\n",
      "Epoch 56: mse did not improve from 275.13760\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282.0545 - mse: 282.0545\n",
      "Epoch 57/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.7753 - mse: 270.7753\n",
      "Epoch 57: mse did not improve from 275.13760\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.9623 - mse: 270.9623\n",
      "Epoch 58/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.1612 - mse: 245.1612\n",
      "Epoch 58: mse improved from 275.13760 to 265.79767, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 246.6684 - mse: 246.6684\n",
      "Epoch 59/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.0885 - mse: 265.0885\n",
      "Epoch 59: mse did not improve from 265.79767\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.3628 - mse: 265.3628\n",
      "Epoch 60/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 266.2642 - mse: 266.2642\n",
      "Epoch 60: mse did not improve from 265.79767\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 266.3725 - mse: 266.3725\n",
      "Epoch 61/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 269.6460 - mse: 269.6460\n",
      "Epoch 61: mse did not improve from 265.79767\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 269.4381 - mse: 269.4381\n",
      "Epoch 62/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.1166 - mse: 273.1166\n",
      "Epoch 62: mse did not improve from 265.79767\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 272.6495 - mse: 272.6495\n",
      "Epoch 63/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 272.3894 - mse: 272.3894\n",
      "Epoch 63: mse improved from 265.79767 to 259.77362, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.0641 - mse: 271.0641\n",
      "Epoch 64/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268.6443 - mse: 268.6443\n",
      "Epoch 64: mse did not improve from 259.77362\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 267.9632 - mse: 267.9632\n",
      "Epoch 65/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 254.8775 - mse: 254.8775\n",
      "Epoch 65: mse did not improve from 259.77362\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.1287 - mse: 255.1287\n",
      "Epoch 66/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 242.0697 - mse: 242.0697\n",
      "Epoch 66: mse improved from 259.77362 to 245.94247, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 242.9554 - mse: 242.9554\n",
      "Epoch 67/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295.4610 - mse: 295.4610\n",
      "Epoch 67: mse did not improve from 245.94247\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 290.7580 - mse: 290.7580\n",
      "Epoch 68/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 254.9013 - mse: 254.9013\n",
      "Epoch 68: mse did not improve from 245.94247\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 254.6698 - mse: 254.6698\n",
      "Epoch 69/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268.6197 - mse: 268.6197\n",
      "Epoch 69: mse did not improve from 245.94247\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 266.8643 - mse: 266.8643\n",
      "Epoch 70/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.3053 - mse: 251.3053\n",
      "Epoch 70: mse did not improve from 245.94247\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.2171 - mse: 251.2171\n",
      "Epoch 71/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 250.4696 - mse: 250.4696\n",
      "Epoch 71: mse did not improve from 245.94247\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 250.5548 - mse: 250.5548\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "validation_loss = []\n",
    "history_list = []\n",
    "\n",
    "for train_index, val_index in kfold.split(X_train, y_train) :\n",
    "    model = create_model()\n",
    "\n",
    "    stop = EarlyStopping(monitor = \"mse\", patience = 5, mode = \"min\")\n",
    "    checkpoint = ModelCheckpoint(filepath = \"my_best_model\" + str(count + 1) + \".keras\", monitor = \"mse\", verbose = 1, save_best_only = True, mode = \"min\")\n",
    "    callbacks_list = [stop, checkpoint]\n",
    "\n",
    "    history = model.fit([X_train[train_index] for _ in range (16)], y_train[train_index], epochs = 100, callbacks = callbacks_list, batch_size = 32)\n",
    "    history_list.append(history)\n",
    "    validation_loss.append(model.evaluate([X_train[val_index] for _ in range (16)], y_train[val_index], return_dict = True, verbose = 0)[\"loss\"])\n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for hist in history_list :\n",
    "    plt.plot(hist.history[\"loss\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mse and standard deviation:  202.67916107177734 115.26253612386142\n"
     ]
    }
   ],
   "source": [
    "print(\"average mse and standard deviation: \", np.mean(validation_loss), np.std(validation_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model = []\n",
    "for i in range (1, 6) :\n",
    "    all_model.append(load_model(\"my_best_model\" + str(i) + \".keras\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "model_predict_moyenne = all_model[0].predict([X_test for _ in range (16)])\n",
    "\n",
    "for i in range(1, 5) :\n",
    "    model_predict_moyenne += all_model[i].predict([X_test for _ in range (16)])\n",
    "\n",
    "model_predict_moyenne = np.round(model_predict_moyenne/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error:  1.919669620000001\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean error: \", (np.sum(np.abs(model_predict_moyenne[:, 0] - y_test)) / len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[929.     , 426.     , 662.     ,  29.     , 606.     ],\n",
       "       [927.17741, 425.18517, 659.32114,  24.10143, 605.93609]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([model_predict_moyenne[:, 0], y_test])[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

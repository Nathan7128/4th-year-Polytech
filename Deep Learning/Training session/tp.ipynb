{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras import Input\n",
    "from keras.layers import Concatenate\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>squareMeters</th>\n",
       "      <th>numberOfRooms</th>\n",
       "      <th>hasYard</th>\n",
       "      <th>hasPool</th>\n",
       "      <th>floors</th>\n",
       "      <th>cityCode</th>\n",
       "      <th>cityPartRange</th>\n",
       "      <th>numPrevOwners</th>\n",
       "      <th>made</th>\n",
       "      <th>isNewBuilt</th>\n",
       "      <th>hasStormProtector</th>\n",
       "      <th>basement</th>\n",
       "      <th>attic</th>\n",
       "      <th>garage</th>\n",
       "      <th>hasStorageRoom</th>\n",
       "      <th>hasGuestRoom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77747</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>98938</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4829</td>\n",
       "      <td>4204</td>\n",
       "      <td>455</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7786197.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28459</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>50114</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3570</td>\n",
       "      <td>9363</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2846923.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34668</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>17366</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2002</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3476</td>\n",
       "      <td>7549</td>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3475230.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64335</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>65939</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7301</td>\n",
       "      <td>6989</td>\n",
       "      <td>802</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6435779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22875</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>8661</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6394</td>\n",
       "      <td>2119</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2295511.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   squareMeters  numberOfRooms  hasYard  hasPool  floors  cityCode  \\\n",
       "0         77747             50        1        1      72     98938   \n",
       "1         28459             52        0        0       4     50114   \n",
       "2         34668             69        1        1      12     17366   \n",
       "3         64335              4        0        0      83     65939   \n",
       "4         22875             86        1        0      95      8661   \n",
       "\n",
       "   cityPartRange  numPrevOwners  made  isNewBuilt  hasStormProtector  \\\n",
       "0              8             10  2014           0                  1   \n",
       "1              1              7  2012           1                  1   \n",
       "2              8              7  2002           0                  1   \n",
       "3              6              9  2020           1                  0   \n",
       "4              5              7  1994           0                  0   \n",
       "\n",
       "   basement  attic  garage  hasStorageRoom  hasGuestRoom      price  \n",
       "0      4829   4204     455               0             3  7786197.4  \n",
       "1      3570   9363     318               0             6  2846923.2  \n",
       "2      3476   7549     503               1             7  3475230.2  \n",
       "3      7301   6989     802               0             1  6435779.0  \n",
       "4      6394   2119     542               0             7  2295511.4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The data describe the characteristics of a house (surface, number of rooms...)\n",
    "# and you should predict its price\n",
    "\n",
    "# The metrics for the ranking will be based on the mean square error ('mse')\n",
    "\n",
    "df_train = pd.read_csv(\"Train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>squareMeters</th>\n",
       "      <th>numberOfRooms</th>\n",
       "      <th>hasYard</th>\n",
       "      <th>hasPool</th>\n",
       "      <th>floors</th>\n",
       "      <th>cityCode</th>\n",
       "      <th>cityPartRange</th>\n",
       "      <th>numPrevOwners</th>\n",
       "      <th>made</th>\n",
       "      <th>isNewBuilt</th>\n",
       "      <th>hasStormProtector</th>\n",
       "      <th>basement</th>\n",
       "      <th>attic</th>\n",
       "      <th>garage</th>\n",
       "      <th>hasStorageRoom</th>\n",
       "      <th>hasGuestRoom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92649</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>56098</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1991</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6811</td>\n",
       "      <td>2656</td>\n",
       "      <td>429</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9271774.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42485</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>23782</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>974</td>\n",
       "      <td>9553</td>\n",
       "      <td>426</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4251851.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65867</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>67725</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3054</td>\n",
       "      <td>4650</td>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6593211.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2372</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>60320</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8041</td>\n",
       "      <td>7294</td>\n",
       "      <td>736</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>241014.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60514</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>76413</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9227</td>\n",
       "      <td>737</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6059360.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   squareMeters  numberOfRooms  hasYard  hasPool  floors  cityCode  \\\n",
       "0         92649             31        0        0      77     56098   \n",
       "1         42485              1        0        0      40     23782   \n",
       "2         65867             37        0        0      92     67725   \n",
       "3          2372             41        1        0       5     60320   \n",
       "4         60514             46        1        1      35     76413   \n",
       "\n",
       "   cityPartRange  numPrevOwners  made  isNewBuilt  hasStormProtector  \\\n",
       "0             10              8  1991           1                  1   \n",
       "1              7              7  2017           0                  1   \n",
       "2              6              2  1994           1                  1   \n",
       "3              1              1  2003           0                  0   \n",
       "4              2              1  2019           1                  0   \n",
       "\n",
       "   basement  attic  garage  hasStorageRoom  hasGuestRoom      price  \n",
       "0      6811   2656     429               1             8  9271774.1  \n",
       "1       974   9553     426               0             3  4251851.7  \n",
       "2      3054   4650     998               1            10  6593211.4  \n",
       "3      8041   7294     736               1             4   241014.3  \n",
       "4      9227    737     340               0             8  6059360.9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"Test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input data/output data and store into numpy array\n",
    "\n",
    "X_train = np.array(df_train.drop('price', axis=1))\n",
    "y_train = np.array(df_train['price'])/10000\n",
    "\n",
    "X_test = np.array(df_test.drop('price', axis=1))\n",
    "y_test = np.array(df_test['price'])/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min, max = np.min(X_train, axis = 0), np.max(X_train, axis = 0)\n",
    "\n",
    "X_train = (X_train - min)/(max - min)\n",
    "X_test = (X_test - min)/(max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 16) (8000,)\n",
      "(1000, 16) (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "\n",
    "def create_model() :\n",
    "\n",
    "    # Input layer\n",
    "    x0 = [Input(shape = (16, )) for _ in range (16)]\n",
    "\n",
    "    # Hiddens layer\n",
    "    x1 = [Dense(3, input_dim = 16, activation = \"relu\")(x) for x in x0]\n",
    "\n",
    "    x2 = [Dense(3, activation = \"relu\")(x) for x in x1]\n",
    "\n",
    "    x3 = [Dense(3, activation = \"relu\")(x) for x in x2]\n",
    "\n",
    "    x3_temp = x3.copy()\n",
    "\n",
    "    x4 = [Concatenate()([x3[i], x3[i + 1]]) for i in range (0, len(x3), 2)]\n",
    "\n",
    "    x5 = [Dense(6, activation = \"relu\")(x) for x in x4]\n",
    "\n",
    "    x6 = [Dense(5, activation = \"relu\")(x) for x in x5]\n",
    "\n",
    "    x7 = [Concatenate()([x6[i], x6[i + 1]] + x3_temp[2*i : int(4*(i/2 + 1))]) for i in range (0, len(x6), 2)]\n",
    "\n",
    "    x8 = [Dense(8, activation = \"relu\")(x) for x in x7]\n",
    "\n",
    "    x9 = [Dense(8, activation = \"relu\")(x) for x in x8]\n",
    "\n",
    "    x10 = [Concatenate()([x9[i], x9[i + 1]]) for i in range (0, len(x9), 2)]\n",
    "\n",
    "    x11 = [Dense(16, activation = \"relu\")(x) for x in x10]\n",
    "\n",
    "    x12 = [Dense(16, activation = \"relu\")(x) for x in x11]\n",
    "\n",
    "    x13 = Concatenate()(x12)\n",
    "\n",
    "    x14 = Dense(256, activation = \"relu\")(x13)\n",
    "\n",
    "    # # Output layer\n",
    "    x15 = Dense(1)(x14)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs = x0, outputs = x15)\n",
    "\n",
    "    plot_model(model, show_shapes = True, to_file = \"model_graph_test.png\") ;\n",
    "\n",
    "    model.compile(optimizer = 'rmsprop', loss = [\"mse\"], metrics = [\"mse\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\Documents\\Programmation\\GitHub\\4th-year-Polytech\\Deep Learning\\env_deep_learning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 199968.0469 - mse: 199968.0469\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30320.5781 - mse: 30320.5781\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2210.7034 - mse: 2210.7034\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1304.9921 - mse: 1304.9921\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 978.9142 - mse: 978.9142\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train for i in range (16)], y_train, epochs = 5, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26e85272390>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additionnal libraries\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\Documents\\Programmation\\GitHub\\4th-year-Polytech\\Deep Learning\\env_deep_learning\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 230688.9062 - mse: 230688.9062\n",
      "Epoch 1: mse improved from inf to 143093.15625, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 227666.0156 - mse: 227666.0156\n",
      "Epoch 2/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 50570.7266 - mse: 50570.7266\n",
      "Epoch 2: mse improved from 143093.15625 to 29210.60742, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48010.1680 - mse: 48010.1680\n",
      "Epoch 3/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2985.0547 - mse: 2985.0547\n",
      "Epoch 3: mse improved from 29210.60742 to 2526.17773, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2967.2390 - mse: 2967.2390\n",
      "Epoch 4/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1624.3779 - mse: 1624.3779\n",
      "Epoch 4: mse improved from 2526.17773 to 1570.44421, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1615.9352 - mse: 1615.9352\n",
      "Epoch 5/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1207.8077 - mse: 1207.8077\n",
      "Epoch 5: mse improved from 1570.44421 to 1200.20190, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1208.4341 - mse: 1208.4341\n",
      "Epoch 6/100\n",
      "\u001b[1m164/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1179.0708 - mse: 1179.0708\n",
      "Epoch 6: mse improved from 1200.20190 to 1099.02979, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1167.9020 - mse: 1167.9020\n",
      "Epoch 7/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1098.8170 - mse: 1098.8170\n",
      "Epoch 7: mse improved from 1099.02979 to 980.38843, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1084.4850 - mse: 1084.4850\n",
      "Epoch 8/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 916.3170 - mse: 916.3170\n",
      "Epoch 8: mse improved from 980.38843 to 902.24731, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 915.6350 - mse: 915.6350\n",
      "Epoch 9/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 836.7592 - mse: 836.7592\n",
      "Epoch 9: mse improved from 902.24731 to 827.94415, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 837.0602 - mse: 837.0602\n",
      "Epoch 10/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 935.3840 - mse: 935.3840\n",
      "Epoch 10: mse improved from 827.94415 to 825.28210, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 924.1350 - mse: 924.1350\n",
      "Epoch 11/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 816.0765 - mse: 816.0765\n",
      "Epoch 11: mse improved from 825.28210 to 784.45343, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 811.9651 - mse: 811.9651\n",
      "Epoch 12/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 719.6437 - mse: 719.6437\n",
      "Epoch 12: mse improved from 784.45343 to 739.08264, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 722.0961 - mse: 722.0961\n",
      "Epoch 13/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 759.7114 - mse: 759.7114\n",
      "Epoch 13: mse improved from 739.08264 to 733.13782, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 756.0799 - mse: 756.0799\n",
      "Epoch 14/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 677.8332 - mse: 677.8332\n",
      "Epoch 14: mse improved from 733.13782 to 692.57599, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 679.5782 - mse: 679.5782\n",
      "Epoch 15/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 701.0844 - mse: 701.0844\n",
      "Epoch 15: mse improved from 692.57599 to 688.24860, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 700.1152 - mse: 700.1152\n",
      "Epoch 16/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 658.7056 - mse: 658.7056\n",
      "Epoch 16: mse improved from 688.24860 to 662.18042, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 659.5329 - mse: 659.5329\n",
      "Epoch 17/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 658.9177 - mse: 658.9177\n",
      "Epoch 17: mse did not improve from 662.18042\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 658.5612 - mse: 658.5612\n",
      "Epoch 18/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 598.4836 - mse: 598.4836\n",
      "Epoch 18: mse improved from 662.18042 to 618.69708, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 601.0523 - mse: 601.0523\n",
      "Epoch 19/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 600.2008 - mse: 600.2008\n",
      "Epoch 19: mse improved from 618.69708 to 613.42365, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 601.0181 - mse: 601.0181\n",
      "Epoch 20/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 570.9122 - mse: 570.9122\n",
      "Epoch 20: mse improved from 613.42365 to 598.29724, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 573.7041 - mse: 573.7041\n",
      "Epoch 21/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 573.6022 - mse: 573.6022\n",
      "Epoch 21: mse improved from 598.29724 to 576.27631, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 573.6466 - mse: 573.6466\n",
      "Epoch 22/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 580.6738 - mse: 580.6738\n",
      "Epoch 22: mse improved from 576.27631 to 572.70514, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 580.1910 - mse: 580.1910\n",
      "Epoch 23/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 579.7270 - mse: 579.7270\n",
      "Epoch 23: mse improved from 572.70514 to 562.53857, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 577.2004 - mse: 577.2004\n",
      "Epoch 24/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 502.6916 - mse: 502.6916\n",
      "Epoch 24: mse improved from 562.53857 to 533.43018, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 506.0504 - mse: 506.0504\n",
      "Epoch 25/100\n",
      "\u001b[1m181/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 540.9399 - mse: 540.9399\n",
      "Epoch 25: mse did not improve from 533.43018\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 540.0029 - mse: 540.0029\n",
      "Epoch 26/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 559.1866 - mse: 559.1866\n",
      "Epoch 26: mse improved from 533.43018 to 527.54889, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 556.6281 - mse: 556.6281\n",
      "Epoch 27/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 529.7075 - mse: 529.7075\n",
      "Epoch 27: mse improved from 527.54889 to 517.62073, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 528.9371 - mse: 528.9371\n",
      "Epoch 28/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 548.3537 - mse: 548.3537\n",
      "Epoch 28: mse did not improve from 517.62073\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 544.4907 - mse: 544.4907\n",
      "Epoch 29/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 511.4699 - mse: 511.4699\n",
      "Epoch 29: mse improved from 517.62073 to 498.40369, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 510.5162 - mse: 510.5162\n",
      "Epoch 30/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 512.6998 - mse: 512.6998\n",
      "Epoch 30: mse improved from 498.40369 to 495.74304, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 510.6596 - mse: 510.6596\n",
      "Epoch 31/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 488.5583 - mse: 488.5583\n",
      "Epoch 31: mse improved from 495.74304 to 493.42465, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 489.0698 - mse: 489.0698\n",
      "Epoch 32/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 479.4409 - mse: 479.4409\n",
      "Epoch 32: mse improved from 493.42465 to 488.50684, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479.5221 - mse: 479.5221\n",
      "Epoch 33/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 424.2625 - mse: 424.2625\n",
      "Epoch 33: mse improved from 488.50684 to 464.27307, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429.2549 - mse: 429.2549\n",
      "Epoch 34/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 474.9078 - mse: 474.9078\n",
      "Epoch 34: mse did not improve from 464.27307\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 473.6136 - mse: 473.6136\n",
      "Epoch 35/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 451.7159 - mse: 451.7159\n",
      "Epoch 35: mse improved from 464.27307 to 457.22220, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 452.1097 - mse: 452.1097\n",
      "Epoch 36/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 455.8929 - mse: 455.8929\n",
      "Epoch 36: mse improved from 457.22220 to 447.38480, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 455.8699 - mse: 455.8699\n",
      "Epoch 37/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 483.0844 - mse: 483.0844\n",
      "Epoch 37: mse did not improve from 447.38480\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479.2747 - mse: 479.2747\n",
      "Epoch 38/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 437.5560 - mse: 437.5560\n",
      "Epoch 38: mse improved from 447.38480 to 439.00256, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 437.2776 - mse: 437.2776\n",
      "Epoch 39/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413.8207 - mse: 413.8207\n",
      "Epoch 39: mse improved from 439.00256 to 428.61575, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413.8943 - mse: 413.8943\n",
      "Epoch 40/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 426.9946 - mse: 426.9946\n",
      "Epoch 40: mse did not improve from 428.61575\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 427.4310 - mse: 427.4310\n",
      "Epoch 41/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 421.0305 - mse: 421.0305\n",
      "Epoch 41: mse improved from 428.61575 to 422.69180, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.7456 - mse: 421.7456\n",
      "Epoch 42/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 446.3877 - mse: 446.3877\n",
      "Epoch 42: mse improved from 422.69180 to 420.60690, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 442.7845 - mse: 442.7845\n",
      "Epoch 43/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 456.6066 - mse: 456.6066\n",
      "Epoch 43: mse did not improve from 420.60690\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 451.4878 - mse: 451.4878\n",
      "Epoch 44/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 393.8715 - mse: 393.8715\n",
      "Epoch 44: mse improved from 420.60690 to 409.22519, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 395.4213 - mse: 395.4213\n",
      "Epoch 45/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 387.6179 - mse: 387.6179\n",
      "Epoch 45: mse improved from 409.22519 to 404.24918, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389.5840 - mse: 389.5840\n",
      "Epoch 46/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 417.7238 - mse: 417.7238\n",
      "Epoch 46: mse improved from 404.24918 to 403.60419, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.8986 - mse: 416.8986\n",
      "Epoch 47/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 438.3991 - mse: 438.3991\n",
      "Epoch 47: mse did not improve from 403.60419\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 434.4233 - mse: 434.4233\n",
      "Epoch 48/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 420.7625 - mse: 420.7625\n",
      "Epoch 48: mse improved from 403.60419 to 392.02606, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 417.6832 - mse: 417.6832\n",
      "Epoch 49/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 425.6616 - mse: 425.6616\n",
      "Epoch 49: mse did not improve from 392.02606\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 423.4901 - mse: 423.4901\n",
      "Epoch 50/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 369.8922 - mse: 369.8922\n",
      "Epoch 50: mse improved from 392.02606 to 379.15125, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.2370 - mse: 371.2370\n",
      "Epoch 51/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 411.3682 - mse: 411.3682\n",
      "Epoch 51: mse did not improve from 379.15125\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 411.0923 - mse: 411.0923\n",
      "Epoch 52/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 367.4576 - mse: 367.4576\n",
      "Epoch 52: mse improved from 379.15125 to 378.61273, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.8531 - mse: 368.8531\n",
      "Epoch 53/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 374.2816 - mse: 374.2816\n",
      "Epoch 53: mse did not improve from 378.61273\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 374.8189 - mse: 374.8189\n",
      "Epoch 54/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 363.3652 - mse: 363.3652\n",
      "Epoch 54: mse improved from 378.61273 to 371.79224, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.7772 - mse: 364.7772\n",
      "Epoch 55/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 368.6082 - mse: 368.6082\n",
      "Epoch 55: mse did not improve from 371.79224\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 369.1480 - mse: 369.1480\n",
      "Epoch 56/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 369.6576 - mse: 369.6576\n",
      "Epoch 56: mse improved from 371.79224 to 367.60516, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.1930 - mse: 369.1930\n",
      "Epoch 57/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 335.9562 - mse: 335.9562\n",
      "Epoch 57: mse did not improve from 367.60516\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 339.7368 - mse: 339.7368\n",
      "Epoch 58/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 345.8647 - mse: 345.8647\n",
      "Epoch 58: mse improved from 367.60516 to 357.55780, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.6499 - mse: 346.6499\n",
      "Epoch 59/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 332.1479 - mse: 332.1479\n",
      "Epoch 59: mse improved from 357.55780 to 353.84650, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 334.6413 - mse: 334.6413\n",
      "Epoch 60/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 343.2688 - mse: 343.2688\n",
      "Epoch 60: mse improved from 353.84650 to 353.73743, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344.5450 - mse: 344.5450\n",
      "Epoch 61/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 330.2798 - mse: 330.2798\n",
      "Epoch 61: mse improved from 353.73743 to 346.54224, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331.7783 - mse: 331.7783\n",
      "Epoch 62/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 326.9771 - mse: 326.9771\n",
      "Epoch 62: mse improved from 346.54224 to 340.10089, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 328.8542 - mse: 328.8542\n",
      "Epoch 63/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 358.3595 - mse: 358.3595\n",
      "Epoch 63: mse did not improve from 340.10089\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 357.6642 - mse: 357.6642\n",
      "Epoch 64/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 339.9095 - mse: 339.9095\n",
      "Epoch 64: mse did not improve from 340.10089\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340.1347 - mse: 340.1347\n",
      "Epoch 65/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 329.4893 - mse: 329.4893\n",
      "Epoch 65: mse improved from 340.10089 to 335.58987, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 330.3319 - mse: 330.3319\n",
      "Epoch 66/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 351.9284 - mse: 351.9284\n",
      "Epoch 66: mse did not improve from 335.58987\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 351.2666 - mse: 351.2666\n",
      "Epoch 67/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 330.4247 - mse: 330.4247\n",
      "Epoch 67: mse did not improve from 335.58987\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 330.5096 - mse: 330.5096\n",
      "Epoch 68/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 330.7647 - mse: 330.7647\n",
      "Epoch 68: mse improved from 335.58987 to 324.94061, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 330.7357 - mse: 330.7357\n",
      "Epoch 69/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.1068 - mse: 346.1068\n",
      "Epoch 69: mse did not improve from 324.94061\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 345.5787 - mse: 345.5787\n",
      "Epoch 70/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 326.9320 - mse: 326.9320\n",
      "Epoch 70: mse did not improve from 324.94061\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 327.1356 - mse: 327.1356\n",
      "Epoch 71/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 313.2640 - mse: 313.2640\n",
      "Epoch 71: mse did not improve from 324.94061\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 314.6583 - mse: 314.6583\n",
      "Epoch 72/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.0348 - mse: 310.0348\n",
      "Epoch 72: mse improved from 324.94061 to 323.87039, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.1036 - mse: 310.1036\n",
      "Epoch 73/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 312.1762 - mse: 312.1762\n",
      "Epoch 73: mse improved from 323.87039 to 320.44794, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 312.2173 - mse: 312.2173\n",
      "Epoch 74/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.9889 - mse: 310.9889\n",
      "Epoch 74: mse improved from 320.44794 to 320.36505, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311.6804 - mse: 311.6804\n",
      "Epoch 75/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 292.1233 - mse: 292.1233\n",
      "Epoch 75: mse improved from 320.36505 to 310.21249, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 294.3008 - mse: 294.3008\n",
      "Epoch 76/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 305.5919 - mse: 305.5919\n",
      "Epoch 76: mse did not improve from 310.21249\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 306.9427 - mse: 306.9427\n",
      "Epoch 77/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 314.1183 - mse: 314.1183\n",
      "Epoch 77: mse did not improve from 310.21249\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 314.0895 - mse: 314.0895\n",
      "Epoch 78/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.3457 - mse: 309.3457\n",
      "Epoch 78: mse did not improve from 310.21249\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.5975 - mse: 309.5975\n",
      "Epoch 79/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 305.1048 - mse: 305.1048\n",
      "Epoch 79: mse improved from 310.21249 to 303.88773, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 305.1420 - mse: 305.1420\n",
      "Epoch 80/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.5753 - mse: 309.5753\n",
      "Epoch 80: mse improved from 303.88773 to 303.86008, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.1923 - mse: 309.1923\n",
      "Epoch 81/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 314.2079 - mse: 314.2079\n",
      "Epoch 81: mse improved from 303.86008 to 302.29105, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 313.7035 - mse: 313.7035\n",
      "Epoch 82/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 324.3807 - mse: 324.3807\n",
      "Epoch 82: mse improved from 302.29105 to 301.41794, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 321.3382 - mse: 321.3382\n",
      "Epoch 83/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 325.0895 - mse: 325.0895\n",
      "Epoch 83: mse did not improve from 301.41794\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 321.7315 - mse: 321.7315\n",
      "Epoch 84/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 290.7646 - mse: 290.7646\n",
      "Epoch 84: mse improved from 301.41794 to 299.69632, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.6097 - mse: 291.6097\n",
      "Epoch 85/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.9333 - mse: 289.9333\n",
      "Epoch 85: mse improved from 299.69632 to 297.25671, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.9697 - mse: 289.9697\n",
      "Epoch 86/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 274.9193 - mse: 274.9193\n",
      "Epoch 86: mse improved from 297.25671 to 292.76834, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.4499 - mse: 275.4499\n",
      "Epoch 87/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.7041 - mse: 278.7041\n",
      "Epoch 87: mse did not improve from 292.76834\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 280.5535 - mse: 280.5535\n",
      "Epoch 88/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.0536 - mse: 285.0536\n",
      "Epoch 88: mse did not improve from 292.76834\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.4312 - mse: 285.4312\n",
      "Epoch 89/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 282.5894 - mse: 282.5894\n",
      "Epoch 89: mse improved from 292.76834 to 288.65155, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 283.2796 - mse: 283.2796\n",
      "Epoch 90/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 286.1632 - mse: 286.1632\n",
      "Epoch 90: mse improved from 288.65155 to 288.02576, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.7201 - mse: 286.7201\n",
      "Epoch 91/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.7607 - mse: 310.7607\n",
      "Epoch 91: mse did not improve from 288.02576\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.6826 - mse: 310.6826\n",
      "Epoch 92/100\n",
      "\u001b[1m166/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.0727 - mse: 265.0727\n",
      "Epoch 92: mse improved from 288.02576 to 282.19568, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 267.6602 - mse: 267.6602\n",
      "Epoch 93/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.1209 - mse: 273.1209\n",
      "Epoch 93: mse improved from 282.19568 to 281.01880, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.3515 - mse: 273.3515\n",
      "Epoch 94/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.9456 - mse: 270.9456\n",
      "Epoch 94: mse improved from 281.01880 to 278.63882, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.5493 - mse: 271.5493\n",
      "Epoch 95/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 287.7690 - mse: 287.7690\n",
      "Epoch 95: mse did not improve from 278.63882\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.5116 - mse: 286.5116\n",
      "Epoch 96/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 276.7139 - mse: 276.7139\n",
      "Epoch 96: mse improved from 278.63882 to 277.58405, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 276.8583 - mse: 276.8583\n",
      "Epoch 97/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.4031 - mse: 278.4031\n",
      "Epoch 97: mse did not improve from 277.58405\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.5736 - mse: 278.5736\n",
      "Epoch 98/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 279.8681 - mse: 279.8681\n",
      "Epoch 98: mse did not improve from 277.58405\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 279.9139 - mse: 279.9139\n",
      "Epoch 99/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 242.0745 - mse: 242.0745\n",
      "Epoch 99: mse improved from 277.58405 to 265.40179, saving model to my_best_model1.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.8515 - mse: 245.8515\n",
      "Epoch 100/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 247.9548 - mse: 247.9548\n",
      "Epoch 100: mse did not improve from 265.40179\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 248.4282 - mse: 248.4282\n",
      "Epoch 1/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 229812.1875 - mse: 229812.1875\n",
      "Epoch 1: mse improved from inf to 136207.73438, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 220414.4219 - mse: 220414.4219\n",
      "Epoch 2/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46427.0977 - mse: 46427.0977\n",
      "Epoch 2: mse improved from 136207.73438 to 31882.05664, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 46354.7344 - mse: 46354.7344\n",
      "Epoch 3/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3722.7390 - mse: 3722.7390\n",
      "Epoch 3: mse improved from 31882.05664 to 2651.55933, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3556.0110 - mse: 3556.0110\n",
      "Epoch 4/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1403.7252 - mse: 1403.7252\n",
      "Epoch 4: mse improved from 2651.55933 to 1253.18372, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1401.4537 - mse: 1401.4537\n",
      "Epoch 5/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1000.6365 - mse: 1000.6365\n",
      "Epoch 5: mse improved from 1253.18372 to 936.00812, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 999.9935 - mse: 999.9935  \n",
      "Epoch 6/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 788.0924 - mse: 788.0924\n",
      "Epoch 6: mse improved from 936.00812 to 789.14252, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 788.1028 - mse: 788.1028\n",
      "Epoch 7/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 699.6009 - mse: 699.6009\n",
      "Epoch 7: mse improved from 789.14252 to 711.69159, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 700.8406 - mse: 700.8406\n",
      "Epoch 8/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 640.6374 - mse: 640.6374\n",
      "Epoch 8: mse improved from 711.69159 to 646.88489, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 641.1412 - mse: 641.1412\n",
      "Epoch 9/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 625.7072 - mse: 625.7072\n",
      "Epoch 9: mse improved from 646.88489 to 614.76666, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 623.1821 - mse: 623.1821\n",
      "Epoch 10/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 568.7245 - mse: 568.7245\n",
      "Epoch 10: mse improved from 614.76666 to 574.26489, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 569.7758 - mse: 569.7758\n",
      "Epoch 11/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 564.3235 - mse: 564.3235\n",
      "Epoch 11: mse improved from 574.26489 to 560.12439, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 564.2817 - mse: 564.2817\n",
      "Epoch 12/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 497.4345 - mse: 497.4345\n",
      "Epoch 12: mse improved from 560.12439 to 522.15546, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 500.5375 - mse: 500.5375\n",
      "Epoch 13/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 494.7350 - mse: 494.7350\n",
      "Epoch 13: mse improved from 522.15546 to 509.81345, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 496.4808 - mse: 496.4808\n",
      "Epoch 14/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 480.7301 - mse: 480.7301\n",
      "Epoch 14: mse improved from 509.81345 to 492.32510, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 481.9501 - mse: 481.9501\n",
      "Epoch 15/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 475.3709 - mse: 475.3709\n",
      "Epoch 15: mse improved from 492.32510 to 467.91272, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 474.3793 - mse: 474.3793\n",
      "Epoch 16/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 459.0322 - mse: 459.0322\n",
      "Epoch 16: mse improved from 467.91272 to 455.53546, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 458.3275 - mse: 458.3275\n",
      "Epoch 17/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 458.6816 - mse: 458.6816\n",
      "Epoch 17: mse improved from 455.53546 to 453.88602, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457.2191 - mse: 457.2191\n",
      "Epoch 18/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 390.4528 - mse: 390.4528\n",
      "Epoch 18: mse improved from 453.88602 to 418.78644, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 394.7728 - mse: 394.7728\n",
      "Epoch 19/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 448.6239 - mse: 448.6239\n",
      "Epoch 19: mse did not improve from 418.78644\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 448.4406 - mse: 448.4406\n",
      "Epoch 20/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 369.0428 - mse: 369.0428\n",
      "Epoch 20: mse improved from 418.78644 to 398.80835, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 374.3953 - mse: 374.3953\n",
      "Epoch 21/100\n",
      "\u001b[1m166/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.0899 - mse: 463.0899\n",
      "Epoch 21: mse did not improve from 398.80835\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 456.0694 - mse: 456.0694\n",
      "Epoch 22/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 409.2369 - mse: 409.2369\n",
      "Epoch 22: mse did not improve from 398.80835\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 409.1027 - mse: 409.1027\n",
      "Epoch 23/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 376.3096 - mse: 376.3096\n",
      "Epoch 23: mse improved from 398.80835 to 382.06122, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377.9091 - mse: 377.9091\n",
      "Epoch 24/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.0919 - mse: 422.0919\n",
      "Epoch 24: mse did not improve from 382.06122\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.9710 - mse: 421.9710\n",
      "Epoch 25/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 369.8813 - mse: 369.8813\n",
      "Epoch 25: mse improved from 382.06122 to 373.27814, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 370.3733 - mse: 370.3733\n",
      "Epoch 26/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 380.6190 - mse: 380.6190\n",
      "Epoch 26: mse did not improve from 373.27814\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 380.6837 - mse: 380.6837\n",
      "Epoch 27/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 393.2214 - mse: 393.2214\n",
      "Epoch 27: mse did not improve from 373.27814\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 391.2576 - mse: 391.2576\n",
      "Epoch 28/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.3477 - mse: 368.3477\n",
      "Epoch 28: mse improved from 373.27814 to 365.52139, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.2803 - mse: 368.2803\n",
      "Epoch 29/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376.1489 - mse: 376.1489\n",
      "Epoch 29: mse did not improve from 365.52139\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.6175 - mse: 375.6175\n",
      "Epoch 30/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 335.2076 - mse: 335.2076\n",
      "Epoch 30: mse improved from 365.52139 to 351.93472, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 337.9592 - mse: 337.9592\n",
      "Epoch 31/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 360.4176 - mse: 360.4176\n",
      "Epoch 31: mse did not improve from 351.93472\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 359.1734 - mse: 359.1734\n",
      "Epoch 32/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 334.5880 - mse: 334.5880\n",
      "Epoch 32: mse improved from 351.93472 to 347.72290, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 335.6635 - mse: 335.6635\n",
      "Epoch 33/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 321.4792 - mse: 321.4792\n",
      "Epoch 33: mse improved from 347.72290 to 334.73608, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 321.7585 - mse: 321.7585\n",
      "Epoch 34/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 335.0840 - mse: 335.0840\n",
      "Epoch 34: mse did not improve from 334.73608\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 336.0480 - mse: 336.0480\n",
      "Epoch 35/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 335.0706 - mse: 335.0706\n",
      "Epoch 35: mse improved from 334.73608 to 333.45203, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 335.0103 - mse: 335.0103\n",
      "Epoch 36/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 325.1827 - mse: 325.1827\n",
      "Epoch 36: mse improved from 333.45203 to 329.25027, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 325.6380 - mse: 325.6380\n",
      "Epoch 37/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 332.8047 - mse: 332.8047\n",
      "Epoch 37: mse improved from 329.25027 to 317.77249, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331.1168 - mse: 331.1168\n",
      "Epoch 38/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 329.4588 - mse: 329.4588\n",
      "Epoch 38: mse did not improve from 317.77249\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 329.3084 - mse: 329.3084\n",
      "Epoch 39/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 318.7686 - mse: 318.7686\n",
      "Epoch 39: mse did not improve from 317.77249\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 319.2323 - mse: 319.2323\n",
      "Epoch 40/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 283.2122 - mse: 283.2122\n",
      "Epoch 40: mse improved from 317.77249 to 307.80444, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.5480 - mse: 286.5480\n",
      "Epoch 41/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 298.8743 - mse: 298.8743\n",
      "Epoch 41: mse did not improve from 307.80444\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 299.0254 - mse: 299.0254\n",
      "Epoch 42/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 303.9379 - mse: 303.9379\n",
      "Epoch 42: mse improved from 307.80444 to 302.55292, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 303.9192 - mse: 303.9192\n",
      "Epoch 43/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 298.3324 - mse: 298.3324\n",
      "Epoch 43: mse did not improve from 302.55292\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 299.3555 - mse: 299.3555\n",
      "Epoch 44/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 303.7510 - mse: 303.7510\n",
      "Epoch 44: mse did not improve from 302.55292\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 303.3492 - mse: 303.3492\n",
      "Epoch 45/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 264.8619 - mse: 264.8619\n",
      "Epoch 45: mse improved from 302.55292 to 292.65204, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268.4459 - mse: 268.4459\n",
      "Epoch 46/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 298.3109 - mse: 298.3109\n",
      "Epoch 46: mse did not improve from 292.65204\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 298.6702 - mse: 298.6702\n",
      "Epoch 47/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.0133 - mse: 285.0133\n",
      "Epoch 47: mse did not improve from 292.65204\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.5473 - mse: 286.5473\n",
      "Epoch 48/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 278.3590 - mse: 278.3590\n",
      "Epoch 48: mse improved from 292.65204 to 287.57394, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 280.0918 - mse: 280.0918\n",
      "Epoch 49/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 299.3796 - mse: 299.3796\n",
      "Epoch 49: mse improved from 287.57394 to 286.95972, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 298.5579 - mse: 298.5579\n",
      "Epoch 50/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 324.0467 - mse: 324.0467\n",
      "Epoch 50: mse did not improve from 286.95972\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 320.2062 - mse: 320.2062\n",
      "Epoch 51/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 280.5732 - mse: 280.5732\n",
      "Epoch 51: mse did not improve from 286.95972\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 280.6897 - mse: 280.6897\n",
      "Epoch 52/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 247.9467 - mse: 247.9467\n",
      "Epoch 52: mse improved from 286.95972 to 277.59308, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.0843 - mse: 251.0843\n",
      "Epoch 53/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 267.4981 - mse: 267.4981\n",
      "Epoch 53: mse did not improve from 277.59308\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 269.0073 - mse: 269.0073\n",
      "Epoch 54/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 255.7616 - mse: 255.7616\n",
      "Epoch 54: mse improved from 277.59308 to 272.46640, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 258.2780 - mse: 258.2780\n",
      "Epoch 55/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 294.1933 - mse: 294.1933\n",
      "Epoch 55: mse did not improve from 272.46640\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 291.8357 - mse: 291.8357\n",
      "Epoch 56/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 288.8664 - mse: 288.8664\n",
      "Epoch 56: mse did not improve from 272.46640\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 288.7406 - mse: 288.7406\n",
      "Epoch 57/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 263.4323 - mse: 263.4323\n",
      "Epoch 57: mse did not improve from 272.46640\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 264.6873 - mse: 264.6873\n",
      "Epoch 58/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.3055 - mse: 265.3055\n",
      "Epoch 58: mse improved from 272.46640 to 268.94653, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.3933 - mse: 265.3933\n",
      "Epoch 59/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 278.3977 - mse: 278.3977\n",
      "Epoch 59: mse improved from 268.94653 to 268.47656, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 277.3450 - mse: 277.3450\n",
      "Epoch 60/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.8577 - mse: 278.8577\n",
      "Epoch 60: mse improved from 268.47656 to 262.20636, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.6140 - mse: 278.6140\n",
      "Epoch 61/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 274.1036 - mse: 274.1036\n",
      "Epoch 61: mse did not improve from 262.20636\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 272.6248 - mse: 272.6248\n",
      "Epoch 62/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 272.5637 - mse: 272.5637\n",
      "Epoch 62: mse did not improve from 262.20636\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 271.5374 - mse: 271.5374\n",
      "Epoch 63/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 252.1698 - mse: 252.1698\n",
      "Epoch 63: mse improved from 262.20636 to 254.89240, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.9290 - mse: 252.9290\n",
      "Epoch 64/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 274.5512 - mse: 274.5512\n",
      "Epoch 64: mse did not improve from 254.89240\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 274.2612 - mse: 274.2612\n",
      "Epoch 65/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.3378 - mse: 255.3378\n",
      "Epoch 65: mse did not improve from 254.89240\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.3441 - mse: 255.3441\n",
      "Epoch 66/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 263.6522 - mse: 263.6522\n",
      "Epoch 66: mse improved from 254.89240 to 252.18813, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 263.4418 - mse: 263.4418\n",
      "Epoch 67/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.5889 - mse: 270.5889\n",
      "Epoch 67: mse did not improve from 252.18813\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268.9225 - mse: 268.9225\n",
      "Epoch 68/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 258.9269 - mse: 258.9269\n",
      "Epoch 68: mse did not improve from 252.18813\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 258.8965 - mse: 258.8965\n",
      "Epoch 69/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 248.5953 - mse: 248.5953\n",
      "Epoch 69: mse did not improve from 252.18813\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 249.0285 - mse: 249.0285\n",
      "Epoch 70/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 231.1085 - mse: 231.1085\n",
      "Epoch 70: mse improved from 252.18813 to 247.70471, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.4315 - mse: 233.4315\n",
      "Epoch 71/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 246.2604 - mse: 246.2604\n",
      "Epoch 71: mse improved from 247.70471 to 246.54999, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 246.0871 - mse: 246.0871\n",
      "Epoch 72/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253.0592 - mse: 253.0592\n",
      "Epoch 72: mse did not improve from 246.54999\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.7064 - mse: 252.7064\n",
      "Epoch 73/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253.6199 - mse: 253.6199\n",
      "Epoch 73: mse improved from 246.54999 to 246.04185, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.2116 - mse: 252.2116\n",
      "Epoch 74/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.3507 - mse: 232.3507\n",
      "Epoch 74: mse improved from 246.04185 to 241.73996, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.9763 - mse: 233.9763\n",
      "Epoch 75/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 249.3455 - mse: 249.3455\n",
      "Epoch 75: mse did not improve from 241.73996\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 248.5145 - mse: 248.5145\n",
      "Epoch 76/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 226.6573 - mse: 226.6573\n",
      "Epoch 76: mse improved from 241.73996 to 240.43582, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 227.0696 - mse: 227.0696\n",
      "Epoch 77/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 232.6893 - mse: 232.6893\n",
      "Epoch 77: mse improved from 240.43582 to 234.55406, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.4626 - mse: 233.4626\n",
      "Epoch 78/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 263.8430 - mse: 263.8430\n",
      "Epoch 78: mse did not improve from 234.55406\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 260.8601 - mse: 260.8601\n",
      "Epoch 79/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 246.3948 - mse: 246.3948\n",
      "Epoch 79: mse did not improve from 234.55406\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 245.2226 - mse: 245.2226\n",
      "Epoch 80/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 235.0126 - mse: 235.0126\n",
      "Epoch 80: mse did not improve from 234.55406\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 235.0542 - mse: 235.0542\n",
      "Epoch 81/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 225.2034 - mse: 225.2034\n",
      "Epoch 81: mse improved from 234.55406 to 234.12854, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 226.5802 - mse: 226.5802\n",
      "Epoch 82/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 237.0188 - mse: 237.0188\n",
      "Epoch 82: mse improved from 234.12854 to 232.74925, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236.3396 - mse: 236.3396\n",
      "Epoch 83/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 230.7379 - mse: 230.7379\n",
      "Epoch 83: mse improved from 232.74925 to 232.26588, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 231.1554 - mse: 231.1554\n",
      "Epoch 84/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 238.1806 - mse: 238.1806\n",
      "Epoch 84: mse did not improve from 232.26588\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 238.0413 - mse: 238.0413\n",
      "Epoch 85/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 236.1067 - mse: 236.1067\n",
      "Epoch 85: mse improved from 232.26588 to 225.92871, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 235.1308 - mse: 235.1308\n",
      "Epoch 86/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 252.0846 - mse: 252.0846\n",
      "Epoch 86: mse did not improve from 225.92871\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 249.7070 - mse: 249.7070\n",
      "Epoch 87/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 248.0550 - mse: 248.0550\n",
      "Epoch 87: mse did not improve from 225.92871\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.7872 - mse: 245.7872\n",
      "Epoch 88/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 234.2344 - mse: 234.2344\n",
      "Epoch 88: mse did not improve from 225.92871\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 234.1261 - mse: 234.1261\n",
      "Epoch 89/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240.2447 - mse: 240.2447\n",
      "Epoch 89: mse did not improve from 225.92871\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 239.5769 - mse: 239.5769\n",
      "Epoch 90/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 222.0431 - mse: 222.0431\n",
      "Epoch 90: mse improved from 225.92871 to 225.73814, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.6104 - mse: 222.6104\n",
      "Epoch 91/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 223.8332 - mse: 223.8332\n",
      "Epoch 91: mse improved from 225.73814 to 224.93532, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 223.8696 - mse: 223.8696\n",
      "Epoch 92/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.5883 - mse: 217.5883\n",
      "Epoch 92: mse improved from 224.93532 to 220.23857, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.6147 - mse: 217.6147\n",
      "Epoch 93/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.3004 - mse: 214.3004\n",
      "Epoch 93: mse improved from 220.23857 to 219.09451, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.0143 - mse: 215.0143\n",
      "Epoch 94/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.9950 - mse: 215.9950\n",
      "Epoch 94: mse did not improve from 219.09451\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.8239 - mse: 216.8239\n",
      "Epoch 95/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.5134 - mse: 217.5134\n",
      "Epoch 95: mse improved from 219.09451 to 213.83344, saving model to my_best_model2.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.2855 - mse: 217.2855\n",
      "Epoch 96/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 231.4793 - mse: 231.4793\n",
      "Epoch 96: mse did not improve from 213.83344\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 229.7891 - mse: 229.7891\n",
      "Epoch 97/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 220.9988 - mse: 220.9988\n",
      "Epoch 97: mse did not improve from 213.83344\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 220.6145 - mse: 220.6145\n",
      "Epoch 98/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 221.5655 - mse: 221.5655\n",
      "Epoch 98: mse did not improve from 213.83344\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 221.3790 - mse: 221.3790\n",
      "Epoch 99/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 235.8227 - mse: 235.8227\n",
      "Epoch 99: mse did not improve from 213.83344\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 235.1157 - mse: 235.1157\n",
      "Epoch 100/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 211.7893 - mse: 211.7893\n",
      "Epoch 100: mse did not improve from 213.83344\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.1907 - mse: 212.1907\n",
      "Epoch 1/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 246434.8906 - mse: 246434.8906\n",
      "Epoch 1: mse improved from inf to 150042.85938, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 239436.3594 - mse: 239436.3594\n",
      "Epoch 2/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56168.8984 - mse: 56168.8984\n",
      "Epoch 2: mse improved from 150042.85938 to 40254.62109, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54200.0508 - mse: 54200.0508\n",
      "Epoch 3/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6745.8550 - mse: 6745.8550\n",
      "Epoch 3: mse improved from 40254.62109 to 4162.83008, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6414.6704 - mse: 6414.6704\n",
      "Epoch 4/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1609.7927 - mse: 1609.7927\n",
      "Epoch 4: mse improved from 4162.83008 to 1436.39160, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1603.1742 - mse: 1603.1742\n",
      "Epoch 5/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1159.3822 - mse: 1159.3822\n",
      "Epoch 5: mse improved from 1436.39160 to 1058.07129, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1158.8782 - mse: 1158.8782\n",
      "Epoch 6/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 872.8634 - mse: 872.8634\n",
      "Epoch 6: mse improved from 1058.07129 to 825.75775, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 871.4222 - mse: 871.4222\n",
      "Epoch 7/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 741.0901 - mse: 741.0901\n",
      "Epoch 7: mse improved from 825.75775 to 724.73383, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 739.7637 - mse: 739.7637\n",
      "Epoch 8/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 695.8402 - mse: 695.8402\n",
      "Epoch 8: mse improved from 724.73383 to 659.66718, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 695.0961 - mse: 695.0961\n",
      "Epoch 9/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 583.4928 - mse: 583.4928\n",
      "Epoch 9: mse improved from 659.66718 to 595.69568, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 586.3115 - mse: 586.3115\n",
      "Epoch 10/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 590.3667 - mse: 590.3667\n",
      "Epoch 10: mse improved from 595.69568 to 578.84601, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 589.7529 - mse: 589.7529\n",
      "Epoch 11/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 517.3656 - mse: 517.3656\n",
      "Epoch 11: mse improved from 578.84601 to 552.97632, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 518.3158 - mse: 518.3158\n",
      "Epoch 12/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 531.1954 - mse: 531.1954\n",
      "Epoch 12: mse improved from 552.97632 to 525.07080, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 531.0818 - mse: 531.0818\n",
      "Epoch 13/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 507.9160 - mse: 507.9160\n",
      "Epoch 13: mse improved from 525.07080 to 514.93579, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 508.5347 - mse: 508.5347\n",
      "Epoch 14/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 513.8596 - mse: 513.8596\n",
      "Epoch 14: mse improved from 514.93579 to 500.20163, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 513.7916 - mse: 513.7916\n",
      "Epoch 15/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444.6210 - mse: 444.6210\n",
      "Epoch 15: mse improved from 500.20163 to 474.76141, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 445.2027 - mse: 445.2027\n",
      "Epoch 16/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 455.7644 - mse: 455.7644\n",
      "Epoch 16: mse improved from 474.76141 to 468.63730, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 456.2643 - mse: 456.2643\n",
      "Epoch 17/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444.1015 - mse: 444.1015\n",
      "Epoch 17: mse improved from 468.63730 to 448.83789, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 445.2188 - mse: 445.2188\n",
      "Epoch 18/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 486.1872 - mse: 486.1872\n",
      "Epoch 18: mse did not improve from 448.83789\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 485.5557 - mse: 485.5557\n",
      "Epoch 19/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427.9651 - mse: 427.9651\n",
      "Epoch 19: mse improved from 448.83789 to 439.92703, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 428.5254 - mse: 428.5254\n",
      "Epoch 20/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.7349 - mse: 430.7349\n",
      "Epoch 20: mse improved from 439.92703 to 437.36868, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.8665 - mse: 430.8665\n",
      "Epoch 21/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 418.5156 - mse: 418.5156\n",
      "Epoch 21: mse improved from 437.36868 to 420.95120, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 418.5277 - mse: 418.5277\n",
      "Epoch 22/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 419.0676 - mse: 419.0676\n",
      "Epoch 22: mse improved from 420.95120 to 414.53470, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 418.6459 - mse: 418.6459\n",
      "Epoch 23/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 420.2597 - mse: 420.2597\n",
      "Epoch 23: mse did not improve from 414.53470\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 419.5542 - mse: 419.5542\n",
      "Epoch 24/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 395.7845 - mse: 395.7845\n",
      "Epoch 24: mse improved from 414.53470 to 400.28711, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 395.8544 - mse: 395.8544\n",
      "Epoch 25/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 394.2490 - mse: 394.2490\n",
      "Epoch 25: mse improved from 400.28711 to 391.68167, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 394.3175 - mse: 394.3175\n",
      "Epoch 26/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425.3705 - mse: 425.3705\n",
      "Epoch 26: mse did not improve from 391.68167\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 422.2994 - mse: 422.2994\n",
      "Epoch 27/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388.6269 - mse: 388.6269\n",
      "Epoch 27: mse improved from 391.68167 to 391.37231, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 388.7152 - mse: 388.7152\n",
      "Epoch 28/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 400.4231 - mse: 400.4231\n",
      "Epoch 28: mse improved from 391.37231 to 383.27725, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 399.7397 - mse: 399.7397\n",
      "Epoch 29/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 420.3618 - mse: 420.3618\n",
      "Epoch 29: mse did not improve from 383.27725\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 419.7980 - mse: 419.7980\n",
      "Epoch 30/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 356.7078 - mse: 356.7078\n",
      "Epoch 30: mse improved from 383.27725 to 371.49432, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 359.2163 - mse: 359.2163\n",
      "Epoch 31/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.5104 - mse: 379.5104\n",
      "Epoch 31: mse did not improve from 371.49432\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.4821 - mse: 379.4821\n",
      "Epoch 32/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.6185 - mse: 365.6185\n",
      "Epoch 32: mse improved from 371.49432 to 368.35602, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.8756 - mse: 365.8756\n",
      "Epoch 33/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389.0829 - mse: 389.0829\n",
      "Epoch 33: mse improved from 368.35602 to 362.47946, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 385.3589 - mse: 385.3589\n",
      "Epoch 34/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376.4785 - mse: 376.4785\n",
      "Epoch 34: mse improved from 362.47946 to 361.29993, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.9806 - mse: 375.9806\n",
      "Epoch 35/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 399.7314 - mse: 399.7314\n",
      "Epoch 35: mse did not improve from 361.29993\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397.5946 - mse: 397.5946\n",
      "Epoch 36/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.2653 - mse: 365.2653\n",
      "Epoch 36: mse improved from 361.29993 to 358.78470, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.2457 - mse: 364.2457\n",
      "Epoch 37/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 357.4523 - mse: 357.4523\n",
      "Epoch 37: mse improved from 358.78470 to 353.06659, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 356.1924 - mse: 356.1924\n",
      "Epoch 38/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 337.3382 - mse: 337.3382\n",
      "Epoch 38: mse improved from 353.06659 to 348.66644, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 337.9118 - mse: 337.9118\n",
      "Epoch 39/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340.6126 - mse: 340.6126\n",
      "Epoch 39: mse did not improve from 348.66644\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 340.6540 - mse: 340.6540\n",
      "Epoch 40/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344.3619 - mse: 344.3619\n",
      "Epoch 40: mse improved from 348.66644 to 340.28339, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344.3416 - mse: 344.3416\n",
      "Epoch 41/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.0984 - mse: 346.0984\n",
      "Epoch 41: mse did not improve from 340.28339\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.0003 - mse: 346.0003\n",
      "Epoch 42/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 336.0346 - mse: 336.0346\n",
      "Epoch 42: mse improved from 340.28339 to 335.06866, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 336.0244 - mse: 336.0244\n",
      "Epoch 43/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 345.0523 - mse: 345.0523\n",
      "Epoch 43: mse improved from 335.06866 to 333.11102, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344.4233 - mse: 344.4233\n",
      "Epoch 44/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.5201 - mse: 333.5201\n",
      "Epoch 44: mse improved from 333.11102 to 330.16711, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333.4741 - mse: 333.4741\n",
      "Epoch 45/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 326.1740 - mse: 326.1740\n",
      "Epoch 45: mse improved from 330.16711 to 328.20132, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 326.2108 - mse: 326.2108\n",
      "Epoch 46/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 328.3822 - mse: 328.3822\n",
      "Epoch 46: mse did not improve from 328.20132\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 328.6700 - mse: 328.6700\n",
      "Epoch 47/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311.3008 - mse: 311.3008\n",
      "Epoch 47: mse improved from 328.20132 to 323.52231, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311.5520 - mse: 311.5520\n",
      "Epoch 48/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 338.5393 - mse: 338.5393\n",
      "Epoch 48: mse improved from 323.52231 to 321.94131, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 338.1046 - mse: 338.1046\n",
      "Epoch 49/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 337.1553 - mse: 337.1553\n",
      "Epoch 49: mse did not improve from 321.94131\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 336.4032 - mse: 336.4032\n",
      "Epoch 50/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 303.0817 - mse: 303.0817\n",
      "Epoch 50: mse improved from 321.94131 to 317.35031, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 303.1527 - mse: 303.1527\n",
      "Epoch 51/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 320.8584 - mse: 320.8584\n",
      "Epoch 51: mse improved from 317.35031 to 315.04260, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 320.7565 - mse: 320.7565\n",
      "Epoch 52/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 308.6386 - mse: 308.6386\n",
      "Epoch 52: mse improved from 315.04260 to 300.75751, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 308.5330 - mse: 308.5330\n",
      "Epoch 53/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 342.3998 - mse: 342.3998\n",
      "Epoch 53: mse did not improve from 300.75751\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 338.6518 - mse: 338.6518\n",
      "Epoch 54/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 293.9331 - mse: 293.9331\n",
      "Epoch 54: mse did not improve from 300.75751\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 294.5429 - mse: 294.5429\n",
      "Epoch 55/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 305.8698 - mse: 305.8698\n",
      "Epoch 55: mse did not improve from 300.75751\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 306.0546 - mse: 306.0546\n",
      "Epoch 56/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 287.7621 - mse: 287.7621\n",
      "Epoch 56: mse did not improve from 300.75751\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 288.8624 - mse: 288.8624\n",
      "Epoch 57/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 267.4000 - mse: 267.4000\n",
      "Epoch 57: mse improved from 300.75751 to 299.17404, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 272.2789 - mse: 272.2789\n",
      "Epoch 58/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 296.4283 - mse: 296.4283\n",
      "Epoch 58: mse did not improve from 299.17404\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 296.8219 - mse: 296.8219\n",
      "Epoch 59/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 292.3552 - mse: 292.3552\n",
      "Epoch 59: mse improved from 299.17404 to 296.17801, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 292.5084 - mse: 292.5084\n",
      "Epoch 60/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 308.3624 - mse: 308.3624\n",
      "Epoch 60: mse did not improve from 296.17801\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 307.7006 - mse: 307.7006\n",
      "Epoch 61/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 276.6814 - mse: 276.6814\n",
      "Epoch 61: mse improved from 296.17801 to 287.62796, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 277.4867 - mse: 277.4867\n",
      "Epoch 62/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311.2716 - mse: 311.2716\n",
      "Epoch 62: mse did not improve from 287.62796\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 310.7818 - mse: 310.7818\n",
      "Epoch 63/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.3018 - mse: 291.3018\n",
      "Epoch 63: mse did not improve from 287.62796\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.4380 - mse: 291.4380\n",
      "Epoch 64/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.7760 - mse: 289.7760\n",
      "Epoch 64: mse did not improve from 287.62796\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 290.2105 - mse: 290.2105\n",
      "Epoch 65/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.5249 - mse: 309.5249\n",
      "Epoch 65: mse did not improve from 287.62796\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 307.9954 - mse: 307.9954\n",
      "Epoch 66/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.5129 - mse: 278.5129\n",
      "Epoch 66: mse improved from 287.62796 to 283.75052, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.8149 - mse: 278.8149\n",
      "Epoch 67/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 298.2298 - mse: 298.2298\n",
      "Epoch 67: mse did not improve from 283.75052\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 296.9666 - mse: 296.9666\n",
      "Epoch 68/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.6975 - mse: 286.6975\n",
      "Epoch 68: mse did not improve from 283.75052\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.6250 - mse: 286.6250\n",
      "Epoch 69/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.5573 - mse: 285.5573\n",
      "Epoch 69: mse improved from 283.75052 to 278.76953, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.2904 - mse: 285.2904\n",
      "Epoch 70/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 303.9642 - mse: 303.9642\n",
      "Epoch 70: mse did not improve from 278.76953\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 303.2494 - mse: 303.2494\n",
      "Epoch 71/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 262.2637 - mse: 262.2637\n",
      "Epoch 71: mse improved from 278.76953 to 278.74094, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 262.6968 - mse: 262.6968\n",
      "Epoch 72/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.4294 - mse: 273.4294\n",
      "Epoch 72: mse did not improve from 278.74094\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.8309 - mse: 273.8309\n",
      "Epoch 73/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 262.8672 - mse: 262.8672\n",
      "Epoch 73: mse improved from 278.74094 to 276.70581, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 263.3282 - mse: 263.3282\n",
      "Epoch 74/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 256.6680 - mse: 256.6680\n",
      "Epoch 74: mse improved from 276.70581 to 270.58459, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 256.8065 - mse: 256.8065\n",
      "Epoch 75/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.2104 - mse: 252.2104\n",
      "Epoch 75: mse did not improve from 270.58459\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253.1253 - mse: 253.1253\n",
      "Epoch 76/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 258.5108 - mse: 258.5108\n",
      "Epoch 76: mse did not improve from 270.58459\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 258.9013 - mse: 258.9013\n",
      "Epoch 77/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 260.4343 - mse: 260.4343\n",
      "Epoch 77: mse improved from 270.58459 to 268.97314, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261.9701 - mse: 261.9701\n",
      "Epoch 78/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.1153 - mse: 273.1153\n",
      "Epoch 78: mse improved from 268.97314 to 268.32907, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.0202 - mse: 273.0202\n",
      "Epoch 79/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 267.8079 - mse: 267.8079\n",
      "Epoch 79: mse did not improve from 268.32907\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 267.9336 - mse: 267.9336\n",
      "Epoch 80/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 272.5255 - mse: 272.5255\n",
      "Epoch 80: mse did not improve from 268.32907\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 272.1614 - mse: 272.1614\n",
      "Epoch 81/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 269.9555 - mse: 269.9555\n",
      "Epoch 81: mse improved from 268.32907 to 259.10031, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268.4308 - mse: 268.4308\n",
      "Epoch 82/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 260.1781 - mse: 260.1781\n",
      "Epoch 82: mse did not improve from 259.10031\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 260.2340 - mse: 260.2340\n",
      "Epoch 83/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.8994 - mse: 265.8994\n",
      "Epoch 83: mse did not improve from 259.10031\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 265.8792 - mse: 265.8792\n",
      "Epoch 84/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.7817 - mse: 255.7817\n",
      "Epoch 84: mse improved from 259.10031 to 249.42311, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 255.7500 - mse: 255.7500\n",
      "Epoch 85/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 299.4610 - mse: 299.4610\n",
      "Epoch 85: mse did not improve from 249.42311\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 294.2088 - mse: 294.2088\n",
      "Epoch 86/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 259.3048 - mse: 259.3048\n",
      "Epoch 86: mse did not improve from 249.42311\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 259.3766 - mse: 259.3766\n",
      "Epoch 87/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 274.4012 - mse: 274.4012\n",
      "Epoch 87: mse did not improve from 249.42311\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.8539 - mse: 273.8539\n",
      "Epoch 88/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 237.4015 - mse: 237.4015\n",
      "Epoch 88: mse did not improve from 249.42311\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 237.5732 - mse: 237.5732\n",
      "Epoch 89/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 237.6588 - mse: 237.6588\n",
      "Epoch 89: mse improved from 249.42311 to 248.64238, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 238.3343 - mse: 238.3343\n",
      "Epoch 90/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.8566 - mse: 278.8566\n",
      "Epoch 90: mse did not improve from 248.64238\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.3750 - mse: 278.3750\n",
      "Epoch 91/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 257.8080 - mse: 257.8080\n",
      "Epoch 91: mse did not improve from 248.64238\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 257.7744 - mse: 257.7744\n",
      "Epoch 92/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 257.1776 - mse: 257.1776\n",
      "Epoch 92: mse did not improve from 248.64238\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 257.0120 - mse: 257.0120\n",
      "Epoch 93/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 266.3927 - mse: 266.3927\n",
      "Epoch 93: mse did not improve from 248.64238\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 263.7743 - mse: 263.7743\n",
      "Epoch 94/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.9101 - mse: 232.9101\n",
      "Epoch 94: mse improved from 248.64238 to 241.82610, saving model to my_best_model3.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.0490 - mse: 233.0490\n",
      "Epoch 95/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 244.4064 - mse: 244.4064\n",
      "Epoch 95: mse did not improve from 241.82610\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 245.3244 - mse: 245.3244\n",
      "Epoch 96/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.1756 - mse: 241.1756\n",
      "Epoch 96: mse did not improve from 241.82610\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.5029 - mse: 241.5029\n",
      "Epoch 97/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.6422 - mse: 233.6422\n",
      "Epoch 97: mse did not improve from 241.82610\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.8741 - mse: 233.8741\n",
      "Epoch 98/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.2966 - mse: 245.2966\n",
      "Epoch 98: mse did not improve from 241.82610\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.3139 - mse: 245.3139\n",
      "Epoch 99/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.9508 - mse: 233.9508\n",
      "Epoch 99: mse did not improve from 241.82610\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 234.5804 - mse: 234.5804\n",
      "Epoch 1/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 240732.8281 - mse: 240732.8281\n",
      "Epoch 1: mse improved from inf to 142892.79688, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 234083.3438 - mse: 234083.3438\n",
      "Epoch 2/100\n",
      "\u001b[1m176/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 47791.9922 - mse: 47791.9922\n",
      "Epoch 2: mse improved from 142892.79688 to 29351.98242, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45674.2344 - mse: 45674.2344\n",
      "Epoch 3/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4122.2183 - mse: 4122.2183\n",
      "Epoch 3: mse improved from 29351.98242 to 3247.21948, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4075.2791 - mse: 4075.2791\n",
      "Epoch 4/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1986.6030 - mse: 1986.6030\n",
      "Epoch 4: mse improved from 3247.21948 to 1764.98901, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1958.8347 - mse: 1958.8347\n",
      "Epoch 5/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1429.7339 - mse: 1429.7339\n",
      "Epoch 5: mse improved from 1764.98901 to 1294.31152, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1410.9377 - mse: 1410.9377\n",
      "Epoch 6/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1096.3440 - mse: 1096.3440\n",
      "Epoch 6: mse improved from 1294.31152 to 1040.38733, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1090.2715 - mse: 1090.2715\n",
      "Epoch 7/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1009.9241 - mse: 1009.9241\n",
      "Epoch 7: mse improved from 1040.38733 to 920.26141, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 996.8963 - mse: 996.8963  \n",
      "Epoch 8/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 825.1268 - mse: 825.1268\n",
      "Epoch 8: mse improved from 920.26141 to 832.53632, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 826.5866 - mse: 826.5866\n",
      "Epoch 9/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 754.6678 - mse: 754.6678\n",
      "Epoch 9: mse improved from 832.53632 to 747.65271, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 754.6329 - mse: 754.6329\n",
      "Epoch 10/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 730.7908 - mse: 730.7908\n",
      "Epoch 10: mse improved from 747.65271 to 712.26331, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 728.3704 - mse: 728.3704\n",
      "Epoch 11/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 710.1965 - mse: 710.1965\n",
      "Epoch 11: mse improved from 712.26331 to 672.28345, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 709.0601 - mse: 709.0601\n",
      "Epoch 12/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 637.4340 - mse: 637.4340\n",
      "Epoch 12: mse improved from 672.28345 to 641.93420, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 637.6501 - mse: 637.6501\n",
      "Epoch 13/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 620.2272 - mse: 620.2272\n",
      "Epoch 13: mse improved from 641.93420 to 610.96045, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 619.4125 - mse: 619.4125\n",
      "Epoch 14/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 608.7424 - mse: 608.7424\n",
      "Epoch 14: mse improved from 610.96045 to 601.29572, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 608.5773 - mse: 608.5773\n",
      "Epoch 15/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 552.3597 - mse: 552.3597\n",
      "Epoch 15: mse improved from 601.29572 to 547.41876, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 553.1457 - mse: 553.1457\n",
      "Epoch 16/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 585.5782 - mse: 585.5782\n",
      "Epoch 16: mse improved from 547.41876 to 543.33612, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 585.1580 - mse: 585.1580\n",
      "Epoch 17/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 549.6795 - mse: 549.6795\n",
      "Epoch 17: mse improved from 543.33612 to 543.26642, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 549.4072 - mse: 549.4072\n",
      "Epoch 18/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 527.5776 - mse: 527.5776\n",
      "Epoch 18: mse improved from 543.26642 to 503.43442, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 526.9810 - mse: 526.9810\n",
      "Epoch 19/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 557.5942 - mse: 557.5942\n",
      "Epoch 19: mse did not improve from 503.43442\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 550.0340 - mse: 550.0340\n",
      "Epoch 20/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 489.0523 - mse: 489.0523\n",
      "Epoch 20: mse improved from 503.43442 to 491.71497, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 489.6439 - mse: 489.6439\n",
      "Epoch 21/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 477.9568 - mse: 477.9568\n",
      "Epoch 21: mse improved from 491.71497 to 477.04190, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 477.9512 - mse: 477.9512\n",
      "Epoch 22/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 487.6646 - mse: 487.6646\n",
      "Epoch 22: mse did not improve from 477.04190\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 485.6726 - mse: 485.6726\n",
      "Epoch 23/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 435.6080 - mse: 435.6080\n",
      "Epoch 23: mse improved from 477.04190 to 459.49612, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 436.4516 - mse: 436.4516\n",
      "Epoch 24/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 417.4806 - mse: 417.4806\n",
      "Epoch 24: mse improved from 459.49612 to 445.86365, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.5148 - mse: 421.5148\n",
      "Epoch 25/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 428.8426 - mse: 428.8426\n",
      "Epoch 25: mse improved from 445.86365 to 439.41919, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 429.9755 - mse: 429.9755\n",
      "Epoch 26/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405.6057 - mse: 405.6057\n",
      "Epoch 26: mse improved from 439.41919 to 422.02972, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405.6873 - mse: 405.6873\n",
      "Epoch 27/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459.7369 - mse: 459.7369\n",
      "Epoch 27: mse did not improve from 422.02972\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459.3607 - mse: 459.3607\n",
      "Epoch 28/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 436.6918 - mse: 436.6918\n",
      "Epoch 28: mse improved from 422.02972 to 414.46906, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 436.0895 - mse: 436.0895\n",
      "Epoch 29/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 443.7486 - mse: 443.7486\n",
      "Epoch 29: mse did not improve from 414.46906\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 443.6124 - mse: 443.6124\n",
      "Epoch 30/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 404.0526 - mse: 404.0526\n",
      "Epoch 30: mse improved from 414.46906 to 407.49243, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 404.1444 - mse: 404.1444\n",
      "Epoch 31/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 379.5007 - mse: 379.5007\n",
      "Epoch 31: mse improved from 407.49243 to 395.63181, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 381.2325 - mse: 381.2325\n",
      "Epoch 32/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.1740 - mse: 380.1740\n",
      "Epoch 32: mse improved from 395.63181 to 384.49667, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.2766 - mse: 380.2766\n",
      "Epoch 33/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 411.8026 - mse: 411.8026\n",
      "Epoch 33: mse did not improve from 384.49667\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 411.6024 - mse: 411.6024\n",
      "Epoch 34/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 347.1720 - mse: 347.1720\n",
      "Epoch 34: mse improved from 384.49667 to 375.55289, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 347.7045 - mse: 347.7045\n",
      "Epoch 35/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.5388 - mse: 368.5388\n",
      "Epoch 35: mse improved from 375.55289 to 374.33633, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 368.5964 - mse: 368.5964\n",
      "Epoch 36/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.4011 - mse: 369.4011\n",
      "Epoch 36: mse did not improve from 374.33633\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.5648 - mse: 369.5648\n",
      "Epoch 37/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 334.4906 - mse: 334.4906\n",
      "Epoch 37: mse improved from 374.33633 to 368.41980, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 337.1866 - mse: 337.1866\n",
      "Epoch 38/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340.1100 - mse: 340.1100\n",
      "Epoch 38: mse improved from 368.41980 to 362.55902, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 340.6675 - mse: 340.6675\n",
      "Epoch 39/100\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 335.3287 - mse: 335.3287\n",
      "Epoch 39: mse improved from 362.55902 to 346.38879, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 337.3286 - mse: 337.3286\n",
      "Epoch 40/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.8235 - mse: 379.8235\n",
      "Epoch 40: mse did not improve from 346.38879\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.2269 - mse: 379.2269\n",
      "Epoch 41/100\n",
      "\u001b[1m186/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.5696 - mse: 364.5696\n",
      "Epoch 41: mse did not improve from 346.38879\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 363.6342 - mse: 363.6342\n",
      "Epoch 42/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.3353 - mse: 346.3353\n",
      "Epoch 42: mse improved from 346.38879 to 337.03265, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346.1682 - mse: 346.1682\n",
      "Epoch 43/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.2185 - mse: 364.2185\n",
      "Epoch 43: mse did not improve from 337.03265\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 363.4046 - mse: 363.4046\n",
      "Epoch 44/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331.0267 - mse: 331.0267\n",
      "Epoch 44: mse did not improve from 337.03265\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 331.5924 - mse: 331.5924\n",
      "Epoch 45/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.6467 - mse: 309.6467\n",
      "Epoch 45: mse improved from 337.03265 to 329.68427, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.7862 - mse: 310.7862\n",
      "Epoch 46/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 319.9896 - mse: 319.9896\n",
      "Epoch 46: mse improved from 329.68427 to 323.54968, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 320.4372 - mse: 320.4372\n",
      "Epoch 47/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 317.1536 - mse: 317.1536\n",
      "Epoch 47: mse did not improve from 323.54968\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 317.3393 - mse: 317.3393\n",
      "Epoch 48/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 321.8423 - mse: 321.8423\n",
      "Epoch 48: mse did not improve from 323.54968\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 321.9386 - mse: 321.9386\n",
      "Epoch 49/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.0096 - mse: 310.0096\n",
      "Epoch 49: mse improved from 323.54968 to 316.64221, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.0756 - mse: 310.0756\n",
      "Epoch 50/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304.2834 - mse: 304.2834\n",
      "Epoch 50: mse improved from 316.64221 to 303.32913, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304.2750 - mse: 304.2750\n",
      "Epoch 51/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 349.6877 - mse: 349.6877\n",
      "Epoch 51: mse did not improve from 303.32913\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 348.9825 - mse: 348.9825\n",
      "Epoch 52/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.4307 - mse: 310.4307\n",
      "Epoch 52: mse did not improve from 303.32913\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.3970 - mse: 310.3970\n",
      "Epoch 53/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311.6812 - mse: 311.6812\n",
      "Epoch 53: mse improved from 303.32913 to 301.32178, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 311.2775 - mse: 311.2775\n",
      "Epoch 54/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 324.0603 - mse: 324.0603\n",
      "Epoch 54: mse did not improve from 301.32178\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 323.9739 - mse: 323.9739\n",
      "Epoch 55/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 294.0552 - mse: 294.0552\n",
      "Epoch 55: mse improved from 301.32178 to 293.34802, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 293.9594 - mse: 293.9594\n",
      "Epoch 56/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 299.6922 - mse: 299.6922\n",
      "Epoch 56: mse did not improve from 293.34802\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 299.5323 - mse: 299.5323\n",
      "Epoch 57/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.2878 - mse: 275.2878\n",
      "Epoch 57: mse improved from 293.34802 to 290.07175, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 276.0089 - mse: 276.0089\n",
      "Epoch 58/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.5107 - mse: 289.5107\n",
      "Epoch 58: mse did not improve from 290.07175\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.8918 - mse: 289.8918\n",
      "Epoch 59/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 280.3983 - mse: 280.3983\n",
      "Epoch 59: mse did not improve from 290.07175\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 280.9630 - mse: 280.9630\n",
      "Epoch 60/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.8380 - mse: 270.8380\n",
      "Epoch 60: mse improved from 290.07175 to 281.86899, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.3375 - mse: 271.3375\n",
      "Epoch 61/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.7747 - mse: 275.7747\n",
      "Epoch 61: mse improved from 281.86899 to 280.09958, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.8772 - mse: 275.8772\n",
      "Epoch 62/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.8063 - mse: 291.8063\n",
      "Epoch 62: mse improved from 280.09958 to 279.25967, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.0659 - mse: 291.0659\n",
      "Epoch 63/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 290.9458 - mse: 290.9458\n",
      "Epoch 63: mse did not improve from 279.25967\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 290.8544 - mse: 290.8544\n",
      "Epoch 64/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 269.5639 - mse: 269.5639\n",
      "Epoch 64: mse improved from 279.25967 to 275.77258, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.0409 - mse: 270.0409\n",
      "Epoch 65/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.1975 - mse: 273.1975\n",
      "Epoch 65: mse improved from 275.77258 to 273.53281, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.2225 - mse: 273.2225\n",
      "Epoch 66/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 263.3115 - mse: 263.3115\n",
      "Epoch 66: mse improved from 273.53281 to 272.70651, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 263.6707 - mse: 263.6707\n",
      "Epoch 67/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.0040 - mse: 251.0040\n",
      "Epoch 67: mse improved from 272.70651 to 265.57507, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.0765 - mse: 251.0765\n",
      "Epoch 68/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.7587 - mse: 271.7587\n",
      "Epoch 68: mse did not improve from 265.57507\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.5345 - mse: 271.5345\n",
      "Epoch 69/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.4200 - mse: 271.4200\n",
      "Epoch 69: mse improved from 265.57507 to 261.46368, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.1582 - mse: 271.1582\n",
      "Epoch 70/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.7496 - mse: 271.7496\n",
      "Epoch 70: mse did not improve from 261.46368\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 271.4674 - mse: 271.4674\n",
      "Epoch 71/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.3512 - mse: 252.3512\n",
      "Epoch 71: mse improved from 261.46368 to 257.26978, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.4260 - mse: 252.4260\n",
      "Epoch 72/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.1796 - mse: 270.1796\n",
      "Epoch 72: mse did not improve from 257.26978\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 269.6116 - mse: 269.6116\n",
      "Epoch 73/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 238.0280 - mse: 238.0280\n",
      "Epoch 73: mse improved from 257.26978 to 252.96098, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 238.1023 - mse: 238.1023\n",
      "Epoch 74/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253.1557 - mse: 253.1557\n",
      "Epoch 74: mse improved from 252.96098 to 251.20158, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.8726 - mse: 252.8726\n",
      "Epoch 75/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 242.5322 - mse: 242.5322\n",
      "Epoch 75: mse did not improve from 251.20158\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 242.7877 - mse: 242.7877\n",
      "Epoch 76/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 246.5246 - mse: 246.5246\n",
      "Epoch 76: mse did not improve from 251.20158\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 246.9007 - mse: 246.9007\n",
      "Epoch 77/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 259.4599 - mse: 259.4599\n",
      "Epoch 77: mse improved from 251.20158 to 248.10582, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 259.0697 - mse: 259.0697\n",
      "Epoch 78/100\n",
      "\u001b[1m174/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 246.7739 - mse: 246.7739\n",
      "Epoch 78: mse improved from 248.10582 to 243.96156, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 246.3289 - mse: 246.3289\n",
      "Epoch 79/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.4113 - mse: 245.4113\n",
      "Epoch 79: mse improved from 243.96156 to 239.39166, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.2980 - mse: 245.2980\n",
      "Epoch 80/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.7594 - mse: 241.7594\n",
      "Epoch 80: mse improved from 239.39166 to 239.24295, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.7471 - mse: 241.7471\n",
      "Epoch 81/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.3384 - mse: 252.3384\n",
      "Epoch 81: mse did not improve from 239.24295\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 252.3022 - mse: 252.3022\n",
      "Epoch 82/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236.6882 - mse: 236.6882\n",
      "Epoch 82: mse improved from 239.24295 to 236.50056, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236.7853 - mse: 236.7853\n",
      "Epoch 83/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 249.7518 - mse: 249.7518\n",
      "Epoch 83: mse did not improve from 236.50056\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 248.5427 - mse: 248.5427\n",
      "Epoch 84/100\n",
      "\u001b[1m175/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 242.3533 - mse: 242.3533\n",
      "Epoch 84: mse did not improve from 236.50056\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.7996 - mse: 241.7996\n",
      "Epoch 85/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 228.6149 - mse: 228.6149\n",
      "Epoch 85: mse improved from 236.50056 to 233.28706, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 229.2700 - mse: 229.2700\n",
      "Epoch 86/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.7724 - mse: 241.7724\n",
      "Epoch 86: mse did not improve from 233.28706\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.4900 - mse: 241.4900\n",
      "Epoch 87/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 230.8694 - mse: 230.8694\n",
      "Epoch 87: mse improved from 233.28706 to 229.43274, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 230.8896 - mse: 230.8896\n",
      "Epoch 88/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.4093 - mse: 232.4093\n",
      "Epoch 88: mse did not improve from 229.43274\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.4472 - mse: 232.4472\n",
      "Epoch 89/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.2955 - mse: 241.2955\n",
      "Epoch 89: mse did not improve from 229.43274\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.0669 - mse: 241.0669\n",
      "Epoch 90/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218.7318 - mse: 218.7318\n",
      "Epoch 90: mse improved from 229.43274 to 225.60347, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218.8930 - mse: 218.8930\n",
      "Epoch 91/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236.6153 - mse: 236.6153\n",
      "Epoch 91: mse did not improve from 225.60347\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236.6067 - mse: 236.6067\n",
      "Epoch 92/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.3470 - mse: 205.3470\n",
      "Epoch 92: mse improved from 225.60347 to 224.60654, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.0800 - mse: 206.0800\n",
      "Epoch 93/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213.6925 - mse: 213.6925\n",
      "Epoch 93: mse improved from 224.60654 to 224.27673, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.1526 - mse: 214.1526\n",
      "Epoch 94/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.4000 - mse: 195.4000\n",
      "Epoch 94: mse improved from 224.27673 to 215.49722, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.0242 - mse: 196.0242\n",
      "Epoch 95/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 220.9267 - mse: 220.9267\n",
      "Epoch 95: mse did not improve from 215.49722\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 220.7932 - mse: 220.7932\n",
      "Epoch 96/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 237.0743 - mse: 237.0743\n",
      "Epoch 96: mse did not improve from 215.49722\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236.5129 - mse: 236.5129\n",
      "Epoch 97/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 249.9624 - mse: 249.9624\n",
      "Epoch 97: mse did not improve from 215.49722\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 246.2810 - mse: 246.2810\n",
      "Epoch 98/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 221.9255 - mse: 221.9255\n",
      "Epoch 98: mse did not improve from 215.49722\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 221.9209 - mse: 221.9209\n",
      "Epoch 99/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 220.7509 - mse: 220.7509\n",
      "Epoch 99: mse improved from 215.49722 to 213.57904, saving model to my_best_model4.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 220.5467 - mse: 220.5467\n",
      "Epoch 100/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 236.0951 - mse: 236.0951\n",
      "Epoch 100: mse did not improve from 213.57904\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 235.9065 - mse: 235.9065\n",
      "Epoch 1/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 239202.0000 - mse: 239202.0000\n",
      "Epoch 1: mse improved from inf to 140159.93750, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 230157.8281 - mse: 230157.8281\n",
      "Epoch 2/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54890.1172 - mse: 54890.1172\n",
      "Epoch 2: mse improved from 140159.93750 to 41722.98438, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53491.9648 - mse: 53491.9648\n",
      "Epoch 3/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6051.0649 - mse: 6051.0649\n",
      "Epoch 3: mse improved from 41722.98438 to 3782.94727, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5972.7646 - mse: 5972.7646\n",
      "Epoch 4/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1632.0305 - mse: 1632.0305\n",
      "Epoch 4: mse improved from 3782.94727 to 1429.85315, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1625.1658 - mse: 1625.1658\n",
      "Epoch 5/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1100.2874 - mse: 1100.2874\n",
      "Epoch 5: mse improved from 1429.85315 to 1037.47534, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1090.4562 - mse: 1090.4562\n",
      "Epoch 6/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 899.7294 - mse: 899.7294\n",
      "Epoch 6: mse improved from 1037.47534 to 840.11987, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 897.5274 - mse: 897.5274\n",
      "Epoch 7/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 758.1880 - mse: 758.1880\n",
      "Epoch 7: mse improved from 840.11987 to 751.44922, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 757.8678 - mse: 757.8678\n",
      "Epoch 8/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 682.6509 - mse: 682.6509\n",
      "Epoch 8: mse improved from 751.44922 to 679.84186, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 683.2375 - mse: 683.2375\n",
      "Epoch 9/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 616.3168 - mse: 616.3168\n",
      "Epoch 9: mse improved from 679.84186 to 644.43884, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 620.5976 - mse: 620.5976\n",
      "Epoch 10/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 603.7756 - mse: 603.7756\n",
      "Epoch 10: mse improved from 644.43884 to 597.16223, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 603.3943 - mse: 603.3943\n",
      "Epoch 11/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 570.0007 - mse: 570.0007\n",
      "Epoch 11: mse improved from 597.16223 to 572.78894, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 570.4115 - mse: 570.4115\n",
      "Epoch 12/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 519.8704 - mse: 519.8704\n",
      "Epoch 12: mse improved from 572.78894 to 521.01837, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 520.7504 - mse: 520.7504\n",
      "Epoch 13/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 576.6957 - mse: 576.6957\n",
      "Epoch 13: mse improved from 521.01837 to 515.65948, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 570.5106 - mse: 570.5106\n",
      "Epoch 14/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 529.6516 - mse: 529.6516\n",
      "Epoch 14: mse improved from 515.65948 to 512.86206, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 526.8282 - mse: 526.8282\n",
      "Epoch 15/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 453.3708 - mse: 453.3708\n",
      "Epoch 15: mse improved from 512.86206 to 481.87503, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 454.2920 - mse: 454.2920\n",
      "Epoch 16/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 486.1700 - mse: 486.1700\n",
      "Epoch 16: mse improved from 481.87503 to 467.07562, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 483.3596 - mse: 483.3596\n",
      "Epoch 17/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 469.6267 - mse: 469.6267\n",
      "Epoch 17: mse improved from 467.07562 to 465.16251, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 469.5595 - mse: 469.5595\n",
      "Epoch 18/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 442.2575 - mse: 442.2575\n",
      "Epoch 18: mse improved from 465.16251 to 449.42532, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 442.6841 - mse: 442.6841\n",
      "Epoch 19/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 428.3173 - mse: 428.3173\n",
      "Epoch 19: mse improved from 449.42532 to 427.60300, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 428.2605 - mse: 428.2605\n",
      "Epoch 20/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409.0443 - mse: 409.0443\n",
      "Epoch 20: mse improved from 427.60300 to 425.04254, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 411.0311 - mse: 411.0311\n",
      "Epoch 21/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 418.0885 - mse: 418.0885\n",
      "Epoch 21: mse improved from 425.04254 to 404.53714, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 416.3073 - mse: 416.3073\n",
      "Epoch 22/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 435.6882 - mse: 435.6882\n",
      "Epoch 22: mse did not improve from 404.53714\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 434.3947 - mse: 434.3947\n",
      "Epoch 23/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376.0867 - mse: 376.0867\n",
      "Epoch 23: mse improved from 404.53714 to 386.18362, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376.1871 - mse: 376.1871\n",
      "Epoch 24/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.9541 - mse: 403.9541\n",
      "Epoch 24: mse did not improve from 386.18362\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.2091 - mse: 403.2091\n",
      "Epoch 25/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 385.7989 - mse: 385.7989\n",
      "Epoch 25: mse improved from 386.18362 to 383.64383, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 386.5406 - mse: 386.5406\n",
      "Epoch 26/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 407.3394 - mse: 407.3394\n",
      "Epoch 26: mse did not improve from 383.64383\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 406.7740 - mse: 406.7740\n",
      "Epoch 27/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 354.5229 - mse: 354.5229\n",
      "Epoch 27: mse improved from 383.64383 to 366.23065, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 354.7022 - mse: 354.7022\n",
      "Epoch 28/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 358.8900 - mse: 358.8900\n",
      "Epoch 28: mse improved from 366.23065 to 362.73926, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 358.9661 - mse: 358.9661\n",
      "Epoch 29/100\n",
      "\u001b[1m187/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 337.4111 - mse: 337.4111\n",
      "Epoch 29: mse improved from 362.73926 to 351.74716, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 338.3380 - mse: 338.3380\n",
      "Epoch 30/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 350.8519 - mse: 350.8519\n",
      "Epoch 30: mse did not improve from 351.74716\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 350.8867 - mse: 350.8867\n",
      "Epoch 31/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 351.4669 - mse: 351.4669\n",
      "Epoch 31: mse improved from 351.74716 to 339.23895, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 351.2860 - mse: 351.2860\n",
      "Epoch 32/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 342.1187 - mse: 342.1187\n",
      "Epoch 32: mse improved from 339.23895 to 336.97348, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 342.0931 - mse: 342.0931\n",
      "Epoch 33/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 343.8571 - mse: 343.8571\n",
      "Epoch 33: mse improved from 336.97348 to 335.27032, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 343.6562 - mse: 343.6562\n",
      "Epoch 34/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 323.7775 - mse: 323.7775\n",
      "Epoch 34: mse improved from 335.27032 to 325.81000, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 325.0394 - mse: 325.0394\n",
      "Epoch 35/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 355.2462 - mse: 355.2462\n",
      "Epoch 35: mse did not improve from 325.81000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 354.0063 - mse: 354.0063\n",
      "Epoch 36/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 307.4090 - mse: 307.4090\n",
      "Epoch 36: mse improved from 325.81000 to 306.96884, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 307.4212 - mse: 307.4212\n",
      "Epoch 37/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 360.6817 - mse: 360.6817\n",
      "Epoch 37: mse did not improve from 306.96884\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 357.9486 - mse: 357.9486\n",
      "Epoch 38/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 324.3415 - mse: 324.3415\n",
      "Epoch 38: mse did not improve from 306.96884\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 324.2689 - mse: 324.2689\n",
      "Epoch 39/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.5607 - mse: 309.5607\n",
      "Epoch 39: mse did not improve from 306.96884\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309.7961 - mse: 309.7961\n",
      "Epoch 40/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 287.7120 - mse: 287.7120\n",
      "Epoch 40: mse improved from 306.96884 to 300.34610, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 288.7054 - mse: 288.7054\n",
      "Epoch 41/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.5394 - mse: 310.5394\n",
      "Epoch 41: mse did not improve from 300.34610\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310.2062 - mse: 310.2062\n",
      "Epoch 42/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295.3370 - mse: 295.3370\n",
      "Epoch 42: mse improved from 300.34610 to 291.73538, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295.2884 - mse: 295.2884\n",
      "Epoch 43/100\n",
      "\u001b[1m185/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 284.9934 - mse: 284.9934\n",
      "Epoch 43: mse did not improve from 291.73538\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.4640 - mse: 285.4640\n",
      "Epoch 44/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.8964 - mse: 275.8964\n",
      "Epoch 44: mse improved from 291.73538 to 284.26273, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.9797 - mse: 275.9797\n",
      "Epoch 45/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.9929 - mse: 285.9929\n",
      "Epoch 45: mse did not improve from 284.26273\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 286.0494 - mse: 286.0494\n",
      "Epoch 46/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.1802 - mse: 289.1802\n",
      "Epoch 46: mse did not improve from 284.26273\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 289.1176 - mse: 289.1176\n",
      "Epoch 47/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295.9037 - mse: 295.9037\n",
      "Epoch 47: mse did not improve from 284.26273\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295.8965 - mse: 295.8965\n",
      "Epoch 48/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 267.4933 - mse: 267.4933\n",
      "Epoch 48: mse improved from 284.26273 to 282.44296, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 267.9074 - mse: 267.9074\n",
      "Epoch 49/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261.1783 - mse: 261.1783\n",
      "Epoch 49: mse improved from 282.44296 to 270.11212, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261.2227 - mse: 261.2227\n",
      "Epoch 50/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282.9721 - mse: 282.9721\n",
      "Epoch 50: mse did not improve from 270.11212\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 282.7350 - mse: 282.7350\n",
      "Epoch 51/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.4967 - mse: 285.4967\n",
      "Epoch 51: mse did not improve from 270.11212\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 285.3463 - mse: 285.3463\n",
      "Epoch 52/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 261.6191 - mse: 261.6191\n",
      "Epoch 52: mse improved from 270.11212 to 268.05536, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 262.0892 - mse: 262.0892\n",
      "Epoch 53/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 267.0999 - mse: 267.0999\n",
      "Epoch 53: mse did not improve from 268.05536\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 267.2424 - mse: 267.2424\n",
      "Epoch 54/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.6715 - mse: 273.6715\n",
      "Epoch 54: mse improved from 268.05536 to 263.69702, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 273.3602 - mse: 273.3602\n",
      "Epoch 55/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 280.3102 - mse: 280.3102\n",
      "Epoch 55: mse did not improve from 263.69702\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 280.1765 - mse: 280.1765\n",
      "Epoch 56/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 243.3872 - mse: 243.3872\n",
      "Epoch 56: mse improved from 263.69702 to 253.19295, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 244.1258 - mse: 244.1258\n",
      "Epoch 57/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.9919 - mse: 275.9919\n",
      "Epoch 57: mse did not improve from 253.19295\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 275.9541 - mse: 275.9541\n",
      "Epoch 58/100\n",
      "\u001b[1m178/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 237.3248 - mse: 237.3248\n",
      "Epoch 58: mse improved from 253.19295 to 246.98170, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 238.6103 - mse: 238.6103\n",
      "Epoch 59/100\n",
      "\u001b[1m199/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 262.5989 - mse: 262.5989\n",
      "Epoch 59: mse did not improve from 246.98170\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 262.5432 - mse: 262.5432\n",
      "Epoch 60/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 248.5699 - mse: 248.5699\n",
      "Epoch 60: mse did not improve from 246.98170\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 248.9083 - mse: 248.9083\n",
      "Epoch 61/100\n",
      "\u001b[1m170/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 250.4122 - mse: 250.4122\n",
      "Epoch 61: mse improved from 246.98170 to 245.41798, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 249.5867 - mse: 249.5867\n",
      "Epoch 62/100\n",
      "\u001b[1m169/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 253.1897 - mse: 253.1897\n",
      "Epoch 62: mse did not improve from 245.41798\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 251.8602 - mse: 251.8602\n",
      "Epoch 63/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 244.6418 - mse: 244.6418\n",
      "Epoch 63: mse improved from 245.41798 to 241.94041, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 244.5714 - mse: 244.5714\n",
      "Epoch 64/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 270.1593 - mse: 270.1593\n",
      "Epoch 64: mse did not improve from 241.94041\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 268.9318 - mse: 268.9318\n",
      "Epoch 65/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 284.5553 - mse: 284.5553\n",
      "Epoch 65: mse did not improve from 241.94041\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 278.3887 - mse: 278.3887\n",
      "Epoch 66/100\n",
      "\u001b[1m197/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 250.7543 - mse: 250.7543\n",
      "Epoch 66: mse improved from 241.94041 to 232.44865, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 250.4050 - mse: 250.4050\n",
      "Epoch 67/100\n",
      "\u001b[1m192/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 247.7844 - mse: 247.7844\n",
      "Epoch 67: mse did not improve from 232.44865\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 247.4048 - mse: 247.4048\n",
      "Epoch 68/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 224.1968 - mse: 224.1968\n",
      "Epoch 68: mse improved from 232.44865 to 230.59416, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 225.5634 - mse: 225.5634\n",
      "Epoch 69/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.8819 - mse: 232.8819\n",
      "Epoch 69: mse did not improve from 230.59416\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.2405 - mse: 233.2405\n",
      "Epoch 70/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 228.2367 - mse: 228.2367\n",
      "Epoch 70: mse improved from 230.59416 to 229.90067, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 228.2946 - mse: 228.2946\n",
      "Epoch 71/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 239.9503 - mse: 239.9503\n",
      "Epoch 71: mse did not improve from 229.90067\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 239.1400 - mse: 239.1400\n",
      "Epoch 72/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218.9006 - mse: 218.9006\n",
      "Epoch 72: mse improved from 229.90067 to 228.62195, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 219.5848 - mse: 219.5848\n",
      "Epoch 73/100\n",
      "\u001b[1m188/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 234.9894 - mse: 234.9894\n",
      "Epoch 73: mse improved from 228.62195 to 228.42134, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 234.4873 - mse: 234.4873\n",
      "Epoch 74/100\n",
      "\u001b[1m190/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213.9316 - mse: 213.9316\n",
      "Epoch 74: mse improved from 228.42134 to 224.91803, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.5311 - mse: 214.5311\n",
      "Epoch 75/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 233.2113 - mse: 233.2113\n",
      "Epoch 75: mse did not improve from 224.91803\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 232.4394 - mse: 232.4394\n",
      "Epoch 76/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218.2408 - mse: 218.2408\n",
      "Epoch 76: mse did not improve from 224.91803\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218.7038 - mse: 218.7038\n",
      "Epoch 77/100\n",
      "\u001b[1m172/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.9450 - mse: 205.9450\n",
      "Epoch 77: mse improved from 224.91803 to 222.94426, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.9568 - mse: 207.9568\n",
      "Epoch 78/100\n",
      "\u001b[1m171/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.0502 - mse: 200.0502\n",
      "Epoch 78: mse improved from 222.94426 to 214.40131, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.3710 - mse: 202.3710\n",
      "Epoch 79/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 226.2551 - mse: 226.2551\n",
      "Epoch 79: mse did not improve from 214.40131\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 225.6193 - mse: 225.6193\n",
      "Epoch 80/100\n",
      "\u001b[1m177/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.1342 - mse: 208.1342\n",
      "Epoch 80: mse improved from 214.40131 to 213.42462, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.7279 - mse: 208.7279\n",
      "Epoch 81/100\n",
      "\u001b[1m179/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 223.4325 - mse: 223.4325\n",
      "Epoch 81: mse did not improve from 213.42462\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.7049 - mse: 222.7049\n",
      "Epoch 82/100\n",
      "\u001b[1m184/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.0088 - mse: 206.0088\n",
      "Epoch 82: mse improved from 213.42462 to 212.28494, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.5343 - mse: 206.5343\n",
      "Epoch 83/100\n",
      "\u001b[1m181/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.5699 - mse: 209.5699\n",
      "Epoch 83: mse did not improve from 212.28494\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.8256 - mse: 209.8256\n",
      "Epoch 84/100\n",
      "\u001b[1m180/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.6594 - mse: 197.6594\n",
      "Epoch 84: mse improved from 212.28494 to 206.13052, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.5075 - mse: 198.5075\n",
      "Epoch 85/100\n",
      "\u001b[1m189/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.6613 - mse: 212.6613\n",
      "Epoch 85: mse did not improve from 206.13052\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.6260 - mse: 212.6260\n",
      "Epoch 86/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.4759 - mse: 206.4759\n",
      "Epoch 86: mse did not improve from 206.13052\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.9189 - mse: 206.9189\n",
      "Epoch 87/100\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.4216 - mse: 197.4216\n",
      "Epoch 87: mse improved from 206.13052 to 205.75462, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.3126 - mse: 198.3126\n",
      "Epoch 88/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.3732 - mse: 210.3732\n",
      "Epoch 88: mse improved from 205.75462 to 201.30742, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.2360 - mse: 210.2360\n",
      "Epoch 89/100\n",
      "\u001b[1m195/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.5783 - mse: 222.5783\n",
      "Epoch 89: mse did not improve from 201.30742\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.1078 - mse: 222.1078\n",
      "Epoch 90/100\n",
      "\u001b[1m183/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.2257 - mse: 179.2257\n",
      "Epoch 90: mse improved from 201.30742 to 200.58411, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 181.0139 - mse: 181.0139\n",
      "Epoch 91/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.3698 - mse: 199.3698\n",
      "Epoch 91: mse did not improve from 200.58411\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.7450 - mse: 199.7450\n",
      "Epoch 92/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.6084 - mse: 197.6084\n",
      "Epoch 92: mse improved from 200.58411 to 198.83372, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.6825 - mse: 197.6825\n",
      "Epoch 93/100\n",
      "\u001b[1m196/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.5196 - mse: 203.5196\n",
      "Epoch 93: mse did not improve from 198.83372\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.4292 - mse: 203.4292\n",
      "Epoch 94/100\n",
      "\u001b[1m167/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.2257 - mse: 212.2257\n",
      "Epoch 94: mse improved from 198.83372 to 198.53964, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.0143 - mse: 210.0143\n",
      "Epoch 95/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.9483 - mse: 209.9483\n",
      "Epoch 95: mse did not improve from 198.53964\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.5679 - mse: 209.5679\n",
      "Epoch 96/100\n",
      "\u001b[1m168/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.1138 - mse: 212.1138\n",
      "Epoch 96: mse improved from 198.53964 to 194.58313, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.6948 - mse: 209.6948\n",
      "Epoch 97/100\n",
      "\u001b[1m193/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.9822 - mse: 207.9822\n",
      "Epoch 97: mse did not improve from 194.58313\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.5300 - mse: 207.5300\n",
      "Epoch 98/100\n",
      "\u001b[1m194/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.6605 - mse: 214.6605\n",
      "Epoch 98: mse did not improve from 194.58313\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.1105 - mse: 214.1105\n",
      "Epoch 99/100\n",
      "\u001b[1m198/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.0057 - mse: 189.0057\n",
      "Epoch 99: mse improved from 194.58313 to 193.35651, saving model to my_best_model5.keras\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 189.0710 - mse: 189.0710\n",
      "Epoch 100/100\n",
      "\u001b[1m191/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.2753 - mse: 201.2753\n",
      "Epoch 100: mse did not improve from 193.35651\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.9896 - mse: 200.9896\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "validation_loss = []\n",
    "history_list = []\n",
    "\n",
    "for train_index, val_index in kfold.split(X_train, y_train) :\n",
    "    model = create_model()\n",
    "\n",
    "    stop = EarlyStopping(monitor = \"mse\", patience = 5, mode = \"min\")\n",
    "    checkpoint = ModelCheckpoint(filepath = \"my_best_model\" + str(count + 1) + \".keras\", monitor = \"mse\", verbose = 1, save_best_only = True, mode = \"min\")\n",
    "    callbacks_list = [stop, checkpoint]\n",
    "\n",
    "    history = model.fit([X_train[train_index, :] for i in range (16)], y_train[train_index], epochs = 100, callbacks = callbacks_list, batch_size = 32, validation_split = 0)\n",
    "    history_list.append(history)\n",
    "    validation_loss.append(model.evaluate([X_train[val_index, :] for i in range (16)], y_train[val_index], return_dict = True, verbose = 0)[\"loss\"])\n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for hist in history_list :\n",
    "    plt.plot(hist.history[\"loss\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average mse and standard deviation:  186.8068878173828 143.32498551713155\n"
     ]
    }
   ],
   "source": [
    "print(\"average mse and standard deviation: \", np.mean(validation_loss), np.std(validation_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model = []\n",
    "for i in range (1, 6) :\n",
    "    all_model.append(load_model(\"my_best_model\" + str(i) + \".keras\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "model_predict_moyenne = all_model[0].predict([X_test for i in range (16)])\n",
    "\n",
    "for i in range(1, 5) :\n",
    "    model_predict_moyenne += all_model[i].predict([X_test for i in range (16)])\n",
    "\n",
    "model_predict_moyenne = np.round(model_predict_moyenne/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error:  1.6851351600000017\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean error: \", (np.sum(np.abs(model_predict_moyenne[:, 0] - y_test)) / len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[930.     , 426.     , 662.     ,  23.     , 608.     ],\n",
       "       [927.17741, 425.18517, 659.32114,  24.10143, 605.93609]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([model_predict_moyenne[:, 0], y_test])[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
